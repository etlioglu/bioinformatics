<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.54">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Modern Statistics for Modern Biology - 12&nbsp; Supervised Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./imgs/msmb-favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="msmb.css">
<meta property="og:title" content="Modern Statistics for Modern Biology - 12&nbsp; Supervised Learning">
<meta property="og:description" content="If you are a biologist and want to get the best out of the powerful methods of modern computational statistics, this is your book.">
<meta property="og:image" content="https://www.huber.embl.de/msmb-quarto/imgs/MSFMB-Cover2-cropped.jpg">
<meta property="og:site-name" content="Modern Statistics for Modern Biology">
<meta name="twitter:title" content="Modern Statistics for Modern Biology - 12&nbsp; Supervised Learning">
<meta name="twitter:description" content="If you are a biologist and want to get the best out of the powerful methods of modern computational statistics, this is your book.">
<meta name="twitter:image" content="https://www.huber.embl.de/msmb-quarto/imgs/MSFMB-Cover2-cropped.jpg">
<meta name="twitter:card" content="summary">
<script type="text/javascript">
  var _paq = _paq || [];
  
  // Call disableCookies before calling trackPageView 
  _paq.push(['disableCookies']);
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u='//tr-denbi.embl.de/heimdall/';
    _paq.push(['setTrackerUrl', u+'p.php']);
    _paq.push(['setSiteId', '26']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'p.js'; s.parentNode.insertBefore(g,s);
  })();
</script>

</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Modern Statistics for Modern Biology</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-chapters" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Chapters</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-chapters">    
        <li>
    <a class="dropdown-item" href="./index.html" rel="" target="">
 <span class="dropdown-text">Home</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./00-chap.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./01-chap.html" rel="" target="">
 <span class="dropdown-text">Generative Models for Discrete Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./02-chap.html" rel="" target="">
 <span class="dropdown-text">Statistical Modeling</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./03-chap.html" rel="" target="">
 <span class="dropdown-text">High Quality Graphics in R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./04-chap.html" rel="" target="">
 <span class="dropdown-text">Mixture Models</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./05-chap.html" rel="" target="">
 <span class="dropdown-text">Clustering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./06-chap.html" rel="" target="">
 <span class="dropdown-text">Testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./07-chap.html" rel="" target="">
 <span class="dropdown-text">Multivariate Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./08-chap.html" rel="" target="">
 <span class="dropdown-text">High-Throughput Count Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./09-chap.html" rel="" target="">
 <span class="dropdown-text">Multivariate methods for heterogeneous data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./10-chap.html" rel="" target="">
 <span class="dropdown-text">Networks and Trees</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./11-chap.html" rel="" target="">
 <span class="dropdown-text">Image data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./12-chap.html" rel="" target="">
 <span class="dropdown-text">Supervised Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./13-chap.html" rel="" target="">
 <span class="dropdown-text">Design of High Throughput Experiments and their Analyses</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./14-chap.html" rel="" target="">
 <span class="dropdown-text">Statistical Concordance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./15-chap.html" rel="" target="">
 <span class="dropdown-text">Acknowledgements</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./16-chap.html" rel="" target="">
 <span class="dropdown-text">References</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Supervised Learning</span></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sections</h2>
   
  <ul class="collapse">
  <li><a href="#goals-for-this-chapter" id="toc-goals-for-this-chapter" class="nav-link active" data-scroll-target="#goals-for-this-chapter"><span class="header-section-number">12.1</span> Goals for this chapter</a></li>
  <li><a href="#what-are-the-data" id="toc-what-are-the-data" class="nav-link" data-scroll-target="#what-are-the-data"><span class="header-section-number">12.2</span> What are the data?</a></li>
  <li><a href="#linear-discrimination" id="toc-linear-discrimination" class="nav-link" data-scroll-target="#linear-discrimination"><span class="header-section-number">12.3</span> Linear discrimination</a></li>
  <li><a href="#machine-learning-vs-rote-learning" id="toc-machine-learning-vs-rote-learning" class="nav-link" data-scroll-target="#machine-learning-vs-rote-learning"><span class="header-section-number">12.4</span> Machine learning vs rote learning</a></li>
  <li><a href="#sec-supervised-objective" id="toc-sec-supervised-objective" class="nav-link" data-scroll-target="#sec-supervised-objective"><span class="header-section-number">12.5</span> Objective functions</a></li>
  <li><a href="#variancebias-trade-off" id="toc-variancebias-trade-off" class="nav-link" data-scroll-target="#variancebias-trade-off"><span class="header-section-number">12.6</span> Variance–bias trade-off</a></li>
  <li><a href="#sec:ML:caret" id="toc-sec:ML:caret" class="nav-link" data-scroll-target="#sec\:ML\:caret"><span class="header-section-number">12.7</span> A large choice of methods</a></li>
  <li><a href="#summary-of-this-chapter" id="toc-summary-of-this-chapter" class="nav-link" data-scroll-target="#summary-of-this-chapter"><span class="header-section-number">12.8</span> Summary of this chapter</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading"><span class="header-section-number">12.9</span> Further reading</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">12.10</span> Exercises</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-supervised" class="quarto-section-identifier"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Supervised Learning</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>


<div class="no-row-height column-margin column-container"><div class="cell quarto-layout-panel" data-hash="12-chap_cache/html/BuildWall_2584c2d93672e77023b259d761258fcc">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/BuildWall.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/EWall.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</div></div><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="">In a supervised learning setting, we have a yardstick or plumbline to judge how well we are doing: the response itself.</span></div></div>
<p>A frequent question in biological and biomedical applications is whether a property of interest (say, disease type, cell type, the prognosis of a patient) can be “predicted”, given one or more other properties, called the <strong>predictors</strong>. Often we are motivated by a situation in which the property to be predicted is unknown (it lies in the future, or is hard to measure), while the predictors are known. The crucial point is that we <em>learn</em> the prediction rule from a set of <em>training data</em> in which the property of interest is also known. Once we have the rule, we can either apply it to new data, and make actual predictions of unknown outcomes; or we can dissect the rule with the aim of better understanding the underlying biology.</p>
<p>Compared to unsupervised learning and what we have seen in Chapters <a href="05-chap.html" class="quarto-xref"><span>5</span></a>, <a href="07-chap.html" class="quarto-xref"><span>7</span></a> and <a href="09-chap.html" class="quarto-xref"><span>9</span></a>, where we do not know what we are looking for or how to decide whether our result is “right”, we are on much more solid ground with supervised learning: the objective is clearly stated, and there are straightforward criteria to measure how well we are doing.</p>
<div class="page-columns page-full"><p>The central issues in <strong>supervised learning</strong><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> are <strong>overfitting</strong> and <strong>generalizability</strong>: did we just learn the training data “by heart” by constructing a rule that has 100% accuracy on the training data, but would perform poorly on any new data? Or did our rule indeed pick up some of the pertinent patterns in the system being studied, which will also apply to yet unseen new data? (<a href="#fig-overfitting-1" class="quarto-xref">Figure&nbsp;<span>12.1</span></a>)</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Sometimes the term <strong>statistical learning</strong> is used, more or less exchangeably.</p></li></div></div>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-overfitting-1_2cdc5fb541320103da1ed08311bb5a3d">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-overfitting-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-overfitting-1-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;12.1: An example for <strong>overfitting</strong>: two regression lines are fit to data in the <span class="math inline">\((x, y)\)</span>-plane (black points). We can think of such a line as a rule that predicts the <span class="math inline">\(y\)</span>-value, given an <span class="math inline">\(x\)</span>-value. Both lines are smooth, but the fits differ in what is called their <strong>bandwidth</strong>, which intuitively can be interpreted their stiffness. The blue line seems overly keen to follow minor wiggles in the data, while the orange line captures the general trend but is less detailed. The effective number of parameters needed to describe the blue line is much higher than for the orange line. Also, if we were to obtain additional data, it is likely that the blue line would do a <strong>worse</strong> job than the orange line in modeling the new data. We’ll formalize these concepts –training error and test set error– later in this chapter. Although exemplified here with line fitting, the concept applies more generally to prediction models.</figcaption>
</figure>
</div>
</div></div></div>
<section id="goals-for-this-chapter" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="goals-for-this-chapter"><span class="header-section-number">12.1</span> Goals for this chapter</h2>
<p>In this chapter we will:</p>
<ul>
<li><p>See exemplary applications that motivate the use of supervised learning methods.</p></li>
<li><p>Learn what discriminant analysis does.</p></li>
<li><p>Define measures of performance.</p></li>
<li><p>Encounter the curse of dimensionality and see what overfitting is.</p></li>
<li><p>Find out about regularization – in particular, penalization – and understand the concepts of generalizability and model complexity.</p></li>
<li><p>See how to use cross-validation to tune parameters of algorithms.</p></li>
<li><p>Discuss method hacking.</p></li>
</ul>
</section>
<section id="what-are-the-data" class="level2 page-columns page-full" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="what-are-the-data"><span class="header-section-number">12.2</span> What are the data?</h2>
<div class="page-columns page-full"><p>The basic data structure for both supervised and unsupervised learning is (at least conceptually) a dataframe, where each row corresponds to an object and the columns are different features (usually numerical values) of the objects<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. While in unsupervised learning we aim to find (dis)similarity relationships between the objects based on their feature values (e.g., by clustering or ordination), in supervised learning we aim to find a mathematical function (or a computational algorithm) that predicts the value of one of the features from the other features. Many implementations require that there are no missing values, whereas other methods can be made to work with some amount of missing data.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;This is a simplified description. Machine learning is a huge field, and lots of generalizations of this simple conceptual picture have been made. Already the construction of relevant features is an art by itself — we have seen examples with images of cells in <a href="11-chap.html" class="quarto-xref"><span>Chapter&nbsp;11</span></a>, and more generally there are lots of possibilities to extract features from images, sounds, movies, free text, <span class="math inline">\(...\)</span> Moreover, there is a variant of machine learning methods called <strong>kernel methods</strong> that do not need features at all; instead, kernel methods use distances or measures of similarity between objects. It may be easier, for instance, to define a measure of similarity between two natural language text objects than to find relevant numerical features to represent them. Kernel methods are beyond the scope of this book.</p></li></div></div>
<p>The feature that we select over all the others with the aim of predicting is called the <strong>objective</strong> or the <strong>response</strong>. Sometimes the choice is natural, but sometimes it is also instructive to reverse the roles, especially if we are interested in dissecting the prediction function for the purpose of biological understanding, or in disentangling correlations from causation.</p>
<p>The framework for supervised learning covers both continuous and categorical response variables. In the continuous case we also call it <strong>regression</strong>, in the categorical case, <strong>classification</strong>. It turns out that this distinction is not a detail, as it has quite far-reaching consequences for the choice of loss function (<a href="#sec-supervised-objective" class="quarto-xref"><span>Section&nbsp;12.5</span></a>) and thus the choice of algorithm <span class="citation" data-cites="friedmanbiasvariance01">(<a href="16-chap.html#ref-friedmanbiasvariance01" role="doc-biblioref">Friedman 1997</a>)</span>.</p>
<p>The first question to consider in any supervised learning task is how the number of objects compares to the number of predictors. The more objects, the better, and much of the hard work in supervised learning has to do with overcoming the limitations of having a finite (and typically, too small) training set.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-fourtypes_a3fad994a889e2e38757a90629673eb2">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-fourtypes" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/fourquad.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;12.2: In supervised learning, we assign two different roles to our variables. We have labeled the explanatory variables <span class="math inline">\(X\)</span> and the response variable(s) <span class="math inline">\(Y\)</span>. There are also two different sets of observations: the training set <span class="math inline">\(X_\ell\)</span> and <span class="math inline">\(Y_\ell\)</span> and the test set <span class="math inline">\(X_v\)</span> and <span class="math inline">\(Y_v\)</span>. (The subscripts refer to alternative names for the two sets: “learning” and “validation”.)</figcaption>
</figure>
</div>
</div></div></div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<p>Give examples where we have encountered instances of supervised learning with a categorical response in this book.</p>
</div>
</div>
<section id="motivating-examples" class="level3 page-columns page-full" data-number="12.2.1">
<h3 data-number="12.2.1" class="anchored" data-anchor-id="motivating-examples"><span class="header-section-number">12.2.1</span> Motivating examples</h3>
<section id="predicting-diabetes-type" class="level4 unnumbered page-columns page-full">
<h4 class="unnumbered anchored" data-anchor-id="predicting-diabetes-type">Predicting diabetes type</h4>
<p>The <code>diabetes</code> dataset <span class="citation" data-cites="diabetes">(<a href="16-chap.html#ref-diabetes" role="doc-biblioref">Reaven and Miller 1979</a>)</span> presents three different groups of diabetes patients and five clinical variables measured on them.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/diabetes_61d49117810de33f79faa9ce9762c08f">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"diabetes"</span>, <span class="at">package =</span> <span class="st">"rrcov"</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(diabetes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    rw fpg glucose insulin sspg  group
1 0.81  80     356     124   55 normal
2 0.95  97     289     117   76 normal
3 0.94 105     319     143  105 normal
4 1.04  90     356     199  108 normal
5 1.00  90     323     240  143 normal
6 0.76  86     381     157  165 normal</code></pre>
</div>
</div>
<p>The univariate distributions (more precisely, some density estimates of them) are shown in <a href="#fig-ldagroups-1" class="quarto-xref">Figure&nbsp;<span>12.3</span></a>.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-ldagroups-1_210a7c65c5586d064b8a0add941787af">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"reshape2"</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">melt</span>(diabetes, <span class="at">id.vars =</span> <span class="st">"group"</span>), <span class="fu">aes</span>(<span class="at">x =</span> value, <span class="at">col =</span> group)) <span class="sc">+</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_density</span>() <span class="sc">+</span> <span class="fu">facet_wrap</span>( <span class="sc">~</span>variable, <span class="at">ncol =</span> <span class="dv">1</span>, <span class="at">scales =</span> <span class="st">"free"</span>) <span class="sc">+</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-ldagroups-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-ldagroups-1-1.png" class="img-fluid figure-img" width="280"></p>
<figcaption class="figure-caption">Figure&nbsp;12.3: We see already from the one-dimensional distributions that some of the individual variables could potentially predict which group a patient is more likely to belong to. Our goal is to combine variables to improve over such one-dimensional prediction models.</figcaption>
</figure>
</div>
</div></div></div>
<p>The variables are explained in the manual page of the dataset, and in the paper <span class="citation" data-cites="diabetes">(<a href="16-chap.html#ref-diabetes" role="doc-biblioref">Reaven and Miller 1979</a>)</span>:</p>
<ul>
<li><p>rw: relative weight</p></li>
<li><p>fpg: fasting plasma glucose</p></li>
<li><p>glucose: area under the plasma glucose curve for the three hour oral glucose tolerance test (OGTT)</p></li>
<li><p>insulin: area under the plasma insulin curve for the OGTT</p></li>
<li><p>sspg: steady state plasma glucose response</p></li>
<li><p>group: normal, chemical diabetes and overt diabetes</p></li>
</ul>
</section>
<section id="predicting-cellular-phenotypes" class="level4 unnumbered page-columns page-full">
<h4 class="unnumbered anchored" data-anchor-id="predicting-cellular-phenotypes">Predicting cellular phenotypes</h4>
<p><span class="citation" data-cites="Neumann:2010">Neumann et al. (<a href="16-chap.html#ref-Neumann:2010" role="doc-biblioref">2010</a>)</span> observed human cancer cells using live-cell imaging. The cells were genetically engineered so that their histones were tagged with a green fluorescent protein (GFP). A genome-wide RNAi library was applied to the cells, and for each siRNA perturbation, movies of a few hundred cells were recorded for about two days, to see what effect the depletion of each gene had on cell cycle, nuclear morphology and cell proliferation. Their paper reports the use of an automated image classification algorithm that quantified the visual appearance of each cell’s nucleus and enabled the prediction of normal mitosis states or aberrant nuclei. The algorithm was trained on the data from around 3000 cells that were annotated by a human expert. It was then applied to almost 2 billions images of nuclei (<a href="#fig-cellshape" class="quarto-xref">Figure&nbsp;<span>12.4</span></a>). Using automated image classification provided scalability (annotating 2 billion images manually would take a long time) and objectivity.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-cellshape_4eec1af5d7205aff9bf34f7be85ede67">
<div class="cell-output-display page-columns page-full">
<div id="fig-cellshape" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="imgs/Neumann2010Fig1b_web.jpg" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption margin-caption">Figure&nbsp;12.4: The data were images of <span class="math inline">\(2\times10^9\)</span> nuclei from movies. The images were segmented to identify the nuclei, and numeric features were computed for each nucleus, corresponding to size, shape, brightness and lots of other more or less abstract quantitative summaries of the joint distribution of pixel intensities. From the features, the cells were classified into 16 different nuclei morphology classes, represented by the rows of the barplot. Representative images for each class are shown in black and white in the center column. The class frequencies, which are very unbalanced, are shown by the lengths of the bars.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="predicting-embryonic-cell-states" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="predicting-embryonic-cell-states">Predicting embryonic cell states</h4>
<p>We will revisit the mouse embryo data <span class="citation" data-cites="Ohnishi2014">(<a href="16-chap.html#ref-Ohnishi2014" role="doc-biblioref">Ohnishi et al. 2014</a>)</span>, which we have already seen in Chapters <a href="03-chap.html" class="quarto-xref"><span>3</span></a>, <a href="05-chap.html" class="quarto-xref"><span>5</span></a> and <a href="07-chap.html" class="quarto-xref"><span>7</span></a>. We’ll try to predict cell state and genotype from the gene expression measurements in Sections <a href="#sec-supervised-predictembryonicday" class="quarto-xref"><span>12.3.2</span></a> and <a href="#sec-supervised-classifymousecells" class="quarto-xref"><span>12.6.3</span></a>.</p>
</section>
</section>
</section>
<section id="linear-discrimination" class="level2 page-columns page-full" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="linear-discrimination"><span class="header-section-number">12.3</span> Linear discrimination</h2>
<div class="page-columns page-full"><p>We start with one of the simplest possible discrimination problems<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>: we have objects described by two continuous features (so the objects can be thought of as points in the 2D plane) and falling into three groups. Our aim is to define class boundaries, which are lines in the 2D space.</p><div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;Arguably the simplest possible problem is a single continuous feature, two classes, and the task of finding a single threshold to discriminate between the two groups – as in <a href="06-chap.html#fig-testing-FDRvspstatic1" class="quarto-xref">Figure&nbsp;<span>6.2</span></a>.</p></li></div></div>
<section id="diabetes-data" class="level3 page-columns page-full" data-number="12.3.1">
<h3 data-number="12.3.1" class="anchored" data-anchor-id="diabetes-data"><span class="header-section-number">12.3.1</span> Diabetes data</h3>
<p>Let’s see whether we can predict the <code>group</code> from the <code>sspg</code> and <code>glucose</code> variables in the <code>diabetes</code> data. It’s always a good idea to first visualise the data (<a href="#fig-scatterdiabetes-1" class="quarto-xref">Figure&nbsp;<span>12.5</span></a>).</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-scatterdiabetes-1_bf7c6e17f620743d02d7b03ae14d3cd3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>ggdb <span class="ot">=</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> sspg, <span class="at">y =</span> glucose)) <span class="sc">+</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">colour =</span> group), <span class="at">data =</span> diabetes)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>ggdb</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-scatterdiabetes-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-scatterdiabetes-1-1.png" class="img-fluid figure-img" width="280"></p>
<figcaption class="figure-caption">Figure&nbsp;12.5: Scatterplot of two of the variables in the <code>diabetes</code> data. Each point is a sample, and the color indicates the diabetes type as encoded in the <code>group</code> variable.</figcaption>
</figure>
</div>
</div></div></div>
<p>We’ll start with a method called <strong>linear discriminant analysis</strong> (<strong>LDA</strong>). This method is a foundation stone of classification, many of the more complicated (and sometimes more powerful) algorithms are really just generalizations of LDA.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/ldaresults_082c7d91cad6b03013858a6a2156382a">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"MASS"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>diabetes_lda <span class="ot">=</span> <span class="fu">lda</span>(group <span class="sc">~</span> sspg <span class="sc">+</span> glucose, <span class="at">data =</span> diabetes)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>diabetes_lda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Call:
lda(group ~ sspg + glucose, data = diabetes)

Prior probabilities of groups:
   normal  chemical     overt 
0.5241379 0.2482759 0.2275862 

Group means:
             sspg   glucose
normal   114.0000  349.9737
chemical 208.9722  493.9444
overt    318.8788 1043.7576

Coefficients of linear discriminants:
                LD1         LD2
sspg    0.005036943 -0.01539281
glucose 0.005461400  0.00449050

Proportion of trace:
   LD1    LD2 
0.9683 0.0317 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>ghat <span class="ot">=</span> <span class="fu">predict</span>(diabetes_lda)<span class="sc">$</span>class</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(ghat, diabetes<span class="sc">$</span>group)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          
ghat       normal chemical overt
  normal       69       12     1
  chemical      7       24     6
  overt         0        0    26</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(ghat <span class="sc">!=</span> diabetes<span class="sc">$</span>group)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1793103</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-ladoutput" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.1 </strong></span>What do the different parts of the above output mean?</p>
</div>
</div>
</div>
<p>Now, let’s visualise the LDA result. We are going to plot the prediction regions for each of the three groups. We do this by creating a grid of points and using our prediction rule on each of them. We’ll then also dig a bit deeper into the mechanics of LDA and plot the class centers (<code>diabetes_lda$means</code>) and ellipses that correspond to the fitted covariance matrix (<code>diabetes_lda$scaling</code>). Assembling this visualization requires us to write a bit of code.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/make1Dgrid_0f6bf97a913bd96ee891b34b3cc3c521">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>make1Dgrid <span class="ot">=</span> <span class="cf">function</span>(x) {</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  rg <span class="ot">=</span> grDevices<span class="sc">::</span><span class="fu">extendrange</span>(x)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">seq</span>(<span class="at">from =</span> rg[<span class="dv">1</span>], <span class="at">to =</span> rg[<span class="dv">2</span>], <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Set up the points for prediction, a <span class="math inline">\(100 \times 100\)</span> grid that covers the data range.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/diabetes_grid_1_e35d95eb90da5325832cd01762036f17">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>diabetes_grid <span class="ot">=</span> <span class="fu">with</span>(diabetes,</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expand.grid</span>(<span class="at">sspg =</span> <span class="fu">make1Dgrid</span>(sspg),</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">glucose =</span> <span class="fu">make1Dgrid</span>(glucose)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Do the predictions.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/diabetes_grid_2_e7ad24df46f2d56710fa2db45ee7b84c">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>diabetes_grid<span class="sc">$</span>ghat <span class="ot">=</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(diabetes_lda, <span class="at">newdata =</span> diabetes_grid)<span class="sc">$</span>class</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The group centers.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/centers_971098dc62afad3a6b9c0f262ad80212">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>centers <span class="ot">=</span> diabetes_lda<span class="sc">$</span>means</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Compute the ellipse. We start from a unit circle (approximated by a polygon with 360 sides) and apply the corresponding affine transformation from the LDA output.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/unitcircle_699f4ec2cd2b7b53be6594c2144428ee">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>unitcircle <span class="ot">=</span> <span class="fu">exp</span>(1i <span class="sc">*</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2</span><span class="sc">*</span>pi, <span class="at">length.out =</span> <span class="dv">360</span>)) <span class="sc">|&gt;</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>          (\(z) <span class="fu">cbind</span>(<span class="fu">Re</span>(z), <span class="fu">Im</span>(z)))() </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>ellipse <span class="ot">=</span> unitcircle <span class="sc">%*%</span> <span class="fu">solve</span>(diabetes_lda<span class="sc">$</span>scaling) <span class="sc">|&gt;</span> <span class="fu">as_tibble</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>All three ellipses, one for each group center.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"dplyr"</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>ellipses <span class="ot">=</span> <span class="fu">lapply</span>(<span class="fu">rownames</span>(centers), <span class="cf">function</span>(gr) {</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(ellipse,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">sspg    =</span> sspg    <span class="sc">+</span> centers[gr, <span class="st">"sspg"</span>],</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">glucose =</span> glucose <span class="sc">+</span> centers[gr, <span class="st">"glucose"</span>],</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">group   =</span> gr)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>}) <span class="sc">|&gt;</span> <span class="fu">bind_rows</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we are ready to plot (<a href="#fig-modeldiabetes-1" class="quarto-xref">Figure&nbsp;<span>12.6</span></a>).</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-modeldiabetes-1_a10845ebc45da6facf4797fb1cd4502e">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>ggdb <span class="sc">+</span> <span class="fu">geom_raster</span>(<span class="fu">aes</span>(<span class="at">fill =</span> ghat),</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> diabetes_grid, <span class="at">alpha =</span> <span class="fl">0.25</span>, <span class="at">interpolate =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">data =</span> <span class="fu">as_tibble</span>(centers), <span class="at">pch =</span> <span class="st">"+"</span>, <span class="at">size =</span> <span class="dv">8</span>) <span class="sc">+</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_path</span>(<span class="fu">aes</span>(<span class="at">colour =</span> group), <span class="at">data =</span> ellipses) <span class="sc">+</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-modeldiabetes-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-modeldiabetes-1-1.png" class="img-fluid figure-img" width="320"></p>
<figcaption class="figure-caption">Figure&nbsp;12.6: As <a href="#fig-scatterdiabetes-1" class="quarto-xref">Figure&nbsp;<span>12.5</span></a>, with the classification regions from the LDA model shown. The three ellipses represent the class centers and the covariance matrix of the LDA model; note that there is only one covariance matrix, which is the same for all three classes. Therefore also the sizes and orientations of the ellipses are the same for the three classes, only their centers differ. They represent contours of equal class membership probability.</figcaption>
</figure>
</div>
</div></div></div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-decisionboundarynotperpendicular" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.2 </strong></span>Why is the boundary between the prediction regions for <em>chemical</em> and <em>overt</em> not perpendicular to the line between the group centers?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The boundaries would be perpendicular if the ellipses were circles. In general, a boundary is tangential to the contours of equal class probabilities, and due the elliptic shape of the contours, a boundary is in general not perpendicular to the line between centers.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-extrapolation" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.3 </strong></span>How confident would you be about the predictions in those areas of the 2D plane that are far from all of the cluster centers?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Predictions that are far from any cluster center should be assessed critically, as this amounts to an extrapolation into regions where the LDA model may not be very good and/or there may be no training data nearby to support the prediction. We could use the distance to the nearest center as a measure of confidence in the prediction for any particular point; although we will see that resampling and cross-validation based methods offer more generic and usually more reliable measures.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-decisionboundarynothalfway" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.4 </strong></span>Why is the boundary between the prediction regions for <em>normal</em> and <em>chemical</em> not half-way between the centers, but shifted in favor of <em>normal</em>? Hint: have a look at the <code>prior</code> argument of <code>lda</code>. Try again with uniform prior.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The result of the following code chunk is shown in <a href="#fig-diabetes-lda-uniform-prior-1" class="quarto-xref">Figure&nbsp;<span>12.7</span></a>. The suffix <code>_up</code> is short for “uniform prior”.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/fig-diabetes-lda-uniform-prior-1_6089124bc7711ca35318596d6281bcff">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>diabetes_up <span class="ot">=</span> <span class="fu">lda</span>(group <span class="sc">~</span> sspg <span class="sc">+</span> glucose, <span class="at">data =</span> diabetes,</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> (\(n) <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span>n, n)) (<span class="fu">nlevels</span>(diabetes<span class="sc">$</span>group)))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>diabetes_grid<span class="sc">$</span>ghat_up <span class="ot">=</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(diabetes_up, <span class="at">newdata =</span> diabetes_grid)<span class="sc">$</span>class</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="fu">stopifnot</span>(<span class="fu">all.equal</span>(diabetes_up<span class="sc">$</span>means, diabetes_lda<span class="sc">$</span>means))</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>ellipse_up  <span class="ot">=</span> unitcircle <span class="sc">%*%</span> <span class="fu">solve</span>(diabetes_up<span class="sc">$</span>scaling) <span class="sc">|&gt;</span> <span class="fu">as_tibble</span>()</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>ellipses_up <span class="ot">=</span> <span class="fu">lapply</span>(<span class="fu">rownames</span>(centers), <span class="cf">function</span>(gr) {</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(ellipse_up,</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">sspg    =</span> sspg    <span class="sc">+</span> centers[gr, <span class="st">"sspg"</span>],</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>     <span class="at">glucose =</span> glucose <span class="sc">+</span> centers[gr, <span class="st">"glucose"</span>],</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">group   =</span> gr)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>}) <span class="sc">|&gt;</span> <span class="fu">bind_rows</span>()</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>ggdb <span class="sc">+</span> <span class="fu">geom_raster</span>(<span class="fu">aes</span>(<span class="at">fill =</span> ghat_up),</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> diabetes_grid, <span class="at">alpha =</span> <span class="fl">0.4</span>, <span class="at">interpolate =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(centers), <span class="at">pch =</span> <span class="st">"+"</span>, <span class="at">size =</span> <span class="dv">8</span>) <span class="sc">+</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_path</span>(<span class="fu">aes</span>(<span class="at">colour =</span> group), <span class="at">data =</span> ellipses_up) <span class="sc">+</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-diabetes-lda-uniform-prior-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-diabetes-lda-uniform-prior-1-1.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;12.7: As <a href="#fig-modeldiabetes-1" class="quarto-xref">Figure&nbsp;<span>12.6</span></a>, but with uniform class priors.</figcaption>
</figure>
</div>
</div>
</div>
<p>The <code>stopifnot</code> line confirms that the class centers are the same, as they are independent of the prior. The joint covariance is not.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-ellipses" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.5 </strong></span>Figures <a href="#fig-modeldiabetes-1" class="quarto-xref"><span>12.6</span></a> and <a href="#fig-diabetes-lda-uniform-prior-1" class="quarto-xref"><span>12.7</span></a> show both the fitted LDA model, through the ellipses, and the prediction regions, through the area coloring. What part of this visualization is generic for all sorts of classification methods, what part is method-specific?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The prediction regions can be shown for any classification method, including a “black box” method. The cluster centers and ellipses in Figures <a href="#fig-modeldiabetes-1" class="quarto-xref"><span>12.6</span></a> and <a href="#fig-diabetes-lda-uniform-prior-1" class="quarto-xref"><span>12.7</span></a> are method-specific.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-fivevar" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.6 </strong></span>What is the difference in the prediction accuracy if we use all 5 variables instead of just <code>glucose</code> and <code>sspg</code>?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/all5diab_3c9de2db30e62b23d29019ae5b741fbf">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>diabetes_lda5 <span class="ot">=</span> <span class="fu">lda</span>(group <span class="sc">~</span> rw <span class="sc">+</span> fpg <span class="sc">+</span> glucose <span class="sc">+</span> sspg <span class="sc">+</span> insulin, <span class="at">data =</span> diabetes)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>diabetes_lda5</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Call:
lda(group ~ rw + fpg + glucose + sspg + insulin, data = diabetes)

Prior probabilities of groups:
   normal  chemical     overt 
0.5241379 0.2482759 0.2275862 

Group means:
                rw       fpg   glucose     sspg  insulin
normal   0.9372368  91.18421  349.9737 114.0000 172.6447
chemical 1.0558333  99.30556  493.9444 208.9722 288.0000
overt    0.9839394 217.66667 1043.7576 318.8788 106.0000

Coefficients of linear discriminants:
                  LD1          LD2
rw       1.3624356881 -3.784142444
fpg     -0.0336487883  0.036633317
glucose  0.0125763942 -0.007092017
sspg     0.0042431866  0.001134070
insulin -0.0001022245 -0.006173424

Proportion of trace:
   LD1    LD2 
0.8812 0.1188 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>ghat5 <span class="ot">=</span> <span class="fu">predict</span>(diabetes_lda5)<span class="sc">$</span>class</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(ghat5, diabetes<span class="sc">$</span>group)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          
ghat5      normal chemical overt
  normal       73        5     1
  chemical      3       31     5
  overt         0        0    27</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(ghat5 <span class="sc">!=</span> diabetes<span class="sc">$</span>group)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.09655172</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-paperandpencil" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.7 </strong></span>Instead of approximating the prediction regions by classification from a grid of points, compute the separating lines explicitly from the linear determinant coefficients.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>See Section 4.3, Equation (4.10) in <span class="citation" data-cites="HastieTibshiraniFriedman">(<a href="16-chap.html#ref-HastieTibshiraniFriedman" role="doc-biblioref">Hastie, Tibshirani, and Friedman 2008</a>)</span>.</p>
</div>
</div>
</div>
</section>
<section id="sec-supervised-predictembryonicday" class="level3 page-columns page-full" data-number="12.3.2">
<h3 data-number="12.3.2" class="anchored" data-anchor-id="sec-supervised-predictembryonicday"><span class="header-section-number">12.3.2</span> Predicting embryonic cell state from gene expression</h3>
<div class="page-columns page-full"><p>Assume that we already know that the four genes <em>FN1</em>, <em>TIMD2</em>, <em>GATA4</em> and <em>SOX7</em> are relevant to the classification task<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. We want to build a classifier that predicts the developmental time (embryonic days: E3.25, E3.5, E4.5). We load the data and select four corresponding probes.</p><div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;Later in this chapter we will see methods that can drop this assumption and screen all available features.</p></li></div></div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"Hiiragi2013"</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"x"</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>probes <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"1426642_at"</span>, <span class="st">"1418765_at"</span>, <span class="st">"1418864_at"</span>, <span class="st">"1416564_at"</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>embryoCells <span class="ot">=</span> <span class="fu">t</span>(Biobase<span class="sc">::</span><span class="fu">exprs</span>(x)[probes, ]) <span class="sc">|&gt;</span> <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Embryonic.day =</span> x<span class="sc">$</span>Embryonic.day) <span class="sc">|&gt;</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(x<span class="sc">$</span>genotype <span class="sc">==</span> <span class="st">"WT"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can use the Bioconductor annotation package associated with the microarray to verify that the probes correspond to the intended genes.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/annoHiiragi_ac0a669127f00548a10c81c73e5cba94">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">annotation</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "mouse4302"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"mouse4302.db"</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>anno <span class="ot">=</span> AnnotationDbi<span class="sc">::</span><span class="fu">select</span>(mouse4302.db, <span class="at">keys =</span> probes,</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>                             <span class="at">columns =</span> <span class="fu">c</span>(<span class="st">"SYMBOL"</span>, <span class="st">"GENENAME"</span>))</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>anno</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     PROBEID SYMBOL                                            GENENAME
1 1426642_at    Fn1                                       fibronectin 1
2 1418765_at  Timd2 T cell immunoglobulin and mucin domain containing 2
3 1418864_at  Gata4                              GATA binding protein 4
4 1416564_at   Sox7                SRY (sex determining region Y)-box 7</code></pre>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>mt <span class="ot">=</span> <span class="fu">match</span>(anno<span class="sc">$</span>PROBEID, <span class="fu">colnames</span>(embryoCells))</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(embryoCells)[mt] <span class="ot">=</span> anno<span class="sc">$</span>SYMBOL</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we are ready to visualize the data in a pairs plot (<a href="#fig-HiiragiFourGenesPairs-1" class="quarto-xref">Figure&nbsp;<span>12.8</span></a>).</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-HiiragiFourGenesPairs-1_d1ebe255b7ac8d0593177cf6738a7ede">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"GGally"</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpairs</span>(embryoCells, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">col =</span> Embryonic.day),</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">columns =</span> anno<span class="sc">$</span>SYMBOL, <span class="at">upper =</span> <span class="fu">list</span>(<span class="at">continuous =</span> <span class="st">"points"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-HiiragiFourGenesPairs-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-HiiragiFourGenesPairs-1-1.png" class="img-fluid figure-img" width="480"></p>
<figcaption class="figure-caption">Figure&nbsp;12.8: Expression values of the discriminating genes, with the prediction target Embryonic.day shown by color.</figcaption>
</figure>
</div>
</div></div></div>
<p>We can now call <code>lda</code> on these data. The linear combinations <code>LD1</code> and <code>LD2</code> that serve as discriminating variables are given in the slot <code>ed_lda$scaling</code> of the output from <code>lda</code>.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/ldacells_b945cf25ca0e7075203f60d1aa4e29d3">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>ec_lda <span class="ot">=</span> <span class="fu">lda</span>(Embryonic.day <span class="sc">~</span> Fn1 <span class="sc">+</span> Timd2 <span class="sc">+</span> Gata4 <span class="sc">+</span> Sox7,</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">data =</span> embryoCells)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(ec_lda<span class="sc">$</span>scaling, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       LD1  LD2
Fn1   -0.2  0.4
Timd2  0.5  0.0
Gata4 -0.1  0.6
Sox7  -0.7 -0.5</code></pre>
</div>
</div>
<p>For the visualization of the learned model in <a href="#fig-edcontour-1" class="quarto-xref">Figure&nbsp;<span>12.9</span></a>, we need to build the prediction regions and their boundaries by expanding the grid in the space of the two new coordinates LD1 and LD2.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-edcontour-1_77f9b6a82feef16ab0fb9edec0349634">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>ec_rot <span class="ot">=</span> <span class="fu">predict</span>(ec_lda)<span class="sc">$</span>x <span class="sc">|&gt;</span> <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>           <span class="fu">mutate</span>(<span class="at">ed =</span> embryoCells<span class="sc">$</span>Embryonic.day)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>ec_lda2 <span class="ot">=</span> <span class="fu">lda</span>(ec_rot[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], <span class="fu">predict</span>(ec_lda)<span class="sc">$</span>class)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>ec_grid <span class="ot">=</span> <span class="fu">with</span>(ec_rot, <span class="fu">expand.grid</span>(</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">LD1 =</span> <span class="fu">make1Dgrid</span>(LD1),</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">LD2 =</span> <span class="fu">make1Dgrid</span>(LD2)))</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>ec_grid<span class="sc">$</span>edhat <span class="ot">=</span> <span class="fu">predict</span>(ec_lda2, <span class="at">newdata =</span> ec_grid)<span class="sc">$</span>class</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> LD1, <span class="at">y =</span> LD2, <span class="at">colour =</span> ed), <span class="at">data =</span> ec_rot) <span class="sc">+</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_raster</span>(<span class="fu">aes</span>(<span class="at">x =</span> LD1, <span class="at">y =</span> LD2, <span class="at">fill =</span> edhat),</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> ec_grid, <span class="at">alpha =</span> <span class="fl">0.4</span>, <span class="at">interpolate =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_fixed</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-edcontour-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-edcontour-1-1.png" class="img-fluid figure-img" width="360"></p>
<figcaption class="figure-caption">Figure&nbsp;12.9: LDA classification regions for Embryonic.day.</figcaption>
</figure>
</div>
</div></div></div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-qda" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.8 </strong></span>Repeat these analyses using quadratic discriminant analysis (<code>qda</code>). What difference do you see in the shape of the boundaries?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>See code below and <a href="#fig-qdamouse-1" class="quarto-xref">Figure&nbsp;<span>12.10</span></a>.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/fig-qdamouse-1_8c648dd26120bd4a3d62a0739692d675">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"gridExtra"</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>ec_qda <span class="ot">=</span> <span class="fu">qda</span>(Embryonic.day <span class="sc">~</span> Fn1 <span class="sc">+</span> Timd2 <span class="sc">+</span> Gata4 <span class="sc">+</span> Sox7,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">data =</span> embryoCells)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>variables <span class="ot">=</span> <span class="fu">colnames</span>(ec_qda<span class="sc">$</span>means)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>pairs <span class="ot">=</span> <span class="fu">combn</span>(variables, <span class="dv">2</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lapply</span>(<span class="fu">seq_len</span>(<span class="fu">ncol</span>(pairs)), <span class="cf">function</span>(i) {</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>  grid <span class="ot">=</span> <span class="fu">with</span>(embryoCells,</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">expand.grid</span>(<span class="at">x =</span> <span class="fu">make1Dgrid</span>(<span class="fu">get</span>(pairs[<span class="dv">1</span>, i])),</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>                <span class="at">y =</span> <span class="fu">make1Dgrid</span>(<span class="fu">get</span>(pairs[<span class="dv">2</span>, i])))) <span class="sc">|&gt;</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">colnames&lt;-</span><span class="st">`</span>(pairs[, i])</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (v <span class="cf">in</span> <span class="fu">setdiff</span>(variables, pairs[, i]))</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    grid[[v]] <span class="ot">=</span> <span class="fu">median</span>(embryoCells[[v]])</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>  grid<span class="sc">$</span>edhat <span class="ot">=</span> <span class="fu">predict</span>(ec_qda, <span class="at">newdata =</span> grid)<span class="sc">$</span>class</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> pairs[<span class="dv">1</span>,i]</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> pairs[<span class="dv">2</span>,i]</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> embryoCells,</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>      <span class="fu">aes</span>(<span class="at">x =</span> .data[[x]], <span class="at">y =</span> .data[[y]], <span class="at">colour =</span> Embryonic.day)</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_raster</span>(</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>      <span class="fu">aes</span>(<span class="at">x =</span> .data[[x]], <span class="at">y =</span> .data[[y]], <span class="at">fill =</span> edhat),</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> grid, <span class="at">alpha =</span> <span class="fl">0.4</span>, <span class="at">interpolate =</span> <span class="cn">TRUE</span></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_fixed</span>() <span class="sc">+</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (i <span class="sc">!=</span> <span class="fu">ncol</span>(pairs)) <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>)</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>}) <span class="sc">|&gt;</span> (\(g) <span class="fu">grid.arrange</span>(<span class="at">grobs =</span> g, <span class="at">ncol =</span> <span class="dv">2</span>))()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-qdamouse-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-qdamouse-1-1.png" class="img-fluid figure-img" width="720"></p>
<figcaption class="figure-caption">Figure&nbsp;12.10: QDA for the mouse cell data. Shown are all pairwise plots of the four features. In each plot, the other two features are set to the median.</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-qdamany" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.9 </strong></span>What happens if you call <code>lda</code> or <code>qda</code> with a lot more genes, say the first 1000, in the Hiiragi dataset?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell" data-layout-align="center" data-warning.known="variables are collinear" data-hash="12-chap_cache/html/ladallvariables_da4b470d75c83649c5d4d9d04eb761c6">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lda</span>(<span class="fu">t</span>(Biobase<span class="sc">::</span><span class="fu">exprs</span>(x))[, <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>], x<span class="sc">$</span>Embryonic.day)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">warnings</span>()</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qda</span>(<span class="fu">t</span>(Biobase<span class="sc">::</span><span class="fu">exprs</span>(x))[, <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>], x<span class="sc">$</span>Embryonic.day)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>Error in qda.default(x, grouping, ...): some group is too small for 'qda'</code></pre>
</div>
</div>
<p>The <code>lda</code> function manages to fit a model, but complains (with the warning) about the fact that there are more variables than replicates, which means that the variables are not linearly independent, and thus are redundant of each other. The <code>qda</code> function aborts with an error, since the QDA model with so many parameters cannot be fitted from the available data (at least, without making further assumptions, such as some sort of regularization, which it is not equipped for).</p>
</div>
</div>
</div>
</section>
</section>
<section id="machine-learning-vs-rote-learning" class="level2 page-columns page-full" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="machine-learning-vs-rote-learning"><span class="header-section-number">12.4</span> Machine learning vs rote learning</h2>
<div class="page-columns page-full"><p>Computers are really good at memorizing facts. In the worst case, a machine learning algorithm is a roundabout way of doing this<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. The central goal in statistical learning, however, is <em>generalizability</em>. We want an algorithm that is able to generalize, i.e., interpolate and extrapolate from given data to make good predictions about future data.</p><div class="no-row-height column-margin column-container"><li id="fn5"><p><sup>5</sup>&nbsp;The not-so roundabout way is database technologies.</p></li></div></div>
<p>Let’s look at the following example. We generate random data (<code>rnorm</code>) for <code>n</code> objects, with different numbers of features (given by <code>p</code>). We train a LDA on these data and compute the <strong>misclassification rate</strong>, i.e., the fraction of times the prediction is wrong (<code>pred != resp</code>).</p>
<div class="cell page-columns page-full" data-layout-align="center" data-warning.known="variables are collinear" data-hash="12-chap_cache/html/fig-learnbyheart-1_09e61136c07bca8d33b419ee8f5c3d82">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">21</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">20</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>mcl <span class="ot">=</span> <span class="fu">lapply</span>(p, <span class="cf">function</span>(pp) {</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(<span class="dv">100</span>, {</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    xmat <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> pp), <span class="at">nrow =</span> n)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    resp <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">"apple"</span>, <span class="st">"orange"</span>), n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    fit  <span class="ot">=</span> <span class="fu">lda</span>(xmat, resp)</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    pred <span class="ot">=</span> <span class="fu">predict</span>(fit)<span class="sc">$</span>class</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>(pred <span class="sc">!=</span> resp)</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>  }) <span class="sc">|&gt;</span> <span class="fu">mean</span>() <span class="sc">|&gt;</span> (\(x) <span class="fu">tibble</span>(<span class="at">mcl =</span> x, <span class="at">p =</span> pp))()</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>}) <span class="sc">|&gt;</span> <span class="fu">bind_rows</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mcl, <span class="fu">aes</span>(<span class="at">x =</span> p, <span class="at">y =</span> mcl)) <span class="sc">+</span> </span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Misclassification rate"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-learnbyheart-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-learnbyheart-1-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;12.11: Misclassification rate of LDA applied to random data. While the number of observations <code>n</code> is held constant (at 20), we are increasing the number of features <code>p</code> starting from 2 up to 21. The misclassification rate becomes almost zero as <code>p</code> approaches 20. The LDA model becomes so elaborate and over-parameterized that it manages to learn the random labels “by heart”. (As <code>p</code> becomes even larger, the “performance” degrades again somewhat, apparently due to numerical properties of the <code>lda</code> implementation used here.)</figcaption>
</figure>
</div>
</div></div></div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-replicate" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.10 </strong></span>What is the purpose of the <code>replicate</code> loop in the above code? What happens if you omit it (or replace the 100 by 1)?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For each single replicate, the curve is a noisier version of <a href="#fig-learnbyheart-1" class="quarto-xref">Figure&nbsp;<span>12.11</span></a>. Averaging the measured misclassifications rate over 100 replicates makes the estimate more stable. We can do this since we are working with simulated data.</p>
</div>
</div>
</div>
<p><a href="#fig-learnbyheart-1" class="quarto-xref">Figure&nbsp;<span>12.11</span></a> seems to imply that we can perfectly predict random labels from random data, if we only fit a complex enough model, i.e., one with many parameters. How can we overcome such an absurd conclusion? The problem with the above code is that the model performance is evaluated on the same data on which it was trained. This generally leads to positive bias, as you see in this crass example. How can we overcome this problem? The key idea is to assess model performance on different data than those on which the model was trained.</p>
<section id="sec-supervised-xval" class="level3 page-columns page-full" data-number="12.4.1">
<h3 data-number="12.4.1" class="anchored" data-anchor-id="sec-supervised-xval"><span class="header-section-number">12.4.1</span> Cross-validation</h3>
<div class="page-columns page-full"><p>A naive approach might be to split the data in two halves, and use the first half for learning (“training”) and the second half for assessment (“testing”). It turns out that this is needlessly variable and needlessly inefficient. It is needlessly variable, since by splitting the data only once, our results can be quite affected by how the split happens to fall. It seems better to do the splitting many times, and average. This will give us more stable results. It is needlessly inefficient, since the performance of machine learning algorithms depends on the number of observations, and the performance measured on half the data is likely<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> to be worse than what it is with all the data. For this reason, it is better to use unequal sizes of training and test data. In the extreme case, we’ll use as much as <span class="math inline">\(n-1\)</span> observations for training, and the remaining one for testing. After we’ve done this likewise for all observations, we can average our performance metric. This is called <strong>leave-one-out cross-validation</strong>.</p><div class="no-row-height column-margin column-container"><li id="fn6"><p><sup>6</sup>&nbsp;Unless we have such an excess of data that it doesn’t matter.</p></li></div></div>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/book-chunk-1_5879a8ed508b22f112d269570abd7a9d">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/book_icon.png" class="img-fluid figure-img" width="126"></p>
</figure>
</div>
</div></div></div>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="">See Chapter <em>Model Assessment and Selection</em> in the book by <span class="citation" data-cites="HastieTibshiraniFriedman">Hastie, Tibshirani, and Friedman (<a href="16-chap.html#ref-HastieTibshiraniFriedman" role="doc-biblioref">2008</a>)</span> for further discussion on these trade-offs.</span></div></div>
<p>An alternative is <strong><span class="math inline">\(k\)</span>-fold cross-validation</strong>, where the observations are repeatedly split into a training set of size of around <span class="math inline">\(n(k-1)/k\)</span> and a test set of size of around <span class="math inline">\(n/k\)</span>. Both alternatives have pros and contras, and there is not a universally best choice. An advantage of leave-one-out is that the amount of data used for training is close to the maximally available data; this is especially important if the sample size is limiting and “every little matters” for the algorithm. A drawback of leave-one-out is that the training sets are all very similar, so they may not model sufficiently well the kind of sampling changes to be expected if a new dataset came along. For large <span class="math inline">\(n\)</span>, leave-one-out cross-validation can be needlessly time-consuming.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-warning.known="variables are collinear" data-hash="12-chap_cache/html/fig-mclcv-1_da9a651c39949346a9cdd6a6fcdb7b5b">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>estimate_mcl_loocv <span class="ot">=</span> <span class="cf">function</span>(x, resp) {</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vapply</span>(<span class="fu">seq_len</span>(<span class="fu">nrow</span>(x)), <span class="cf">function</span>(i) {</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    fit  <span class="ot">=</span> <span class="fu">lda</span>(x[<span class="sc">-</span>i, ], resp[<span class="sc">-</span>i])</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    ptrn <span class="ot">=</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> x[<span class="sc">-</span>i,, <span class="at">drop =</span> <span class="cn">FALSE</span>])<span class="sc">$</span>class</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    ptst <span class="ot">=</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> x[ i,, <span class="at">drop =</span> <span class="cn">FALSE</span>])<span class="sc">$</span>class</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="at">train =</span> <span class="fu">mean</span>(ptrn <span class="sc">!=</span> resp[<span class="sc">-</span>i]), <span class="at">test =</span> (ptst <span class="sc">!=</span> resp[i]))</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>  }, <span class="at">FUN.VALUE =</span> <span class="fu">numeric</span>(<span class="dv">2</span>)) <span class="sc">|&gt;</span> <span class="fu">rowMeans</span>() <span class="sc">|&gt;</span> <span class="fu">t</span>() <span class="sc">|&gt;</span> <span class="fu">as_tibble</span>()</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>xmat <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> <span class="fu">last</span>(p)), <span class="at">nrow =</span> n)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>resp <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">"apple"</span>, <span class="st">"orange"</span>), n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>mcl <span class="ot">=</span> <span class="fu">lapply</span>(p, <span class="cf">function</span>(k) {</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">estimate_mcl_loocv</span>(xmat[, <span class="dv">1</span><span class="sc">:</span>k], resp)</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>}) <span class="sc">|&gt;</span> <span class="fu">bind_rows</span>() <span class="sc">|&gt;</span> <span class="fu">data.frame</span>(p) <span class="sc">|&gt;</span> <span class="fu">melt</span>(<span class="at">id.var =</span> <span class="st">"p"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mcl, <span class="fu">aes</span>(<span class="at">x =</span> p, <span class="at">y =</span> value, <span class="at">col =</span> variable)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Misclassification rate"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-mclcv-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-mclcv-1-1.png" class="img-fluid figure-img" width="320"></p>
<figcaption class="figure-caption">Figure&nbsp;12.12: Cross-validation: the misclassification rate of LDA applied to random data, when evaluated on test data that were not used for learning, hovers around 0.5 independent of <code>p</code>. The misclassification rate on the training data is also shown. It behaves similar to what we already saw in <a href="#fig-learnbyheart-1" class="quarto-xref">Figure&nbsp;<span>12.11</span></a>.</figcaption>
</figure>
</div>
</div></div></div>
<p>The result is show in <a href="#fig-mclcv-1" class="quarto-xref">Figure&nbsp;<span>12.12</span></a>.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-wiggly" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.11 </strong></span>Why are the curves in <a href="#fig-mclcv-1" class="quarto-xref">Figure&nbsp;<span>12.12</span></a> more variable (“wiggly”) than in <a href="#fig-learnbyheart-1" class="quarto-xref">Figure&nbsp;<span>12.11</span></a>? How can you overcome this?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Only one dataset (<code>xmat</code>, <code>resp</code>) was used to calculate <a href="#fig-mclcv-1" class="quarto-xref">Figure&nbsp;<span>12.12</span></a>, whereas for <a href="#fig-learnbyheart-1" class="quarto-xref">Figure&nbsp;<span>12.11</span></a>, we had the data generated within a <code>replicate</code> loop. You could similarly extend the above code to average the misclassification rate curves over many replicate simulated datasets.</p>
</div>
</div>
</div>
</section>
<section id="sec-supervised-curse" class="level3 page-columns page-full" data-number="12.4.2">
<h3 data-number="12.4.2" class="anchored" data-anchor-id="sec-supervised-curse"><span class="header-section-number">12.4.2</span> The curse of dimensionality</h3>
<p>In <a href="#sec-supervised-xval" class="quarto-xref"><span>Section&nbsp;12.4.1</span></a> we have seen overfitting and cross-validation on random data, but how does it look if there is in fact a relevant class separation?</p>
<div class="cell page-columns page-full" data-layout-align="center" data-warning.known="variables are collinear" data-hash="12-chap_cache/html/fig-curseofdim_046affddd0a3ee772d264a3508f1d0ec">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>p   <span class="ot">=</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">20</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>mcl <span class="ot">=</span> <span class="fu">replicate</span>(<span class="dv">100</span>, {</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  xmat <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> <span class="fu">last</span>(p)), <span class="at">nrow =</span> n)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>  resp <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">"apple"</span>, <span class="st">"orange"</span>), n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>  xmat[, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>] <span class="ot">=</span> xmat[, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>] <span class="sc">+</span> <span class="fu">as.integer</span>(<span class="fu">factor</span>(resp))</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(p, <span class="cf">function</span>(k) {</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">estimate_mcl_loocv</span>(xmat[, <span class="dv">1</span><span class="sc">:</span>k], resp)</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>  }) <span class="sc">|&gt;</span> <span class="fu">bind_rows</span>() <span class="sc">|&gt;</span> <span class="fu">cbind</span>(<span class="at">p =</span> p) <span class="sc">|&gt;</span> <span class="fu">melt</span>(<span class="at">id.var =</span> <span class="st">"p"</span>)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>}, <span class="at">simplify =</span> <span class="cn">FALSE</span>) <span class="sc">|&gt;</span> <span class="fu">bind_rows</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>mcl <span class="ot">=</span> <span class="fu">group_by</span>(mcl, p, variable) <span class="sc">|&gt;</span> <span class="fu">summarise</span>(<span class="at">value =</span> <span class="fu">mean</span>(value))</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mcl, <span class="fu">aes</span>(<span class="at">x =</span> p, <span class="at">y =</span> value, <span class="at">col =</span> variable)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Misclassification rate"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-curseofdim" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-curseofdim-1.png" class="img-fluid figure-img" width="280"></p>
<figcaption class="figure-caption">Figure&nbsp;12.13: As we increase the number of features included in the model, the misclassification rate initially improves; as we start including more and more irrelevant features, it increases again, as we are fitting noise.</figcaption>
</figure>
</div>
</div></div></div>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-BiasVarianceTradeoff_41be8bb33ae6edb2d447fdc58acc391d">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-BiasVarianceTradeoff" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/BiasVarianceTradeoff.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;12.14: Idealized version of <a href="#fig-curseofdim" class="quarto-xref">Figure&nbsp;<span>12.13</span></a>, from <span class="citation" data-cites="HastieTibshiraniFriedman">Hastie, Tibshirani, and Friedman (<a href="16-chap.html#ref-HastieTibshiraniFriedman" role="doc-biblioref">2008</a>)</span>. A recurrent goal in machine learning is finding the sweet spot in the variance &lt;- bias trade-off.</figcaption>
</figure>
</div>
</div></div></div>
<p>The result is shown in <a href="#fig-curseofdim" class="quarto-xref">Figure&nbsp;<span>12.13</span></a>. The group centers are the vectors (in <span class="math inline">\(\mathbb{R}^{20}\)</span>) given by the coordinates <span class="math inline">\((1, 1, 1, 1, 1, 1, 0, 0, 0, ...)\)</span> (apples) and <span class="math inline">\((2, 2, 2, 2, 2, 2, 0, 0, 0, ...)\)</span> (oranges), and the optimal decision boundary is the hyperplane orthogonal to the line between them. For <span class="math inline">\(p\)</span> smaller than <span class="math inline">\(6\)</span>, the decision rule cannot reach this hyperplane – it is biased. As a result, the misclassification rate is suboptimal, and it decreases with <span class="math inline">\(p\)</span>. But what happens for <span class="math inline">\(p\)</span> larger than <span class="math inline">\(6\)</span>? The algorithm is, in principle, able to model the optimal hyperplane, and it should not be distracted by the additional features. The problem is that it is. The more additional features enter the dataset, the higher the probability that one or more of them happen to fall in a way that they <em>look like</em> good, discriminating features in the training data – only to mislead the classifier and degrade its performance in the test data. Shortly we’ll see how to use penalization to (try to) control this problem.</p>
<p>The term <strong>curse of dimensionality</strong> was coined by <span class="citation" data-cites="Bellman:1961">Bellman (<a href="16-chap.html#ref-Bellman:1961" role="doc-biblioref">1961</a>)</span>. It refers to the fact that high-dimensional spaces are very hard, if not impossible, to sample thoroughly: for instance, to cover a 2-dimensional square of side length 1 with grid points that are 0.1 apart, we need <span class="math inline">\(10^2=100\)</span> points. In 100 dimensions, we need <span class="math inline">\(10^{100}\)</span> – which is already more than <a href="https://en.wikipedia.org/wiki/Eddington_number">the number of protons in the universe</a>. In genomics, we often aim to fit models to data with thousands of features. Also our intuitions about distances between points or about the relationship between a volume and its surface break down in a high-dimensional settings. We’ll explore some of the weirdnesses of high-dimensional spaces in the next few questions.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-hypercubesidelen" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.12 </strong></span>Assume you have a dataset with 1 000 000 data points in <span class="math inline">\(p\)</span> dimensions. The data are uniformly distributed in the unit hybercube (i.e., all features lie in the interval <span class="math inline">\([0,1]\)</span>). What’s the side length of a hybercube that can be expected to contain just 10 of the points, as a function of <span class="math inline">\(p\)</span>?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-24-contents" aria-controls="callout-24" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-24" class="callout-24-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>See <a href="#fig-cursedimans1-1" class="quarto-xref">Figure&nbsp;<span>12.15</span></a>.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/fig-cursedimans1-1_d3518240a8696e007d1fc29a166ce4df">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>sideLength <span class="ot">=</span> <span class="cf">function</span>(p, <span class="at">pointDensity =</span> <span class="fl">1e6</span>, <span class="at">pointsNeeded =</span> <span class="dv">10</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>  (pointsNeeded <span class="sc">/</span> pointDensity) <span class="sc">^</span> (<span class="dv">1</span> <span class="sc">/</span> p)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">400</span>, <span class="at">sideLength =</span> <span class="fu">sideLength</span>(p)),</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> p, <span class="at">y =</span> sideLength)) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="at">col =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept =</span> <span class="dv">1</span>), <span class="at">linetype =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-cursedimans1-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-cursedimans1-1-1.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;12.15: Side length of a <span class="math inline">\(p\)</span>-dimensional hybercube expected to contain 10 points out of 1 million uniformly distributed ones, as a function of the <span class="math inline">\(p\)</span>. While for <span class="math inline">\(p=1\)</span>, this length is conveniently small, namely <span class="math inline">\(10/10^6=10^{-5}\)</span>, for larger <span class="math inline">\(p\)</span> it approaches 1, i.,e., becomes the same as the range of each the features. This means that a “local neighborhood” of 10 points encompasses almost the same data range as the whole dataset.</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<p>Next, let’s look at the relation between inner regions of the feature space versus its boundary regions. Generally speaking, prediction at the boundaries of feature space is more difficult than in its interior, as it tends to involve extrapolation, rather than interpolation. In the next question you’ll see how this difficulty explodes with feature space dimension.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-hypercubevolfrac" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.13 </strong></span>What fraction of a unit cube’s total volume is closer than 0.01 to any of its surfaces, as a function of the dimension?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-26-contents" aria-controls="callout-26" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-26" class="callout-26-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>See code below and <a href="#fig-cursedimans2-1" class="quarto-xref">Figure&nbsp;<span>12.16</span></a>.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/fig-cursedimans2-1_27d78363d839fe2d7192ddabd745fe8a">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">400</span>,</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">volOuterCube =</span> <span class="dv">1</span> <span class="sc">^</span> p,</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">volInnerCube =</span> <span class="fl">0.98</span> <span class="sc">^</span> p,  <span class="co"># 0.98 = 1 - 2 * 0.01</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">V(shell)</span><span class="st">`</span> <span class="ot">=</span> volOuterCube <span class="sc">-</span> volInnerCube) <span class="sc">|&gt;</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p, <span class="at">y =</span><span class="st">`</span><span class="at">V(shell)</span><span class="st">`</span>)) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="at">col =</span> <span class="st">"blue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-cursedimans2-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-cursedimans2-1-1.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;12.16: Fraction of a unit cube’s total volume that is in its “shell” (here operationalised as those points that are closer than 0.01 to its surface) as a function of the dimension <span class="math inline">\(p\)</span>.</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-cv" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.14 </strong></span>What is the coefficient of variation (ratio of standard deviation over average) of the distance between two randomly picked points in the unit hypercube, as a function of the dimension?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-28-contents" aria-controls="callout-28" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-28" class="callout-28-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We solve this one by simulation. We generate <code>n</code> pairs of random points in the hypercube (<code>x1</code>, <code>x2</code>) and compute their Euclidean distances. See <a href="#fig-cursedimans3-1" class="quarto-xref">Figure&nbsp;<span>12.17</span></a>. This result can also be predicted from the central limit theorem.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/fig-cursedimans3-1_a6074cd736c31347dc3898b03bd5a618">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>df <span class="ot">=</span> <span class="fu">tibble</span>(</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> <span class="fu">round</span>(<span class="dv">10</span> <span class="sc">^</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">4</span>, <span class="at">by =</span> <span class="fl">0.25</span>)),</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">cv =</span> <span class="fu">vapply</span>(p, <span class="cf">function</span>(k) {</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>    x1 <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(k <span class="sc">*</span> n), <span class="at">nrow =</span> n)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>    x2 <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(k <span class="sc">*</span> n), <span class="at">nrow =</span> n)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>    d <span class="ot">=</span> <span class="fu">sqrt</span>(<span class="fu">rowSums</span>((x1 <span class="sc">-</span> x2)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sd</span>(d) <span class="sc">/</span> <span class="fu">mean</span>(d)</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>  }, <span class="at">FUN.VALUE =</span> <span class="fu">numeric</span>(<span class="dv">1</span>)))</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">log10</span>(p), <span class="at">y =</span> cv)) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="at">col =</span> <span class="st">"orange"</span>) <span class="sc">+</span></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-cursedimans3-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-cursedimans3-1-1.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;12.17: Coefficient of variation (CV) of the distance between randomly picked points in the unit hypercube, as a function of the dimension. As the dimension increases, everybody is equally far away from everyone else: there is almost no variation in the distances any more.</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="sec-supervised-objective" class="level2 page-columns page-full" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="sec-supervised-objective"><span class="header-section-number">12.5</span> Objective functions</h2>
<p>We’ve already seen the <strong>misclassification rate</strong> (MCR) used to assess our classification performance in Figures <a href="#fig-learnbyheart-1" class="quarto-xref"><span>12.11</span></a>–<a href="#fig-curseofdim" class="quarto-xref"><span>12.13</span></a>. Its population version is defined as</p>
<p><span class="anchored-eq" data-anchor-id="eq-sec" id="eq-sec-super-expmcl"><span class="math display">\[
\text{MCR} = \text{E}\left[ 𝟙_{\hat{y} \neq y} \right],
\text{MCR} = \text{E}\left[ 𝟙_{\hat{y} \neq y} \right],
\tag{12.1}\]</span></span></p>
<p>and for a finite sample</p>
<p><span class="anchored-eq" data-anchor-id="eq-sec" id="eq-sec-super-obsmcl"><span class="math display">\[
\widehat{\text{MCR}} = \frac{1}{n}\sum_{i=1}^n 𝟙_{\hat{y_i} \neq y_i}.
\tag{12.2}\]</span></span></p>
<p>This is not the only choice we could make. Perhaps we care more about the misclassification of apples as oranges than vice versa, and we can reflect this by introducing weights that depend on the type of error made into the sum of <a href="#eq-sec-super-obsmcl" class="quarto-xref">Equation&nbsp;<span class="anchored-eq" data-anchor-id="eq-sec">12.2</span></a> (or the integral of <a href="#eq-sec-super-expmcl" class="quarto-xref">Equation&nbsp;<span>12.1</span></a>). This can get even more elaborate if we have more than two classes. Often we want to see the whole <strong>confusion table</strong>, which we can get via</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/confusiontable_cc224860d27aac5fc9876b55fad6dc4c">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(truth, response)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>An important special case is binary classification with asymmetric costs – think about, say, a medical test. Here, the <strong>sensitivity</strong> (a.k.a. <strong>true positive rate</strong> or <strong>recall</strong>) is related to the misclassification of healthy as ill, and the <strong>specificity</strong> (or <strong>true negative rate</strong>) depends on the probability of misclassification of ill as healthy. Often, there is a single parameter (e.g., a threshold) that can be moved up and down, allowing a trade-off between sensitivity and specificity (and thus, equivalently, between the two types of misclassification). In those cases, we usually are not content to know the classifier performance at one single choice of threshold, but at many (or all) of them. This leads to <strong>receiver operating characteristic</strong> (<strong>ROC</strong>) or <strong>precision-recall</strong> curves.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-mcrspsp" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.15 </strong></span>What are the exact relationships between the per-class misclassification rates and sensitivity and specificity?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-30-contents" aria-controls="callout-30" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-30" class="callout-30-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The sensitivity or true positive rate is</p>
<p><span class="math display">\[
\text{TPR} = \frac{\text{TP}}{\text{P}},
\]</span></p>
<p>where <span class="math inline">\(\text{TP}\)</span> is the number of true positives and <span class="math inline">\(\text{P}\)</span> the number of all positives. The specificity or true negative rate is</p>
<p><span class="math display">\[
\text{SPC} = \frac{\text{TN}}{\text{N}},
\]</span></p>
<p>where <span class="math inline">\(\text{TN}\)</span> is the number of true negatives and <span class="math inline">\(\text{N}\)</span> the number of all negatives. See also <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" class="uri">https://en.wikipedia.org/wiki/Sensitivity_and_specificity</a></p>
</div>
</div>
</div>
<p>Another cost function can be computed from the <strong>Jaccard index</strong>, which we already saw in <a href="05-chap.html" class="quarto-xref"><span>Chapter&nbsp;5</span></a>.</p>
<p><span class="anchored-eq" data-anchor-id="eq-sec" id="eq-sec-super-jaccard"><span class="math display">\[
J(A,B) = \frac{|\,A\cap B\,|}{|\,A\cup B\,|},
\tag{12.3}\]</span></span></p>
<p>where <span class="math inline">\(A\)</span> is the set of observations for which the true class is 1 (<span class="math inline">\(A=\{i\,|\,y_i=1\}\)</span>) and <span class="math inline">\(B\)</span> is the set of observations for which the predicted class is 1. The number <span class="math inline">\(J\)</span> is between 0 and 1, and when <span class="math inline">\(J\)</span> is large, it indicates high overlap of the two sets. Note that <span class="math inline">\(J\)</span> does not depend on the number of observations for which both true and predicted class is 0 – so it is particularly suitable for measuring the performance of methods that try to find rare events.</p>
<p>We can also consider probabilistic class predictions, which come in the form <span class="math inline">\(\hat{P}(Y\,|\,X)\)</span>. In this case, a possible risk function would be obtained by looking at distances between the true probability distribution and the estimated probability distributions. For two classes, the finite sample version of the <span class="math inline">\(\log \text{loss}\)</span> is</p>
<p><span class="anchored-eq" data-anchor-id="eq-sec" id="eq-sec-super-logloss"><span class="math display">\[
\log \text{loss} = -\frac{1}{n}\sum_{i=1}^n y_i\log(\hat{p}_i) + (1 - y_i)\log(1 - \hat{p}_i),
\tag{12.4}\]</span></span></p>
<p>where <span class="math inline">\(\hat{p}_i \in [0,1]\)</span> is the prediction, and <span class="math inline">\(y_i\in\{0,1\}\)</span> is the truth.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/unnamed-chunk-67_780f0972c0b37601993eb639cfdae95e">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/devil.png" class="img-fluid figure-img" width="123"></p>
<figcaption class="figure-caption">Note that the <span class="math inline">\(\log\text{loss}\)</span> will be infinite if a prediction is totally confident (<span class="math inline">\(\hat{p}_i\)</span> is exactly <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>) but wrong.</figcaption>
</figure>
</div>
</div></div></div>
<p>For continuous continuous response variables (regression), a natural choice is the <strong>mean squared error</strong> (<strong>MSE</strong>). It is the average squared error,</p>
<p><span class="anchored-eq" data-anchor-id="eq-sec" id="eq-sec-super-obsmse"><span class="math display">\[
\widehat{\text{MSE}} = \frac{1}{n}\sum_{i=1}^n ( \hat{Y}_i - Y_i )^2.
\tag{12.5}\]</span></span></p>
<p>The population version is defined analogously, by turning the summation into an integral as in Equations <a href="#eq-sec-super-expmcl" class="quarto-xref"><span class="anchored-eq" data-anchor-id="eq-sec">12.1</span></a> and <a href="#eq-sec-super-obsmcl" class="quarto-xref"><span>12.2</span></a>.</p>
<div class="page-columns page-full"><p>Statisticians call functions like Equations <a href="#eq-sec-super-expmcl" class="quarto-xref"><span class="anchored-eq" data-anchor-id="eq-sec">12.1</span></a>—<a href="#eq-sec-super-obsmse" class="quarto-xref"><span>12.5</span></a> variously (and depending on context and predisposition) <strong>risk function</strong>, <strong>cost function</strong>, <strong>objective function</strong><a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p><div class="no-row-height column-margin column-container"><li id="fn7"><p><sup>7</sup>&nbsp;There is even an R package dedicated to evaluation of statistical learners called <strong><a href="https://cran.r-project.org/web/packages/metrics/">metrics</a></strong>.</p></li></div></div>
</section>
<section id="variancebias-trade-off" class="level2 page-columns page-full" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="variancebias-trade-off"><span class="header-section-number">12.6</span> Variance–bias trade-off</h2>

<div class="no-row-height column-margin column-container"><div id="fig-supervised-bullseye" class="cell quarto-layout-panel" data-hash="12-chap_cache/html/fig-supervised-bullseye_46577a9eadc264fca9b2dedf071b607e">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-supervised-bullseye-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/TargetBias.png" class="img-fluid figure-img" data-ref-parent="fig-supervised-bullseye"></p>
<figcaption class="figure-caption">(a)</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-supervised-bullseye-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/TargetVariance.png" class="img-fluid figure-img" data-ref-parent="fig-supervised-bullseye"></p>
<figcaption class="figure-caption">(b)</figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;12.18: In bull’s eye (a), the estimates are systematically off target, but in a quite reproducible manner. The green segment represents the bias. In bull’s eye (b), the estimates are not biased, as they are centered in the right place, however they have high variance. We can distinguish the two scenarios since we see the result from many shots. If we only had one shot and missed the bull’s eye, we could not easily know whether that’s because of bias or variance.</figcaption><p></p>
</figure>
</div></div><p>An important fact that helps us understand the tradeoffs when picking a statistical learning model is that the MSE is the sum of two terms, and often the choices we can make are such that one of those terms goes down while the other one goes up. The bias measures how different the average of all the different estimates is from the truth, and variance, how much an individual one might scatter from the average value (<a href="#fig-supervised-bullseye" class="quarto-xref">Figure&nbsp;<span>12.18</span></a>). In applications, we often only get one shot, therefore being reliably almost on target can beat being right on the long term average but really off today. The decomposition</p>
<p><span class="anchored-eq" data-anchor-id="eq-sec" id="eq-sec-super-biasvariancedecompose"><span class="math display">\[
\text{MSE} = \underbrace{\text{Var}(\hat{Y})}_{\text{variance}}
+ \underbrace{\mathbb{E}[\hat{Y}-Y]^2}_{\text{bias}}
\tag{12.6}\]</span></span></p>
<p>follows by straightforward algebra.</p>
<p>When trying to minimize the MSE, it is important to realize that sometimes we can pay the price of a small bias to greatly reduce variance, and thus overall improve MSE. We already encountered shrinkage estimation in <a href="08-chap.html" class="quarto-xref"><span class="anchored-eq" data-anchor-id="eq-sec">Chapter&nbsp;8</span></a>. In classification (i.e., when we have categorical response variables), different objective functions than the MSE are used, and there is usually no such straightforward decomposition as in <a href="#eq-sec-super-biasvariancedecompose" class="quarto-xref">Equation&nbsp;<span>12.6</span></a>. The good news is that we can usually go even much further than in the case of continuous responses with our trading biases for variance. This is because the discreteness of the response absorbs certain biases <span class="citation" data-cites="friedmanbiasvariance01">(<a href="16-chap.html#ref-friedmanbiasvariance01" role="doc-biblioref">Friedman 1997</a>)</span>, so that the cost of higher bias is almost zero, while we still get the benefit of better (smaller) variance.</p>
<section id="penalization" class="level3 page-columns page-full" data-number="12.6.1">
<h3 data-number="12.6.1" class="anchored" data-anchor-id="penalization"><span class="header-section-number">12.6.1</span> Penalization</h3>
<p>In high-dimensional statistics, we are constantly plagued by variance: there is just not enough data to fit all the possible parameters. One of the most fruitful ideas in high-dimensional statistics is <strong>penalization</strong>: a tool to actively control and exploit the variance-bias tradeoff. Penalization is part of a larger class of regularization methods that are used to ensure stable estimates.</p>
<div class="page-columns page-full"><p>Although generalization of LDA to high-dimensional settings is possible <span class="citation" data-cites="clemmensen2012sparse witten2011penalized">(<a href="16-chap.html#ref-clemmensen2012sparse" role="doc-biblioref">Clemmensen et al. 2011</a>; <a href="16-chap.html#ref-witten2011penalized" role="doc-biblioref">Witten and Tibshirani 2011</a>)</span>, it turns out that logistic regression is a more general approach<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>, and therefore we’ll now switch to that, using the <strong><a href="https://cran.r-project.org/web/packages/glmnet/">glmnet</a></strong> package.</p><div class="no-row-height column-margin column-container"><li id="fn8"><p><sup>8</sup>&nbsp;It fits into the framework of generalized linear models, which we encountered in <a href="08-chap.html" class="quarto-xref"><span>Chapter&nbsp;8</span></a>.</p></li></div></div>
<p>For multinomial—or, for the special case of two classes, binomial—logistic regression models, the posterior log-odds between <span class="math inline">\(k\)</span> classes and can be written in the form (see the section on <em>Logistic Regression</em> in the book by <span class="citation" data-cites="HastieTibshiraniFriedman">Hastie, Tibshirani, and Friedman (<a href="16-chap.html#ref-HastieTibshiraniFriedman" role="doc-biblioref">2008</a>)</span> for a more complete presentation):</p>
<p><span class="anchored-eq" data-anchor-id="eq-super" id="eq-super-deflogregress"><span class="math display">\[
\log \frac{P(Y=i\,|\,X=x)}{P(Y=k\,|\,X=x)} = \beta^0_i + \beta_i x,
\tag{12.7}\]</span></span></p>
<p>where <span class="anchored-eq" data-anchor-id="eq-super" class="math inline">\(i=1,...,k-1\)</span> enumerates the different classes and the <span class="math inline">\(k\)</span>-th class is chosen as a reference. The data matrix <span class="math inline">\(x\)</span> has dimensions <span class="math inline">\(n\times p\)</span>, where <span class="math inline">\(n\)</span> is number of observations and <span class="math inline">\(p\)</span> the number of features. The <span class="math inline">\(p\)</span>-dimensional vector <span class="math inline">\(\beta_i\)</span> determines how the classification odds for class <span class="math inline">\(i\)</span> versus class <span class="math inline">\(k\)</span> depend on <span class="math inline">\(x\)</span>. The numbers <span class="math inline">\(\beta^0_i\)</span> are intercepts and depend, among other things, on the classes’ prior probabilities. Instead of the log odds <a href="#eq-super-deflogregress" class="quarto-xref"><span>12.7</span></a> (i.e., ratios of class probabilities), we can also write down an equivalent model for the class probabilities themselves, and the fact that we here used the <span class="math inline">\(k\)</span>-th class as a reference is an arbitrary choice, as the model estimates are equivariant under this choice <span class="citation" data-cites="HastieTibshiraniFriedman">(<a href="16-chap.html#ref-HastieTibshiraniFriedman" role="doc-biblioref">Hastie, Tibshirani, and Friedman 2008</a>)</span>. The model is fit by maximising the log-likelihood <span class="math inline">\(\mathcal{l}(\beta, \beta^0; x)\)</span>, where <span class="math inline">\(\beta=(\beta_1,...,\beta_{k-1})\)</span> and analogously for <span class="math inline">\(\beta^0\)</span>.</p>
<p>So far, so good. But as <span class="math inline">\(p\)</span> gets larger, there is an increasing chance that some of the estimates go wildly off the mark, due to random sampling happenstances in the data (remember <a href="#fig-overfitting-1" class="quarto-xref">Figure&nbsp;<span>12.1</span></a>). This is true even if for each individual coordinate of the vector <span class="math inline">\(\beta_i\)</span>, the error distribution is bounded: the probabilty of there being one coordinate that is in the far tails increases the more coordiates there are, i.e., the larger <span class="math inline">\(p\)</span> is.</p>
<p>A related problem can also occur, not in <a href="#eq-super-deflogregress" class="quarto-xref"><span>12.7</span></a>, but in other, non-linear models, as the model dimension <span class="math inline">\(p\)</span> increases while the sample size <span class="math inline">\(n\)</span> remains the same: the likelihood landscape around its maximum becomes increasingly flat, and the maximum-likelihood estimate of the model parameters becomes more and more variable. Eventually, the maximum is no longer a point, but a submanifold, and the maximum likelihood estimate is unidentifiable. Both of these limitations can be overcome with a modification of the objective: instead of maximising the bare log-likelihood, we maximise a penalized version of it,</p>
<p><span class="anchored-eq" data-anchor-id="eq-super" id="eq-super-penll"><span class="math display">\[
\hat{\beta}= \arg\max_\beta \mathcal{l}(\beta, \beta^0; x) + \lambda \operatorname{pen}(\beta),
\tag{12.8}\]</span></span></p>
<p>where <span class="math inline">\(\lambda\ge0\)</span> is a real number, and <span class="math inline">\(\operatorname{pen}\)</span> is a convex function, called the <strong>penalty function</strong>. Popular choices are <span class="math inline">\(\operatorname{pen}(\beta)=|\beta|^2\)</span> (<strong>ridge regression</strong>) and <span class="math inline">\(\operatorname{pen}(\beta)=|\beta|^1\)</span> (<strong>lasso</strong>).</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/unnamed-chunk-68_5d153219b2d2ebb58a8911d94582e46a">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/devil.png" class="img-fluid figure-img" width="123"></p>
<figcaption class="figure-caption">Here, <span class="math inline">\(|\beta|^\nu=\sum_i\beta_i^\nu\)</span> is the <span class="math inline">\(L_\nu\)</span>-norm of the vector <span class="math inline">\(\beta\)</span>. Variations are possible, for instead we could include in this summation only some but not all of the elements of <span class="math inline">\(\beta\)</span>; or we could scale different elements differently, for instance based on some prior belief of their scale and importance.</figcaption>
</figure>
</div>
</div></div></div>
<p>In the <strong>elastic net</strong>, ridge and lasso are hybridized by using the penalty function <span class="math inline">\(\operatorname{pen}(\beta)=(1-\alpha)|\beta|^1+\alpha|\beta|^2\)</span> with some further parameter <span class="math inline">\(\alpha\in[0,1]\)</span>. The crux is, of course, how to choose the right <span class="math inline">\(\lambda\)</span>, and we will discuss that in the following.</p>
</section>
<section id="example-predicting-colon-cancer-from-stool-microbiome-composition" class="level3 page-columns page-full" data-number="12.6.2">
<h3 data-number="12.6.2" class="anchored" data-anchor-id="example-predicting-colon-cancer-from-stool-microbiome-composition"><span class="header-section-number">12.6.2</span> Example: predicting colon cancer from stool microbiome composition</h3>
<p><span class="citation" data-cites="Zeller:MSB:2014">Zeller et al. (<a href="16-chap.html#ref-Zeller:MSB:2014" role="doc-biblioref">2014</a>)</span> studied metagenome sequencing data from fecal samples of 156 humans that included colorectal cancer patients and tumor-free controls. Their aim was to see whether they could identify biomarkers (presence or abundance of certain taxa) that could help with early tumor detection. The data are available from <a href="https://www.bioconductor.org">Bioconductor</a> through its <strong>ExperimentHub</strong> service under the identifier EH361.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"ExperimentHub"</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>eh <span class="ot">=</span> <span class="fu">ExperimentHub</span>()</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>zeller <span class="ot">=</span> eh[[<span class="st">"EH361"</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/colon1b_aaf4430432ab7370dc93fd27fcc9ef8d">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(zeller<span class="sc">$</span>disease)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
       cancer large_adenoma             n small_adenoma 
           53            15            61            27 </code></pre>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-ehexplore" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.16 </strong></span>Explore the <code>eh</code> object to see what other datasets there are.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-32-contents" aria-controls="callout-32" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-32" class="callout-32-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Type <code>eh</code> into the R prompt and study the output.</p>
</div>
</div>
</div>
<p>For the following, let’s focus on the normal and cancer samples and set the adenomas aside.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/colon2_58cfe6a507c143f5cc4a2e46108dfeb6">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>zellerNC <span class="ot">=</span> zeller[, zeller<span class="sc">$</span>disease <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"n"</span>, <span class="st">"cancer"</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Before jumping into model fitting, as always it’s a good idea to do some exploration of the data. First, let’s look at the sample annotations. The following code prints the data from three randomly picked samples. (Only looking at the first ones, say with the R function <code>head</code>, is also an option, but may not be representative of the whole dataset).</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/zellerpData-1_86f8a4aef54862c91387afae22cf4f96">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pData</span>(zellerNC)[ <span class="fu">sample</span>(<span class="fu">ncol</span>(zellerNC), <span class="dv">3</span>), ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                   subjectID age gender bmi country disease tnm_stage
CCIS12656533ST-4-0    FR-654  51   male  30  france  cancer    t2n1m1
CCIS87252800ST-4-0    FR-505  73   male  17  france  cancer    t2n0m0
CCIS16383318ST-4-0    FR-139  61 female  24  france       n      &lt;NA&gt;
                   ajcc_stage localization     fobt wif-1_gene_methylation_test
CCIS12656533ST-4-0         iv       rectum negative                    negative
CCIS87252800ST-4-0          i        sigma negative                    positive
CCIS16383318ST-4-0       &lt;NA&gt;         &lt;NA&gt; negative                    negative
                     group bodysite ethnicity number_reads
CCIS12656533ST-4-0     crc    stool     white     45546920
CCIS87252800ST-4-0     crc    stool     white     26015120
CCIS16383318ST-4-0 control    stool     white     78085760</code></pre>
</div>
</div>
<p>Next, let’s explore the feature names:</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/unnamed-chunk-69_2c78533f00fab09035330a47d29fb106">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/devil.png" class="img-fluid figure-img" width="123"></p>
<figcaption class="figure-caption">We define the helper function <code>formatfn</code> to line wrap these long character strings for the available space here.</figcaption>
</figure>
</div>
</div></div></div>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/zellerrownames_bca5f8ff956c11dfc3ab5a1e2447bcd3">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>formatfn <span class="ot">=</span> <span class="cf">function</span>(x)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">gsub</span>(<span class="st">"|"</span>, <span class="st">"| "</span>, x, <span class="at">fixed =</span> <span class="cn">TRUE</span>) <span class="sc">|&gt;</span> <span class="fu">lapply</span>(strwrap)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(zellerNC)[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "k__Bacteria"                  "k__Viruses"                  
[3] "k__Bacteria|p__Firmicutes"    "k__Bacteria|p__Bacteroidetes"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(zellerNC)[<span class="fu">nrow</span>(zellerNC) <span class="sc">+</span> (<span class="sc">-</span><span class="dv">2</span><span class="sc">:</span><span class="dv">0</span>)] <span class="sc">|&gt;</span> <span class="fu">formatfn</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[1]]
[1] "k__Bacteria| p__Proteobacteria| c__Deltaproteobacteria|"         
[2] "o__Desulfovibrionales| f__Desulfovibrionaceae| g__Desulfovibrio|"
[3] "s__Desulfovibrio_termitidis"                                     

[[2]]
[1] "k__Viruses| p__Viruses_noname| c__Viruses_noname| o__Viruses_noname|"
[2] "f__Baculoviridae| g__Alphabaculovirus|"                              
[3] "s__Bombyx_mori_nucleopolyhedrovirus|"                                
[4] "t__Bombyx_mori_nucleopolyhedrovirus_unclassified"                    

[[3]]
[1] "k__Bacteria| p__Proteobacteria| c__Deltaproteobacteria|"         
[2] "o__Desulfovibrionales| f__Desulfovibrionaceae| g__Desulfovibrio|"
[3] "s__Desulfovibrio_termitidis| t__GCF_000504305"                   </code></pre>
</div>
</div>
<p>As you can see, the features are a mixture of abundance quantifications at different taxonomic levels, from <em>k</em>ingdom over <em>p</em>hylum to <em>s</em>pecies. We could select only some of these, but here we continue with all of them. Next, let’s look at the distribution of some of the features. Here, we show an arbitrary choice of two, number 510 and 527; in practice, it is helpful to scroll through many such plots quickly to get an impression (<a href="#fig-zellerHist-1" class="quarto-xref">Figure&nbsp;<span>12.19</span></a>).</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-zellerHist-1_87306d878a965d9e88b48efa104b1ac4">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">melt</span>(Biobase<span class="sc">::</span><span class="fu">exprs</span>(zellerNC)[<span class="fu">c</span>(<span class="dv">510</span>, <span class="dv">527</span>), ]), <span class="fu">aes</span>(<span class="at">x =</span> value)) <span class="sc">+</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">25</span>) <span class="sc">+</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_wrap</span>( <span class="sc">~</span> Var1, <span class="at">ncol =</span> <span class="dv">1</span>, <span class="at">scales =</span> <span class="st">"free"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-zellerHist-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-zellerHist-1-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;12.19: Histograms of the distributions for two randomly selected features. The distributions are highly skewed, with many zero values and a thin, long tail of non-zero values.</figcaption>
</figure>
</div>
</div></div></div>
<p>In the simplest case, we fit model <a href="#eq-super-deflogregress" class="quarto-xref"><span>12.7</span></a> as follows.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/glmnet_8c9f0549caa7e9e87a1e772edd79e8ad">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"glmnet"</span>)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>glmfit <span class="ot">=</span> <span class="fu">glmnet</span>(<span class="at">x =</span> <span class="fu">t</span>(Biobase<span class="sc">::</span><span class="fu">exprs</span>(zellerNC)),</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">y =</span> <span class="fu">factor</span>(zellerNC<span class="sc">$</span>disease),</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">family =</span> <span class="st">"binomial"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A remarkable feature of the <code>glmnet</code> function is that it fits <a href="#eq-super-deflogregress" class="quarto-xref"><span>12.7</span></a> not only for one choice of <span class="math inline">\(\lambda\)</span>, but for all possible <span class="math inline">\(\lambda\)</span>s at once. For now, let’s look at the prediction performance for, say, <span class="math inline">\(\lambda=0.04\)</span>. The name of the function parameter is <code>s</code>:</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/colonPred_d2db4ad90410b7cfa73eeab2b318db90">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>predTrsf <span class="ot">=</span> <span class="fu">predict</span>(glmfit, <span class="at">newx =</span> <span class="fu">t</span>(Biobase<span class="sc">::</span><span class="fu">exprs</span>(zellerNC)),</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">type =</span> <span class="st">"class"</span>, <span class="at">s =</span> <span class="fl">0.04</span>)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(predTrsf, zellerNC<span class="sc">$</span>disease)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        
predTrsf cancer  n
  cancer     51  0
  n           2 61</code></pre>
</div>
</div>
<p>Not bad – but remember that this is on the training data, without cross-validation. Let’s have a closer look at <code>glmfit</code>. The <strong><a href="https://cran.r-project.org/web/packages/glmnet/">glmnet</a></strong> package offers a a diagnostic plot that is worth looking at (<a href="#fig-plotglmfit-1" class="quarto-xref">Figure&nbsp;<span>12.20</span></a>).</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-plotglmfit-1_7472ffb4161dd764dc1d09a37a8c37f2">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(glmfit, <span class="at">col =</span> <span class="fu">brewer.pal</span>(<span class="dv">8</span>, <span class="st">"Dark2"</span>), <span class="at">lwd =</span> <span class="fu">sqrt</span>(<span class="dv">3</span>), <span class="at">ylab =</span> <span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-plotglmfit-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-plotglmfit-1-1.png" class="img-fluid figure-img" width="288"></p>
<figcaption class="figure-caption">Figure&nbsp;12.20: Regularization paths for <code>glmfit</code>.</figcaption>
</figure>
</div>
</div></div></div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-plotglmfit" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.17 </strong></span>What are the <span class="math inline">\(x\)</span>- and <span class="math inline">\(y\)</span>-axes in <a href="#fig-plotglmfit-1" class="quarto-xref">Figure&nbsp;<span>12.20</span></a>? What are the different lines?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-34-contents" aria-controls="callout-34" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-34" class="callout-34-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Consult the manual page of the function <code>plot.glmnet</code> in the <strong><a href="https://cran.r-project.org/web/packages/glmnet/">glmnet</a></strong> package.</p>
</div>
</div>
</div>
<p>Let’s get back to the question of how to choose the parameter <span class="math inline">\(\lambda\)</span>. We could try many different choices –and indeed, all possible choices– of <span class="math inline">\(\lambda\)</span>, assess classification performance in each case using cross-validation, and then choose the best <span class="math inline">\(\lambda\)</span>.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/unnamed-chunk-70_ac1db13bcebbba2edf7df6465c5070fe">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/devil.png" class="img-fluid figure-img" width="123"></p>
<figcaption class="figure-caption">You’ll already realize from the description of this strategy that if we optimize <span class="math inline">\(\lambda\)</span> in this way, the resulting apparent classification performance will likely be exaggerated. We need a truly independent dataset, or at least another, outer cross-validation loop to get a more realistic impression of the generalizability. We will get back to this question at the end of the chapter.</figcaption>
</figure>
</div>
</div></div></div>
<p>We could do so by writing a loop as we did in the <code>estimate_mcl_loocv</code> function in <a href="#sec-supervised-xval" class="quarto-xref"><span>Section&nbsp;12.4.1</span></a>. It turns out that the <strong><a href="https://cran.r-project.org/web/packages/glmnet/">glmnet</a></strong> package already has built-in functionality for that, with the function <code>cv.glmnet</code>, which we can use instead.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-colonCV-1_e585bab98087b60b5a522c63fa4e840b">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>cvglmfit <span class="ot">=</span> <span class="fu">cv.glmnet</span>(<span class="at">x =</span> <span class="fu">t</span>(Biobase<span class="sc">::</span><span class="fu">exprs</span>(zellerNC)),</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">y =</span> <span class="fu">factor</span>(zellerNC<span class="sc">$</span>disease),</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cvglmfit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-colonCV-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-colonCV-1-1.png" class="img-fluid figure-img" width="320"></p>
<figcaption class="figure-caption">Figure&nbsp;12.21: Diagnostic plot for <code>cv.glmnet</code>: shown is a measure of cross-validated prediction performance, the deviance, as a function of <span class="math inline">\(\lambda\)</span>. The dashed vertical lines show <code>lambda.min</code> and <code>lambda.1se</code>.</figcaption>
</figure>
</div>
</div></div></div>
<p>The diagnostic plot is shown in <a href="#fig-colonCV-1" class="quarto-xref">Figure&nbsp;<span>12.21</span></a>. We can access the optimal value with</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/lambda.min_1cd98bce4acdea0542716b96f5dac4a3">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>cvglmfit<span class="sc">$</span>lambda.min</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.06680157</code></pre>
</div>
</div>
<p>As this value results from finding a minimum in an estimated curve, it turns out that it is often too small, i.e., that the implied penalization is too weak. A heuristic recommended by the authors of the <strong><a href="https://cran.r-project.org/web/packages/glmnet/">glmnet</a></strong> package is to use a somewhat larger value instead, namely the largest value of <span class="math inline">\(\lambda\)</span> such that the performance measure is within 1 standard error of the minimum.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/lambda.1se_2287c50f06a412462ff07bc213e9091b">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>cvglmfit<span class="sc">$</span>lambda<span class="fl">.1</span>se</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.09691764</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-confusion" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.18 </strong></span>How does the confusion table look like for <span class="math inline">\(\lambda=\;\)</span><code>lambda.1se</code>?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-36-contents" aria-controls="callout-36" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-36" class="callout-36-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/predictwithlambda1se_ded62bfd61d436948be2dd263b69e1a8">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>s0 <span class="ot">=</span> cvglmfit<span class="sc">$</span>lambda<span class="fl">.1</span>se</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(glmfit, <span class="at">newx =</span> <span class="fu">t</span>(Biobase<span class="sc">::</span><span class="fu">exprs</span>(zellerNC)),<span class="at">type =</span> <span class="st">"class"</span>, <span class="at">s =</span> s0) <span class="sc">|&gt;</span></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">table</span>(zellerNC<span class="sc">$</span>disease)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        
         cancer  n
  cancer     37  6
  n          16 55</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-drivingfeatures" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.19 </strong></span>What features drive the classification?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-38-contents" aria-controls="callout-38" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-38" class="callout-38-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/zellercoef_3303849d609265632f6f9504322cd169">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>coefs <span class="ot">=</span> <span class="fu">coef</span>(glmfit)[, <span class="fu">which.min</span>(<span class="fu">abs</span>(glmfit<span class="sc">$</span>lambda <span class="sc">-</span> s0))]</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>topthree <span class="ot">=</span> <span class="fu">order</span>(<span class="fu">abs</span>(coefs), <span class="at">decreasing =</span> <span class="cn">TRUE</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="fu">as.vector</span>(coefs[topthree])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -41.884114  -6.396031  -1.234294</code></pre>
</div>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">formatfn</span>(<span class="fu">names</span>(coefs)[topthree])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[1]]
[1] "k__Bacteria| p__Candidatus_Saccharibacteria|"      
[2] "c__Candidatus_Saccharibacteria_noname|"            
[3] "o__Candidatus_Saccharibacteria_noname|"            
[4] "f__Candidatus_Saccharibacteria_noname|"            
[5] "g__Candidatus_Saccharibacteria_noname|"            
[6] "s__candidate_division_TM7_single_cell_isolate_TM7b"

[[2]]
[1] "k__Bacteria| p__Firmicutes| c__Clostridia| o__Clostridiales|"        
[2] "f__Ruminococcaceae| g__Subdoligranulum| s__Subdoligranulum_variabile"

[[3]]
[1] "k__Bacteria| p__Firmicutes| c__Clostridia| o__Clostridiales|"
[2] "f__Lachnospiraceae| g__Lachnospiraceae_noname|"              
[3] "s__Lachnospiraceae_bacterium_7_1_58FAA"                      </code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-asinh" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.20 </strong></span>How do the results change if we transform the data, say, with the <code>asinh</code> transformation as we saw in <a href="05-chap.html" class="quarto-xref"><span>Chapter&nbsp;5</span></a>?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-40-contents" aria-controls="callout-40" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-40" class="callout-40-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>See <a href="#fig-colonCVTrsf-1" class="quarto-xref">Figure&nbsp;<span>12.22</span></a>.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/fig-colonCVTrsf-1_6324b588304df371a5f4c74b88c6dc88">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cv.glmnet</span>(<span class="at">x =</span> <span class="fu">t</span>(<span class="fu">asinh</span>(Biobase<span class="sc">::</span><span class="fu">exprs</span>(zellerNC))),</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>          <span class="at">y =</span> <span class="fu">factor</span>(zellerNC<span class="sc">$</span>disease),</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">family =</span> <span class="st">"binomial"</span>) <span class="sc">|&gt;</span> <span class="fu">plot</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-colonCVTrsf-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-colonCVTrsf-1-1.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;12.22: like <a href="#fig-colonCV-1" class="quarto-xref">Figure&nbsp;<span>12.21</span></a>, but using an <span class="math inline">\(\text{asinh}\)</span> transformation of the data.</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-ready" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.21 </strong></span>Would a good classification performance on these data mean that this assay is ready for screening and early cancer detection?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-42-contents" aria-controls="callout-42" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-42" class="callout-42-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>No.&nbsp;The performance here is measured on a set of samples in which the cases have similar prevalence as the controls. This serves well enough to explore the biology. However, in a real-life application, the cases will be much less frequent. To be practically useful, the assay must have a much higher specificity, i.e., rarely diagnose disease where there is none. To establish specificity, a much larger set of normal samples need to be tested.</p>
</div>
</div>
</div>
</section>
<section id="sec-supervised-classifymousecells" class="level3 page-columns page-full" data-number="12.6.3">
<h3 data-number="12.6.3" class="anchored" data-anchor-id="sec-supervised-classifymousecells"><span class="header-section-number">12.6.3</span> Example: classifying mouse cells from their expression profiles</h3>
<p>Figures <a href="#fig-colonCV-1" class="quarto-xref"><span>12.21</span></a> and <a href="#fig-colonCVTrsf-1" class="quarto-xref"><span>12.22</span></a> are textbook examples of how we expect the dependence of (cross-validated) classification performance versus model complexity (<span class="math inline">\(\lambda\)</span>) to look. Now let’s get back to the mouse embryo cells data. We’ll try to classify the cells from embryonic day <code>E3.25</code> with respect to their genotype.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-mousecvglmfit-1_1d289e19db570dbaf77d8adb2642cc1b">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>sx <span class="ot">=</span> x[, x<span class="sc">$</span>Embryonic.day <span class="sc">==</span> <span class="st">"E3.25"</span>]</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>embryoCellsClassifier <span class="ot">=</span> <span class="fu">cv.glmnet</span>(<span class="fu">t</span>(Biobase<span class="sc">::</span><span class="fu">exprs</span>(sx)), sx<span class="sc">$</span>genotype,</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">type.measure =</span> <span class="st">"class"</span>)</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(embryoCellsClassifier)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-mousecvglmfit-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-mousecvglmfit-1-1.png" class="img-fluid figure-img" width="320"></p>
<figcaption class="figure-caption">Figure&nbsp;12.23: Cross-validated misclassification error versus penalty parameter for the mouse cells data.</figcaption>
</figure>
</div>
</div></div></div>
<p>In <a href="#fig-mousecvglmfit-1" class="quarto-xref">Figure&nbsp;<span>12.23</span></a> we see that the misclassification error is (essentially) monotonously increasing with <span class="math inline">\(\lambda\)</span>, and is smallest for <span class="math inline">\(\lambda\to 0\)</span>, i.e., if we apply no penalization at all.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-mousewhatsgoingon" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.22 </strong></span>What is going on with these data?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-44-contents" aria-controls="callout-44" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-44" class="callout-44-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>It looks that inclusion of more, and even of all features, does not harm the classification performance. In a way, these data are “too easy”. Let’s do a <span class="math inline">\(t\)</span>-test for all features:</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/fig-mousecellsrowttst-1_6759d63a55a232fcef536e07857ddcab">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>mouse_de <span class="ot">=</span> <span class="fu">rowttests</span>(sx, <span class="st">"genotype"</span>)</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mouse_de, <span class="fu">aes</span>(<span class="at">x =</span> p.value)) <span class="sc">+</span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">boundary =</span> <span class="dv">0</span>, <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.01</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mousecellsrowttst-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-mousecellsrowttst-1-1.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;12.24: Histogram of p-values for the per-feature <span class="math inline">\(t\)</span>-tests between genotypes in the E3.25 cells.</figcaption>
</figure>
</div>
</div>
</div>
<p>The result, shown in <a href="#fig-mousecellsrowttst-1" class="quarto-xref">Figure&nbsp;<span>12.24</span></a>, shows that large number of genes are differentially expressed, and thus informative for the class distinction. We can also compute the pairwise distances between all cells, using all features.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/mousecellsnn1_fc57fa114caa86b63420b9f5359819ff">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>dists <span class="ot">=</span> <span class="fu">as.matrix</span>(<span class="fu">dist</span>(<span class="fu">scale</span>(<span class="fu">t</span>(Biobase<span class="sc">::</span><span class="fu">exprs</span>(x)))))</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(dists) <span class="ot">=</span> <span class="sc">+</span><span class="cn">Inf</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>and then for each cell determine the class of its nearest neighbor</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/mousecellsnn2_8dfc0be80c667ef97d08c09e59b48849">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>nn <span class="ot">=</span> <span class="fu">sapply</span>(<span class="fu">seq_len</span>(<span class="fu">ncol</span>(dists)), <span class="cf">function</span>(i) <span class="fu">which.min</span>(dists[, i]))</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(x<span class="sc">$</span>sampleGroup, x<span class="sc">$</span>sampleGroup[nn]) <span class="sc">|&gt;</span> <span class="st">`</span><span class="at">colnames&lt;-</span><span class="st">`</span>(<span class="cn">NULL</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 
                  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
  E3.25             33    0    0    0    3    0    0    0
  E3.25 (FGF4-KO)    1   15    0    1    0    0    0    0
  E3.5 (EPI)         2    0    3    0    6    0    0    0
  E3.5 (FGF4-KO)     0    0    0    8    0    0    0    0
  E3.5 (PE)          0    0    0    0   11    0    0    0
  E4.5 (EPI)         0    0    0    0    2    2    0    0
  E4.5 (FGF4-KO)     1    0    0    0    0    0    9    0
  E4.5 (PE)          0    0    0    0    2    0    0    2</code></pre>
</div>
</div>
<p>Using all features, the 1 nearest-neighbor classifier is correct in almost all cases, including for the E3.25 wildtype vs FGF4-KO distinction. This means that for these data, there is no apparent benefit in regularization or feature selection. Limitations of using all features might become apparent with truly new data, but that is out of reach for cross-validation.</p>
</div>
</div>
</div>
</section>
</section>
<section id="sec:ML:caret" class="level2 page-columns page-full" data-number="12.7">
<h2 data-number="12.7" class="anchored" data-anchor-id="sec:ML:caret"><span class="header-section-number">12.7</span> A large choice of methods</h2>
<div class="page-columns page-full"><p>We have now seen three classification methods: linear discriminant analysis (<code>lda</code>), quadratic discriminant analysis (<code>qda</code>) and logistic regression using elastic net penalization (<code>glmnet</code>). In fact, there are hundreds of different learning algorithms<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> available in R and its add-on packages. You can get an overview in the CRAN task view <a href="https://cran.r-project.org/web/views/MachineLearning.html">Machine Learning &amp; Statistical Learning</a>. Some examples are:</p><div class="no-row-height column-margin column-container"><li id="fn9"><p><sup>9</sup>&nbsp;For an introduction to the subject that uses R and provides many examples and exercises, we recommend <span class="citation" data-cites="James:2013">(<a href="16-chap.html#ref-James:2013" role="doc-biblioref">James et al. 2013</a>)</span>.</p></li></div></div>
<ul>
<li><p>Support vector machines: the function <code>svm</code> in the package <strong><a href="https://cran.r-project.org/web/packages/e1071/">e1071</a></strong>; <code>ksvm</code> in <strong><a href="https://cran.r-project.org/web/packages/kernlab/">kernlab</a></strong></p></li>
<li><p>Tree based methods in the packages <strong><a href="https://cran.r-project.org/web/packages/rpart/">rpart</a></strong>, <strong><a href="https://cran.r-project.org/web/packages/tree/">tree</a></strong>, <strong><a href="https://cran.r-project.org/web/packages/randomForest/">randomForest</a></strong></p></li>
<li><p>Boosting methods: the functions <code>glmboost</code> and <code>gamboost</code> in package <strong><a href="https://cran.r-project.org/web/packages/mboost/">mboost</a></strong></p></li>
<li><p><code>PenalizedLDA</code> in the package <strong><a href="https://cran.r-project.org/web/packages/PenalizedLDA/">PenalizedLDA</a></strong>, <code>dudi.discr</code> and <code>dist.pcaiv</code> in <strong><a href="https://cran.r-project.org/web/packages/ade4/">ade4</a></strong>).</p></li>
</ul>
<p>The complexity and heterogeneity of choices of learning strategies, tuning parameters and evaluation criteria in each of these packages can be confusing. You will already have noted differences in the interfaces of the <code>lda</code>, <code>qda</code> and <code>glmnet</code> functions, i.e., in how they expect their input data to presented and what they return. There is even greater diversity across all the other packages and functions. At the same time, there are common tasks such as cross-validation, parameter tuning and performance assessment that are more or less the same no matter what specific method is used. As you have seen, e.g., in our <code>estimate_mcl_loocv</code> function, the looping and data shuffling involved led to rather verbose code.</p>
<p>So what to do if you want to try out and explore different learning algorithms? Fortunately, there are several projects that provide unified interfaces to the large number of different machine learning interfaces in R, and also try to provide “best practice” implementations of the common tasks such as parameter tuning and performance assessment. The two most well-known ones are the packages <strong><a href="https://cran.r-project.org/web/packages/caret/">caret</a></strong> and <strong><a href="https://cran.r-project.org/web/packages/mlr/">mlr</a></strong>. Here were have a look at <strong><a href="https://cran.r-project.org/web/packages/caret/">caret</a></strong>. You can get a list of supported methods through its <code>getModelInfo</code> function. There are quite a few, here we just show the first 8.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/caret1_129840c289e9b3c4a5a5ee1363b713b2">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"caret"</span>)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>caretMethods <span class="ot">=</span> <span class="fu">names</span>(<span class="fu">getModelInfo</span>())</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(caretMethods, <span class="dv">8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "ada"         "AdaBag"      "AdaBoost.M1" "adaboost"    "amdai"      
[6] "ANFIS"       "avNNet"      "awnb"       </code></pre>
</div>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(caretMethods)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 239</code></pre>
</div>
</div>
<div class="page-columns page-full"><p>We will check out a neural network method, the <code>nnet</code> function from the eponymous package. The <code>parameter</code> slot informs us on the the available tuning parameters<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>.</p><div class="no-row-height column-margin column-container"><li id="fn10"><p><sup>10</sup>&nbsp;They are described in the manual of the <code>nnet</code> function.</p></li></div></div>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/caret2_a212d85491912060a80867adc29027af">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getModelInfo</span>(<span class="st">"nnet"</span>, <span class="at">regex =</span> <span class="cn">FALSE</span>)[[<span class="dv">1</span>]]<span class="sc">$</span>parameter</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  parameter   class         label
1      size numeric #Hidden Units
2     decay numeric  Weight Decay</code></pre>
</div>
</div>
<p>Let’s try it out.</p>
<div class="cell" data-layout-align="center" data-hash="12-chap_cache/html/caret3_25c14c4a64e9aa4abd25c6b293b40807">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>trnCtrl <span class="ot">=</span> <span class="fu">trainControl</span>(</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"repeatedcv"</span>,</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">repeats =</span> <span class="dv">3</span>,</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">classProbs =</span> <span class="cn">TRUE</span>)</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>tuneGrid <span class="ot">=</span> <span class="fu">expand.grid</span>(</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>),</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">decay =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">1e-2</span>, <span class="fl">1e-1</span>))</span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>nnfit <span class="ot">=</span> <span class="fu">train</span>(</span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>  Embryonic.day <span class="sc">~</span> Fn1 <span class="sc">+</span> Timd2 <span class="sc">+</span> Gata4 <span class="sc">+</span> Sox7,</span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> embryoCells,</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"nnet"</span>,</span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneGrid  =</span> tuneGrid,</span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> trnCtrl,</span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">metric =</span> <span class="st">"Accuracy"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>That’s quite a mouthful, but the nice thing is that this syntax is standardized and applies across many different methods. All you need to do specify the name of the method and the grid of tuning parameters that should be explored via the <code>tuneGrid</code> argument.</p>
<p>Now we can have a look at the output (<a href="#fig-ML-nnfit" class="quarto-xref">Figure&nbsp;<span>12.25</span></a>).</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="12-chap_cache/html/fig-ML-nnfit_755789e94aec53874c90f58464e341e2">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>nnfit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Neural Network 

66 samples
 4 predictor
 3 classes: 'E3.25', 'E3.5', 'E4.5' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 3 times) 
Summary of sample sizes: 58, 59, 60, 60, 60, 59, ... 
Resampling results across tuning parameters:

  size  decay  Accuracy   Kappa    
  2     0.00   0.7695635  0.5508743
  2     0.01   0.7439683  0.5386560
  2     0.10   0.7646032  0.5710356
  4     0.00   0.7576190  0.5358955
  4     0.01   0.7593254  0.5760262
  4     0.10   0.7688492  0.5844597
  8     0.00   0.7835714  0.6185697
  8     0.01   0.7939683  0.6373179
  8     0.10   0.7579365  0.5610362

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were size = 8 and decay = 0.01.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(nnfit)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(nnfit) <span class="sc">|&gt;</span> <span class="fu">head</span>(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] E3.25 E3.25 E3.25 E3.25 E3.25 E3.25 E3.25 E3.25 E3.25 E3.25
Levels: E3.25 E3.5 E4.5</code></pre>
</div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-ML-nnfit" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="12-chap_files/figure-html/fig-ML-nnfit-1.png" class="img-fluid figure-img" width="300"></p>
<figcaption class="figure-caption">Figure&nbsp;12.25: Parameter tuning of the neural net by cross-validation.</figcaption>
</figure>
</div>
</div></div></div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-supervised-generalize" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 12.23 </strong></span>Will the accuracy that we obtained above for the optimal tuning parameters generalize to a new dataset? What could you do to address that?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-46-contents" aria-controls="callout-46" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-46" class="callout-46-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>No, it is likely to be too optimistic, as we have picked the optimum. To get a somewhat more realistic estimate of prediction performance when generalized, we could formalize (into computer code) all our data preprocessing choices and the above parameter tuning procedure, and embed this in another, outer cross-validation loop <span class="citation" data-cites="ambroise2002selection">(<a href="16-chap.html#ref-ambroise2002selection" role="doc-biblioref">Ambroise and McLachlan 2002</a>)</span>. However, this is likely still not enough, as we discuss in the next section.</p>
</div>
</div>
</div>
<section id="method-hacking" class="level3" data-number="12.7.1">
<h3 data-number="12.7.1" class="anchored" data-anchor-id="method-hacking"><span class="header-section-number">12.7.1</span> Method hacking</h3>
<p>In <a href="06-chap.html" class="quarto-xref"><span>Chapter&nbsp;6</span></a> we encountered <em>p-value hacking</em>. A similar phenomenon exists in statistical learning: given a dataset, we explore various different methods of preprocessing (such as normalization, outlier detection, transformation, feature selection), try out different machine learning algorithms and tune their parameters until we are content with the result. The measured accuracy is likely to be too optimistic, i.e., will not generalize to a new dataset. Embedding as many of our methodical choices into a computational formalism and having an outer cross-validation loop (not to be confused with the inner loop that does the parameter tuning) will ameliorate the problem. But is unlikely to address it completely, since not all our choices can be formalized.</p>
<p>The gold standard remains validation on truly unseen data. In addition, it is never a bad thing if the classifier is not a black box but can be interpreted in terms of domain knowledge. Finally, report not just summary statistics, such as misclassification rates, but lay open the complete computational workflow, so that anyone (including your future self) can convince themselves of the robustness of the result or of the influence of the preprocessing, model selection and tuning choices <span class="citation" data-cites="Holmes2017">(<a href="16-chap.html#ref-Holmes2017" role="doc-biblioref">Holmes 2018</a>)</span>.</p>
</section>
</section>
<section id="summary-of-this-chapter" class="level2 page-columns page-full" data-number="12.8">
<h2 data-number="12.8" class="anchored" data-anchor-id="summary-of-this-chapter"><span class="header-section-number">12.8</span> Summary of this chapter</h2>
<p>We have seen examples of machine learning applications; we have focused on predicting categorical variables (like diabetes type or cell class). Predicting continuous outcomes is also part of machine learning, although we have not considered it here. There are many parallels and overlaps between <em>machine learning</em> and <em>statistical regression</em> (which we studied in <a href="08-chap.html" class="quarto-xref"><span>Chapter&nbsp;8</span></a>). One can consider them two different names for pretty much the same activity, although each has its own flavors: in machine learning, the emphasis is on the prediction of the outcome variables, whereas in regression we often care at least as much about the role of the covariates – which of them have an effect on the outcome, and what is the nature of these effects? In other words, we do not only want predictions, we also want to understand them.</p>
<p>We saw linear and quadratic discriminant analysis, two intuitive methods for partitioning a two-dimensional data plane (or a <span class="math inline">\(p\)</span>-dimensional space) into regions using either linear or quadratic separation lines (or hypersurfaces). We also saw logistic regression, which takes a slightly different approach but is more amenable to operating in higher dimensions and to regularization.</p>
<p>We encountered the main challenge of machine learning: how to avoid overfitting? We explored why overfitting happens in the context of the so-called curse of dimensionality, and we learned how it may be overcome using regularization.</p>
<div class="page-columns page-full"><p>In other words, machine learning would be easy if we had infinite amounts of data representatively covering the whole space of possible inputs and outputs<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>. The challenge is to make the best out of a finite amount of training data, and to generalize these to new, unseen inputs. There is a vigorous trade-off between the amount, resolution and coverage of training data and the complexity of the model. Many models have continuous parameters that enable us to “tune” their complexity or the strength of their regularization. Cross-validation can help us with such tuning, although it is not a panacea, and caveats apply, as we saw in <a href="#sec-supervised-classifymousecells" class="quarto-xref"><span>Section&nbsp;12.6.3</span></a>.</p><div class="no-row-height column-margin column-container"><li id="fn11"><p><sup>11</sup>&nbsp;It would “just” be a formidable database / data management problem.</p></li></div></div>
</section>
<section id="further-reading" class="level2" data-number="12.9">
<h2 data-number="12.9" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">12.9</span> Further reading</h2>
<ul>
<li><p>An introduction to statistical learning that employs many concrete data examples and uses little mathematical formalism is given by <span class="citation" data-cites="James:2013">James et al. (<a href="16-chap.html#ref-James:2013" role="doc-biblioref">2013</a>)</span>. An extension, with more mathematical background, is the textbook by <span class="citation" data-cites="HastieTibshiraniFriedman">Hastie, Tibshirani, and Friedman (<a href="16-chap.html#ref-HastieTibshiraniFriedman" role="doc-biblioref">2008</a>)</span>.</p></li>
<li><p>The <a href="https://cran.r-project.org/web/views/MachineLearning.html">CRAN task view on machine learning</a> gives an overview over machine learning software in R.</p></li>
<li><p><a href="https://tensorflow.rstudio.com/keras">RStudio’s API for the “deep learning” platforms Keras and TensorFlow</a> and the associated teaching materials and demos are a good place to try out some of the recent developments in this field.</p></li>
</ul>
</section>
<section id="exercises" class="level2" data-number="12.10">
<h2 data-number="12.10" class="anchored" data-anchor-id="exercises"><span class="header-section-number">12.10</span> Exercises</h2>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-supervised-kernelsvm" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 12.1 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p>Apply a <em>kernel support vector machine</em>, available in the <strong><a href="https://cran.r-project.org/web/packages/kernlab/">kernlab</a></strong> package, to the <code>zeller</code> microbiome data. What kernel function works well?</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-supervised-glmnet" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 12.2 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p>Use <code>glmnet</code> for a <em>prediction of a continuous variable</em>, i.e., for regression. Use the prostate cancer data from Chapter 3 of <span class="citation" data-cites="HastieTibshiraniFriedman">(<a href="16-chap.html#ref-HastieTibshiraniFriedman" role="doc-biblioref">Hastie, Tibshirani, and Friedman 2008</a>)</span>. The data are available in the CRAN package <strong><a href="https://cran.r-project.org/web/packages/ElemStatLearn/">ElemStatLearn</a></strong>. Explore the effects of using ridge versus lasso penalty.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-supervised-smoothing" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 12.3 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p>Consider <em>smoothing as a regression and model selection problem</em> (remember <a href="#fig-overfitting-1" class="quarto-xref">Figure&nbsp;<span class="anchored-eq" data-anchor-id="eq-super">12.1</span></a>). What is the equivalent quantity to the penalization parameter <span class="math inline">\(\lambda\)</span> in <a href="#eq-super-penll" class="quarto-xref">Equation&nbsp;<span>12.8</span></a>? How do you choose it?</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-50-contents" aria-controls="callout-50" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-50" class="callout-50-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We refer to Chapter 5 of <span class="citation" data-cites="HastieTibshiraniFriedman">(<a href="16-chap.html#ref-HastieTibshiraniFriedman" role="doc-biblioref">Hastie, Tibshirani, and Friedman 2008</a>)</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-supervised-scale" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 12.4 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p><em>Scale invariance</em>. Consider a rescaling of one of the features in the (generalized) linear model <a href="#eq-super-deflogregress" class="quarto-xref"><span class="anchored-eq" data-anchor-id="eq-super">12.7</span></a>. For instance, denote the <span class="math inline">\(\nu\)</span>-th column of <span class="math inline">\(x\)</span> by <span class="math inline">\(x_{\cdot\nu}\)</span>, and suppose that <span class="math inline">\(p\ge2\)</span> and that we rescale <span class="math inline">\(x_{\cdot\nu} \mapsto s\, x_{\cdot\nu}\)</span> with some number <span class="math inline">\(s\neq0\)</span>. What will happen to the estimate <span class="math inline">\(\hat{\beta}\)</span> from <a href="#eq-super-penll" class="quarto-xref">Equation&nbsp;<span>12.8</span></a> in (a) the unpenalized case (<span class="math inline">\(\lambda=0\)</span>) and (b) the penalized case (<span class="math inline">\(\lambda&gt;0\)</span>)?</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-52-contents" aria-controls="callout-52" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-52" class="callout-52-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In the unpenalized case, the estimates will be scaled by <span class="math inline">\(1/s\)</span>, so that the resulting model is, in effect, the same. In the penalized case, the penalty from the <span class="math inline">\(\nu\)</span>-th component of <span class="math inline">\(\beta\)</span> will be different. If <span class="math inline">\(|s|&gt;1\)</span>, the amplitude of the feature is increased, smaller <span class="math inline">\(\beta\)</span>-components are required for it to have the same effect in the prediction, and therefore the feature is more likely to receive a non-zero and/or larger estimate, possibly on the cost of the other features; conversely for <span class="math inline">\(|s|&lt;1\)</span>. Regular linear regression is scale-invariant, whereas penalized regression is scale-dependent. It’s important to remember this when interpreting penalized model fits.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-supervised-quip" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 12.5 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p>It has been quipped that all classification methods are just refinements of <em>two archetypal ideas</em>: discriminant analysis and <span class="math inline">\(k\)</span> nearest neighbors. In what sense might that be a useful classification?</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-54-contents" aria-controls="callout-54" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-54" class="callout-54-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In linear discriminant analysis, we consider our objects as elements of <span class="math inline">\(\mathbb{R}^p\)</span>, and the learning task is to define regions in this space, or boundary hyperplanes between them, which we use to predict the class membership of new objects. This is archetypal for <em>classification by partition</em>. Generalizations of linear discriminant analysis permit more general spaces and more general boundary shapes.</p>
<p>In <span class="math inline">\(k\)</span> nearest neighbors, no embedding into a coordinate space is needed, but instead we require a distance (or dissimilarity) measure that can be computed between each pair of objects, and the classification decision for a new object depends on its distances to the training objects and their classes. This is archetypal for <em>kernel-based</em> methods.</p>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-ambroise2002selection" class="csl-entry" role="listitem">
Ambroise, Christophe, and Geoffrey J. McLachlan. 2002. <span>“<span>S</span>election Bias in Gene Extraction on the Basis of Microarray Gene-Expression Data.”</span> <em>PNAS</em> 99 (10): 6562–66.
</div>
<div id="ref-Bellman:1961" class="csl-entry" role="listitem">
Bellman, Richard Ernest. 1961. <em>Adaptive Control Processes: A Guided Tour</em>. Princeton University Press.
</div>
<div id="ref-clemmensen2012sparse" class="csl-entry" role="listitem">
Clemmensen, Line, Trevor Hastie, Daniela Witten, and Bjarne Ersbøll. 2011. <span>“Sparse Discriminant Analysis.”</span> <em>Technometrics</em> 53: 406–13.
</div>
<div id="ref-friedmanbiasvariance01" class="csl-entry" role="listitem">
Friedman, Jerome H. 1997. <span>“On Bias, Variance, 0/1—Loss, and the Curse-of-Dimensionality.”</span> <em>Data Mining and Knowledge Discovery</em> 1: 55–77.
</div>
<div id="ref-HastieTibshiraniFriedman" class="csl-entry" role="listitem">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2008. <em>The Elements of Statistical Learning</em>. 2^{\text{nd}} ed. Springer.
</div>
<div id="ref-Holmes2017" class="csl-entry" role="listitem">
Holmes, Susan. 2018. <span>“Statistical Proof? The Problem of Irreproducibility.”</span> <em>Bulletin of the AMS</em> 55 (1): 31–55.
</div>
<div id="ref-James:2013" class="csl-entry" role="listitem">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Springer.
</div>
<div id="ref-Neumann:2010" class="csl-entry" role="listitem">
Neumann, B., T. Walter, J. K. Heriche, J. Bulkescher, H. Erfle, C. Conrad, P. Rogers, et al. 2010. <span>“<span class="nocase"><span>P</span>henotypic profiling of the human genome by time-lapse microscopy reveals cell division genes</span>.”</span> <em>Nature</em> 464 (7289): 721–27.
</div>
<div id="ref-Ohnishi2014" class="csl-entry" role="listitem">
Ohnishi, Y., W. Huber, A. Tsumura, M. Kang, P. Xenopoulos, K. Kurimoto, A. K. Oles, et al. 2014. <span>“Cell-to-Cell Expression Variability Followed by Signal Reinforcement Progressively Segregates Early Mouse Lineages.”</span> <em>Nature Cell Biology</em> 16 (1): 27–37.
</div>
<div id="ref-diabetes" class="csl-entry" role="listitem">
Reaven, GM, and RG Miller. 1979. <span>“An Attempt to Define the Nature of Chemical Diabetes Using a Multidimensional Analysis.”</span> <em>Diabetologia</em> 16 (1): 17–24.
</div>
<div id="ref-witten2011penalized" class="csl-entry" role="listitem">
Witten, Daniela M, and Robert Tibshirani. 2011. <span>“Penalized Classification Using <span>F</span>isher’s Linear Discriminant.”</span> <em>JRSSB</em> 73 (5): 753–72.
</div>
<div id="ref-Zeller:MSB:2014" class="csl-entry" role="listitem">
Zeller, Georg, Julien Tap, Anita Y Voigt, Shinichi Sunagawa, Jens Roat Kultima, Paul I Costea, Aurélien Amiot, et al. 2014. <span>“<span>P</span>otential of Fecal Microbiota for Early-Stage Detection of Colorectal Cancer.”</span> <em>Molecular Systems Biology</em> 10 (11): 766. <a href="https://doi.org/10.15252/msb.20145645">https://doi.org/10.15252/msb.20145645</a>.
</div>
</div>
</section>
<aside id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>











</ol>
</aside>

<p>Page built on 2023-08-03 21:37:40.884902 using R version 4.3.0 (2023-04-21)</p></main> <!-- /main --></p><p class="build-date">
Support for maintaining the online version of this book is provided by <a href="http://www.denbi.de">de.NBI</a>
  <img src="imgs/denbi.png" style="vertical-align: text-top;height: 16px"><br>
For website support please contact msmith@embl.de
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS_eq = new window.AnchorJS();
  anchorJS_eq.options = {
    placement: 'left',
    class: 'eq-link',
    icon: icon
  };
  anchorJS_eq.add('.anchored-eq');
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>
