<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.54">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Modern Statistics for Modern Biology - 6&nbsp; Testing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./imgs/msmb-favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="msmb.css">
<meta property="og:title" content="Modern Statistics for Modern Biology - 6&nbsp; Testing">
<meta property="og:description" content="If you are a biologist and want to get the best out of the powerful methods of modern computational statistics, this is your book.">
<meta property="og:image" content="https://www.huber.embl.de/msmb-quarto/imgs/MSFMB-Cover2-cropped.jpg">
<meta property="og:site-name" content="Modern Statistics for Modern Biology">
<meta name="twitter:title" content="Modern Statistics for Modern Biology - 6&nbsp; Testing">
<meta name="twitter:description" content="If you are a biologist and want to get the best out of the powerful methods of modern computational statistics, this is your book.">
<meta name="twitter:image" content="https://www.huber.embl.de/msmb-quarto/imgs/MSFMB-Cover2-cropped.jpg">
<meta name="twitter:card" content="summary">
<script type="text/javascript">
  var _paq = _paq || [];
  
  // Call disableCookies before calling trackPageView 
  _paq.push(['disableCookies']);
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u='//tr-denbi.embl.de/heimdall/';
    _paq.push(['setTrackerUrl', u+'p.php']);
    _paq.push(['setSiteId', '26']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'p.js'; s.parentNode.insertBefore(g,s);
  })();
</script>

</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Modern Statistics for Modern Biology</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-chapters" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Chapters</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-chapters">    
        <li>
    <a class="dropdown-item" href="./index.html" rel="" target="">
 <span class="dropdown-text">Home</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./00-chap.html" rel="" target="">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./01-chap.html" rel="" target="">
 <span class="dropdown-text">Generative Models for Discrete Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./02-chap.html" rel="" target="">
 <span class="dropdown-text">Statistical Modeling</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./03-chap.html" rel="" target="">
 <span class="dropdown-text">High Quality Graphics in R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./04-chap.html" rel="" target="">
 <span class="dropdown-text">Mixture Models</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./05-chap.html" rel="" target="">
 <span class="dropdown-text">Clustering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./06-chap.html" rel="" target="">
 <span class="dropdown-text">Testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./07-chap.html" rel="" target="">
 <span class="dropdown-text">Multivariate Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./08-chap.html" rel="" target="">
 <span class="dropdown-text">High-Throughput Count Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./09-chap.html" rel="" target="">
 <span class="dropdown-text">Multivariate methods for heterogeneous data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./10-chap.html" rel="" target="">
 <span class="dropdown-text">Networks and Trees</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./11-chap.html" rel="" target="">
 <span class="dropdown-text">Image data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./12-chap.html" rel="" target="">
 <span class="dropdown-text">Supervised Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./13-chap.html" rel="" target="">
 <span class="dropdown-text">Design of High Throughput Experiments and their Analyses</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./14-chap.html" rel="" target="">
 <span class="dropdown-text">Statistical Concordance</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./15-chap.html" rel="" target="">
 <span class="dropdown-text">Acknowledgements</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./16-chap.html" rel="" target="">
 <span class="dropdown-text">References</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Testing</span></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sections</h2>
   
  <ul class="collapse">
  <li><a href="#goals-for-this-chapter" id="toc-goals-for-this-chapter" class="nav-link active" data-scroll-target="#goals-for-this-chapter"><span class="header-section-number">6.1</span> Goals for this Chapter</a></li>
  <li><a href="#sec-cointossing" id="toc-sec-cointossing" class="nav-link" data-scroll-target="#sec-cointossing"><span class="header-section-number">6.2</span> An example: coin tossing</a></li>
  <li><a href="#sec-fivesteps" id="toc-sec-fivesteps" class="nav-link" data-scroll-target="#sec-fivesteps"><span class="header-section-number">6.3</span> The five steps of hypothesis testing</a></li>
  <li><a href="#sec-testing-typesoferror" id="toc-sec-testing-typesoferror" class="nav-link" data-scroll-target="#sec-testing-typesoferror"><span class="header-section-number">6.4</span> Types of error</a></li>
  <li><a href="#sec-testing-ttest" id="toc-sec-testing-ttest" class="nav-link" data-scroll-target="#sec-testing-ttest"><span class="header-section-number">6.5</span> The t-test</a></li>
  <li><a href="#sec-pvaluehack" id="toc-sec-pvaluehack" class="nav-link" data-scroll-target="#sec-pvaluehack"><span class="header-section-number">6.6</span> P-value hacking</a></li>
  <li><a href="#multiple-testing" id="toc-multiple-testing" class="nav-link" data-scroll-target="#multiple-testing"><span class="header-section-number">6.7</span> Multiple testing</a></li>
  <li><a href="#sec-testing-FWER" id="toc-sec-testing-FWER" class="nav-link" data-scroll-target="#sec-testing-FWER"><span class="header-section-number">6.8</span> The family wise error rate</a></li>
  <li><a href="#the-false-discovery-rate" id="toc-the-false-discovery-rate" class="nav-link" data-scroll-target="#the-false-discovery-rate"><span class="header-section-number">6.9</span> The false discovery rate</a></li>
  <li><a href="#sec-testing-localfdr" id="toc-sec-testing-localfdr" class="nav-link" data-scroll-target="#sec-testing-localfdr"><span class="header-section-number">6.10</span> The local FDR</a></li>
  <li><a href="#independent-hypothesis-weighting" id="toc-independent-hypothesis-weighting" class="nav-link" data-scroll-target="#independent-hypothesis-weighting"><span class="header-section-number">6.11</span> Independent hypothesis weighting</a></li>
  <li><a href="#summary-of-this-chapter" id="toc-summary-of-this-chapter" class="nav-link" data-scroll-target="#summary-of-this-chapter"><span class="header-section-number">6.12</span> Summary of this chapter</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading"><span class="header-section-number">6.13</span> Further reading</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">6.14</span> Exercises</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-testing" class="quarto-section-identifier"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Testing</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/xkcdmulttest-newspapertitle_b7e76a4e16666ced0cbef293cda054f4">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/xkcdmulttest-newspapertitle.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div></div></div>
<p>Hypothesis testing is one of the workhorses of science. It is how we can draw conclusions or make decisions based on finite samples of data. For instance, new treatments for a disease are usually approved on the basis of clinical trials that aim to decide whether the treatment has better efficacy compared to the other available options, and an acceptable trade-off of side effects. Such trials are expensive and can take a long time. Therefore, the number of patients we can enroll is limited, and we need to base our inference on a limited sample of observed patient responses. The data are noisy, since a patient’s response depends not only on the treatment, but on many other factors outside of our control. The sample size needs to be large enough to enable us to make a reliable conclusion. On the other hand, it also must not be too large, so that we do not waste precious resources or time, e.g., by making drugs more expensive than necessary, or by denying patients that would benefit from the new drug access to it. The machinery of hypothesis testing was developed largely with such applications in mind, although today it is used much more widely.</p>
<div class="page-columns page-full"><p>In biological data analysis (and in many other fields<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>) we see hypothesis testing applied to screen thousands or millions of possible hypotheses to find the ones that are worth following up. For instance, researchers screen genetic variants for associations with a phenotype, or gene expression levels for associations with disease. Here, “worthwhile” is often interpreted as “statistically significant”, although the two concepts are clearly not the same. It is probably fair to say that statistical significance is a necessary condition for making a data-driven decision to find something interesting, but it’s clearly not sufficient. In any case, such large-scale association screening is closely related to multiple hypothesis testing.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Detecting credit card fraud, email spam detection, <span class="math inline">\(...\)</span></p></li></div></div>
<section id="goals-for-this-chapter" class="level2 page-columns page-full" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="goals-for-this-chapter"><span class="header-section-number">6.1</span> Goals for this Chapter</h2>
<p>In this chapter we will:</p>
<ul>
<li><p>Familiarize ourselves with the statistical machinery of hypothesis testing, its vocabulary, its purpose, and its strengths and limitations.</p></li>
<li><p>Understand what multiple testing means.</p></li>
<li><p>See that multiple testing is not a problem – but rather, an opportunity, as it overcomes many of the limitations of single testing.</p></li>
<li><p>Understand the false discovery rate.</p></li>
<li><p>Learn how to make diagnostic plots.</p></li>
<li><p>Use hypothesis weighting to increase the power of our analyses.</p></li>
</ul>
<section id="drinking-from-the-firehose" class="level3 page-columns page-full" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="drinking-from-the-firehose"><span class="header-section-number">6.1.1</span> Drinking from the firehose</h3>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-active-substance-discovery-robot-screening-robot_d5d9c39e12bf13b1c7e1bb62c011fec1">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-active-substance-discovery-robot-screening-robot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="imgs/active-substance-discovery-robot-screening-robot.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;6.1: High-throughput data in modern biology are screened for associations with millions of hypothesis tests. (<a href="https://www.research.bayer.com/en/automated-search-for-active-ingredients-with-robots.aspx">Source: Bayer</a>)</figcaption>
</figure>
</div>
</div></div></div>
<p>If statistical testing—decision making with uncertainty—seems a hard task when making a single decision, then brace yourself: in genomics, or more generally with “big data”, we need to accomplish it not once, but thousands or millions of times. In <a href="02-chap.html" class="quarto-xref"><span>Chapter&nbsp;2</span></a>, we saw the example of epitope detection and the challenges from considering not only one, but several positions. Similarly, in whole genome sequencing, we scan every position in the genome for a difference between the DNA library at hand and a reference (or, another library): that’s in the order of six billion tests if we are looking at human data! In genetic or chemical compound screening, we test each of the reagents for an effect in the assay, compared to a control: that’s again tens of thousands, if not millions of tests. In <a href="08-chap.html" class="quarto-xref"><span>Chapter&nbsp;8</span></a>, we will analyse RNA-Seq data for differential expression by applying a hypothesis test to each of the thousands of genes assayed.</p>
</section>
<section id="testing-versus-classification" class="level3" data-number="6.1.2">
<h3 data-number="6.1.2" class="anchored" data-anchor-id="testing-versus-classification"><span class="header-section-number">6.1.2</span> Testing versus classification</h3>
<p>Suppose we measured the expression level of a marker gene to decide whether some cells we are studying are from cell type A or B. First, let’s consider that we have no prior assumption, and it’s equally important to us to get the assignment right no matter whether the true cell type is A or B. This is a <em>classification</em> task. We’ll cover classification in <a href="12-chap.html" class="quarto-xref"><span>Chapter&nbsp;12</span></a>. In this chapter, we consider the asymmetric case: based on what we already know (we could call this our <em>prior</em> knowledge), we lean towards conservatively calling any cell A, unless there is strong enough evidence for the alternative. Or maybe class B is interesting, rare, and/or worthwhile studying further, whereas A is a “catch-all” class for all the boring rest. In such cases, the machinery of hypothesis testing is for us.</p>
<p>Formally, there are many similarities between hypothesis testing and classification. In both cases, we aim to use data to choose between several possible decisions. It is even possible to think of hypothesis testing as a special case of classification. However, these two approaches are geared towards different objectives and underlying assumptions, and when you encounter a statistical decision problem, it is good to keep that in mind in your choice of methodology.</p>
</section>
<section id="false-discovery-rate-versus-p-value-which-is-more-intuitive" class="level3 page-columns page-full" data-number="6.1.3">
<h3 data-number="6.1.3" class="anchored" data-anchor-id="false-discovery-rate-versus-p-value-which-is-more-intuitive"><span class="header-section-number">6.1.3</span> False discovery rate versus p-value: which is more intuitive?</h3>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-FDRvspstatic1_61e5bed364b853f1c809f75865c1579b">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-FDRvspstatic1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-FDRvspstatic1-1.png" class="img-fluid figure-img" width="448"></p>
<figcaption class="figure-caption">Figure&nbsp;6.2: Making a binary (yes/no) decision. Here, we call the two possible decisions “positive” and “negative” based on some continuous-valued score <span class="math inline">\(x\)</span>, shown along the <span class="math inline">\(x\)</span>-axis. The curve shaded in blue shows the distribution density of <span class="math inline">\(x\)</span> for one of the classes (the negatives), the curve shaded in red, for the other class (the positives). The distributions are distinctive (the red values are generally lower), but have some overlap. The vertical black bar marks some choice of a decision boundary, which results in four possible outcomes highlighted by the color key.</figcaption>
</figure>
</div>
</div></div></div>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-FDRvspstatic2_89cd0d3bb28f75f09fe339342018b71b">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-FDRvspstatic2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-FDRvspstatic2-1.png" class="img-fluid figure-img" width="448"></p>
<figcaption class="figure-caption">Figure&nbsp;6.3: Analogous to <a href="#fig-testing-FDRvspstatic1" class="quarto-xref">Figure&nbsp;<span class="anchored-eq" data-anchor-id="eq-testing">6.2</span></a>, but now we have transformed <span class="math inline">\(x\)</span> from its original range to the range <span class="math inline">\([0,1]\)</span> using a non-linear, strictly increasing transformation function <span class="math inline">\(p=f(x)\)</span>, which we chose such that the resulting blue distribution is uniform. Such a function always exists: it is the cumulative distribution function of <span class="math inline">\(x\)</span> (we have seen it in <a href="03-chap.html#sec-graphics-ecdf" class="quarto-xref"><span>Section&nbsp;3.6.7</span></a>). We call the result a <strong>p-value</strong>. The definition of the FDR in <a href="#eq-testing-simplefdr" class="quarto-xref">Equation&nbsp;<span>6.2</span></a> applies equally well in <a href="#fig-testing-FDRvspstatic1" class="quarto-xref">Figure&nbsp;<span>6.2</span></a> and here.</figcaption>
</figure>
</div>
</div></div></div>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-FDRvspanim_f549db583d20cb07afc393f75484cd50">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-FDRvspanim" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-FDRvspanim-1.gif" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;6.4: The animation highlights the analogies between using a generic score <span class="math inline">\(x\)</span> (as in <a href="#fig-testing-FDRvspstatic1" class="quarto-xref">Figure&nbsp;<span>6.2</span></a>) and a p-value from a formal hypothesis test (as in <a href="#fig-testing-FDRvspstatic2" class="quarto-xref">Figure&nbsp;<span>6.3</span></a>) for decision making. We will come back to these concepts in terms of the two-group model in <a href="#sec-testing-localfdr" class="quarto-xref"><span>Section&nbsp;6.10</span></a> and <a href="#fig-testing-lfdr" class="quarto-xref">Figure&nbsp;<span>6.16</span></a>.</figcaption>
</figure>
</div>
</div></div></div>
<p>Hypothesis testing has traditionally been taught with p-values first—introducing them as the primal, basic concept. Multiple testing and false discovery rates are then presented as derived, additional ideas. There are good mathematical and practical reasons for doing so, and the rest of this chapter follows this tradition. However, in this prefacing section we would like to point out that it can be more intuitive and more pedagogical to revert the order, and learn about false discovery rates first and think of p-values as an imperfect proxy.</p>
<div class="page-columns page-full"><p>Consider <a href="#fig-testing-FDRvspstatic1" class="quarto-xref">Figure&nbsp;<span>6.2</span></a>, which represents a binary decision problem. Let’s say we call a <em>discovery</em> whenever the summary statistic <span class="math inline">\(x\)</span> is particularly small, i.e., when it falls to the left of the vertical black bar<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Then the <em>false discovery rate</em><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> (FDR) is simply the fraction of false discoveries among all discoveries, i.e.:</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;This is “without loss of generality”: we could also flip the <span class="math inline">\(x\)</span>-axis and call something with a high score a discovery.</p></li><li id="fn3"><p><sup>3</sup>&nbsp;This is a rather informal definition. For more precise definitions, see for instance <span class="citation" data-cites="Storey:AnnStat:2003 Efron2010">(<a href="16-chap.html#ref-Storey:AnnStat:2003" role="doc-biblioref">Storey 2003</a>; <a href="16-chap.html#ref-Efron2010" role="doc-biblioref">Efron 2010</a>)</span> and <a href="#sec-testing-localfdr" class="quarto-xref"><span>Section&nbsp;6.10</span></a>.</p></li></div></div>
<p><span class="anchored-eq" data-anchor-id="eq-testing" id="eq-testing-simplefdr"><span class="math display">\[
\text{FDR}=\frac{\text{area shaded in light blue}}{\text{sum of the areas left of the vertical bar (light blue + strong red)}}.
\tag{6.1}\]</span></span></p>
<p>The FDR depends not only on the position of the decision threshold (the vertical bar), but also on the shape and location of the two distributions, and on their relative sizes. In Figures <a href="#fig-testing-FDRvspstatic1" class="quarto-xref"><span>6.2</span></a> and <a href="#fig-testing-FDRvspstatic2" class="quarto-xref"><span>6.3</span></a>, the overall blue area is twice as big as the overall red area, reflecting the fact that the blue class is (in this example) twice as prevalent (or: a priori, twice as likely) as the red class.</p>
<p>Note that this definition does not require the concept or even the calculation of a p-value. It works for any arbitrarily defined score <span class="math inline">\(x\)</span>. However, it requires knowledge of three things:</p>
<ol type="1">
<li><p>the distribution of <span class="math inline">\(x\)</span> in the blue class (the blue curve),</p></li>
<li><p>the distribution of <span class="math inline">\(x\)</span> in the red class (the red curve),</p></li>
<li><p>the relative sizes of the blue and the red classes.</p></li>
</ol>
<p>If we know these, then we are basically done at this point; or we can move on to supervised classification in <a href="12-chap.html" class="quarto-xref"><span>Chapter&nbsp;12</span></a>, which deals with the extension of <a href="#fig-testing-FDRvspstatic1" class="quarto-xref">Figure&nbsp;<span>6.2</span></a> to multivariate <span class="math inline">\(x\)</span>.</p>
<p>Very often, however, we do not know all of these, and this is the realm of hypothesis testing. In particular, suppose that one of the two classes (say, the blue one) is easier than the other, and we can figure out its distribution, either from first principles or simulations. We use that fact to transform our score <span class="math inline">\(x\)</span> to a standardized range between 0 and 1 (see Figures <a href="#fig-testing-FDRvspstatic1" class="quarto-xref"><span>6.2</span></a>—<a href="#fig-testing-FDRvspanim" class="quarto-xref"><span>6.4</span></a>), which we call the <em>p-value</em>. We give the class a fancier name: <em>null hypothesis</em>. This addresses Point 1 in the above list. We do not insist on knowing Point 2 (and we give another fancy name, <em>alternative hypothesis</em>, to the red class). As for Point 3, we can use the conservative upper limit that the null hypothesis is far more prevalent (or: likely) than the alternative and do our calculations under the condition that the null hypothesis is true. This is the traditional approach to hypothesis testing.</p>
<p>Thus, instead of basing our decision-making on the intuitive FDR (<a href="#eq-testing-simplefdr" class="quarto-xref">Equation&nbsp;<span>6.2</span></a>), we base it on the</p>
<p><span class="anchored-eq" data-anchor-id="eq-testing" id="eq-testing-simplefdr"><span class="math display">\[
\text{p-value}=\frac{\text{area shaded in light blue}}{\text{overall blue area}}.
\tag{6.2}\]</span></span></p>
<p>In other words, the p-value is the precise and often relatively easy-to-compute answer to a rather convoluted question (and perhaps the wrong question). The FDR answers the right question, but requires a lot more input, which we often do not have.</p>
</section>
<section id="the-multiple-testing-opportunity" class="level3" data-number="6.1.4">
<h3 data-number="6.1.4" class="anchored" data-anchor-id="the-multiple-testing-opportunity"><span class="header-section-number">6.1.4</span> The multiple testing opportunity</h3>
<p>Here is the good news about multiple testing: even if we do not know Items 2 and 3 from the bullet list above explicitly for our tests (and perhaps even if we are unsure about Point 1 <span class="citation" data-cites="Efron2010">(<a href="16-chap.html#ref-Efron2010" role="doc-biblioref">Efron 2010</a>)</span>), we may be able to infer this information from the multiplicity—and thus convert p-values into estimates of the FDR!</p>
<p>Thus, multiple testing tends to make our inference better, and our task simpler. Since we have so much data, we do not only have to rely on abstract assumptions. We can check empirically whether the requirements of the tests are actually met by the data. All this can be incredibly helpful, and we get it <em>because</em> of the multiplicity. So we should think about multiple testing not as a “problem” or a “burden”, but as an opportunity!</p>
</section>
</section>
<section id="sec-cointossing" class="level2 page-columns page-full" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="sec-cointossing"><span class="header-section-number">6.2</span> An example: coin tossing</h2>
<div class="page-columns page-full"><p>So now let’s dive into hypothesis testing, starting with single testing. To really understand the mechanics, we use one of the simplest possible examples: suppose we are flipping a coin to see if it is fair<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. We flip the coin 100 times and each time record whether it came up heads or tails. So, we have a record that could look something like this:</p><div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;We don’t look at coin tossing because it’s inherently important, but because it is an easy “model system” (just as we use model systems in biology): everything can be calculated easily, and you do not need a lot of domain knowledge to understand what coin tossing is. All the important concepts come up, and we can apply them, only with more additional details, to other applications.</p></li></div></div>
<center>
HHTTHTHTT…
</center>
<p>which we can simulate in R. Let’s assume we are flipping a biased coin, so we set <code>probHead</code> different from 1/2:</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/whatprob1_ab2908e13f1dd9d10b4107991f32fa7d">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0xdada</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>numFlips <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>probHead <span class="ot">=</span> <span class="fl">0.6</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>coinFlips <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">"H"</span>, <span class="st">"T"</span>), <span class="at">size =</span> numFlips,</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(probHead, <span class="dv">1</span> <span class="sc">-</span> probHead))</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(coinFlips)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "T" "T" "H" "T" "H" "H"</code></pre>
</div>
</div>
<p>Now, if the coin were fair, we would expect half of the time to get heads. Let’s see.</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/tableCoinFlips_d54e8746692f6853da8479448fd1acd7">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(coinFlips)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>coinFlips
 H  T 
59 41 </code></pre>
</div>
</div>
<div class="page-columns page-full"><p>So that is different from 50/50. Suppose we showed the data to a friend without telling them whether the coin is fair, and their prior assumption, i.e., their null hypothesis, is that coins are, by and large, fair. Would the data be strong enough to make them conclude that this coin isn’t fair? They know that random sampling differences are to be expected. To decide, let’s look at the sampling distribution of our test statistic – the total number of heads seen in 100 coin tosses – for a fair coin<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. As we saw in <a href="01-chap.html" class="quarto-xref"><span>Chapter&nbsp;1</span></a>, the number, <span class="math inline">\(k\)</span>, of heads, in <span class="math inline">\(n\)</span> independent tosses of a coin is</p><div class="no-row-height column-margin column-container"><li id="fn5"><p><sup>5</sup>&nbsp;We haven’t really defined what we mean be fair – a reasonable definition would be that head and tail are equally likely, and that the outcome of each coin toss does not depend on the previous ones. For more complex applications, nailing down the most suitable null hypothesis can take some thought.</p></li></div></div>
<p><span class="anchored-eq" data-anchor-id="eq-testing" id="eq-testing-dbinom"><span class="math display">\[
P(K=k\,|\,n, p) = \left(\begin{array}{c}n\\k\end{array}\right) p^k\;(1-p)^{n-k},
\tag{6.3}\]</span></span></p>
<div class="page-columns page-full"><p>where <span class="math inline">\(p\)</span> is the probability of heads (0.5 if we assume a fair coin). We read the left hand side of the above equation as “the probability that the observed value for <span class="math inline">\(K\)</span> is <span class="math inline">\(k\)</span>, given the values of <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>”. Statisticians like to make a difference between all the possible values of a statistic and the one that was observed<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, and we use the upper case <span class="math inline">\(K\)</span> for the possible values (so <span class="math inline">\(K\)</span> can be anything between 0 and 100), and the lower case <span class="math inline">\(k\)</span> for the observed value.</p><div class="no-row-height column-margin column-container"><li id="fn6"><p><sup>6</sup>&nbsp;In other words, <span class="math inline">\(K\)</span> is the abstract random variable in our probabilistic model, whereas <span class="math inline">\(k\)</span> is its realization, that is, a specific data point.</p></li></div></div>
<p>We plot <a href="#eq-testing-dbinom" class="quarto-xref">Equation&nbsp;<span>6.3</span></a> in <a href="#fig-testing-dbinom" class="quarto-xref">Figure&nbsp;<span>6.5</span></a>; for good measure, we also mark the observed value <code>numHeads</code> with a vertical blue line.</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/binomDens_3141124995a398a7e88f6fe213d01c45">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"dplyr"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>k <span class="ot">=</span> <span class="dv">0</span><span class="sc">:</span>numFlips</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>numHeads <span class="ot">=</span> <span class="fu">sum</span>(coinFlips <span class="sc">==</span> <span class="st">"H"</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>binomDensity <span class="ot">=</span> <span class="fu">tibble</span>(<span class="at">k =</span> k,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">p =</span> <span class="fu">dbinom</span>(k, <span class="at">size =</span> numFlips, <span class="at">prob =</span> <span class="fl">0.5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-dbinom_d7d818016658ba81172266cdb120ab0c">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"ggplot2"</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(binomDensity) <span class="sc">+</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">x =</span> k, <span class="at">y =</span> p), <span class="at">stat =</span> <span class="st">"identity"</span>) <span class="sc">+</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> numHeads, <span class="at">col =</span> <span class="st">"blue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-dbinom" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-dbinom-1.png" class="img-fluid figure-img" width="280"></p>
<figcaption class="figure-caption">Figure&nbsp;6.5: The binomial distribution for the parameters <span class="anchored-eq" data-anchor-id="eq-testing" class="math inline">\(n=100\)</span> and <span class="math inline">\(p=0.5\)</span>, according to <a href="#eq-testing-dbinom" class="quarto-xref">Equation&nbsp;<span>6.3</span></a>.</figcaption>
</figure>
</div>
</div></div></div>
<p>Suppose we didn’t know about <a href="#eq-testing-dbinom" class="quarto-xref">Equation&nbsp;<span>6.3</span></a>. We can still use Monte Carlo simulation to give us something to compare with:</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-rbinom_b32d8cbf12965834bf4abd4174600f3a">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>numSimulations <span class="ot">=</span> <span class="dv">10000</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>outcome <span class="ot">=</span> <span class="fu">replicate</span>(numSimulations, {</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  coinFlips <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">"H"</span>, <span class="st">"T"</span>), <span class="at">size =</span> numFlips,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(coinFlips <span class="sc">==</span> <span class="st">"H"</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(outcome)) <span class="sc">+</span> <span class="fu">xlim</span>(<span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">100.5</span>) <span class="sc">+</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> outcome), <span class="at">binwidth =</span> <span class="dv">1</span>, <span class="at">center =</span> <span class="dv">50</span>) <span class="sc">+</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> numHeads, <span class="at">col =</span> <span class="st">"blue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-rbinom" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-rbinom-1.png" class="img-fluid figure-img" width="280"></p>
<figcaption class="figure-caption">Figure&nbsp;6.6: An approximation of the binomial distribution from <span class="math inline">\(10000\)</span> simulations (same parameters as <a href="#fig-testing-dbinom" class="quarto-xref">Figure&nbsp;<span>6.5</span></a>).</figcaption>
</figure>
</div>
</div></div></div>
<div class="page-columns page-full"><p>As expected, the most likely number of heads is 50, that is, half the number of coin flips. But we see that other numbers near 50 are also quite likely. How do we quantify whether the observed value, 59, is among those values that we are likely to see from a fair coin, or whether its deviation from the expected value is already large enough for us to conclude with enough confidence that the coin is biased? We divide the set of all possible <span class="math inline">\(k\)</span> (0 to 100) in two complementary subsets, the <strong>rejection region</strong> and the region of no rejection. Our choice here<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> is to fill up the rejection region with as many <span class="math inline">\(k\)</span> as possible while keeping their total probability, assuming the null hypothesis, below some threshold <span class="math inline">\(\alpha\)</span> (say, 0.05).</p><div class="no-row-height column-margin column-container"><li id="fn7"><p><sup>7</sup>&nbsp;More on this in <a href="#sec-testing-rejectionregion" class="quarto-xref"><span>Section&nbsp;6.3.1</span></a>.</p></li></div></div>
<p>In the code below, we use the function <code>arrange</code> from the <strong><a href="https://cran.r-project.org/web/packages/dplyr/">dplyr</a></strong> package to sort the p-values from lowest to highest, then pass the result to <code>mutate</code>, which adds another dataframe column <code>reject</code> that is defined by computing the cumulative sum (<code>cumsum</code>) of the p-values and thresholding it against <code>alpha</code>. The logical vector <code>reject</code> therefore marks with <code>TRUE</code> a set of <code>k</code>s whose total probability is less than <code>alpha</code>. These are marked in <a href="#fig-testing-findrej" class="quarto-xref">Figure&nbsp;<span>6.7</span></a>, and we can see that our rejection region is not contiguous – it comprises both the very large and the very small values of <code>k</code>.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-findrej_e84413ef29f7e53a65359d404f3b314d">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"dplyr"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">=</span> <span class="fl">0.05</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>binomDensity <span class="ot">=</span> <span class="fu">arrange</span>(binomDensity, p) <span class="sc">|&gt;</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">reject =</span> (<span class="fu">cumsum</span>(p) <span class="sc">&lt;=</span> alpha))</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(binomDensity) <span class="sc">+</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">x =</span> k, <span class="at">y =</span> p, <span class="at">col =</span> reject), <span class="at">stat =</span> <span class="st">"identity"</span>) <span class="sc">+</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_colour_manual</span>(</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">`</span><span class="at">TRUE</span><span class="st">`</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">`</span><span class="at">FALSE</span><span class="st">`</span> <span class="ot">=</span> <span class="st">"darkgrey"</span>)) <span class="sc">+</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> numHeads, <span class="at">col =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-findrej" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-findrej-1.png" class="img-fluid figure-img" width="280"></p>
<figcaption class="figure-caption">Figure&nbsp;6.7: As <a href="#fig-testing-dbinom" class="quarto-xref">Figure&nbsp;<span>6.5</span></a>, with rejection region (red) that has been chosen such that it contains the maximum number of bins whose total area is at most <span class="math inline">\(\alpha=0.05\)</span>.</figcaption>
</figure>
</div>
</div></div></div>
<p>The explicit summation over the probabilities is clumsy, we did it here for pedagogic value. For one-dimensional distributions, R provides not only functions for the densities (e.g., <code>dbinom</code>) but also for the cumulative distribution functions (<code>pbinom</code>), which are more precise and faster than <code>cumsum</code> over the probabilities. These should be used in practice.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<p>Do the computations for the rejection region and produce a plot like <a href="#fig-testing-findrej" class="quarto-xref">Figure&nbsp;<span>6.7</span></a> without using <code>dbinom</code> and <code>cumsum</code>, and with using <code>pbinom</code> instead.</p>
</div>
</div>
<p>We see in <a href="#fig-testing-findrej" class="quarto-xref">Figure&nbsp;<span>6.7</span></a> that the observed value, 59, lies in the grey shaded area, so we would <em>not</em> reject the null hypothesis of a fair coin from these data at a significance level of <span class="math inline">\(\alpha=0.05\)</span>.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-norejectnopower" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.1 </strong></span>Does the fact that we don’t reject the null hypothesis mean that the coin is fair?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-moretossing" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.2 </strong></span>Would we have a better chance of detecting that the coin is not fair if we did more coin tosses? How many?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-rejectreproduce" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.3 </strong></span>If we repeated the whole procedure and again tossed the coin 100 times, might we <em>then</em> reject the null hypothesis?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-rejectionregionasymmetric" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.4 </strong></span>The rejection region in <a href="#fig-testing-findrej" class="quarto-xref">Figure&nbsp;<span>6.7</span></a> is asymmetric – its left part ends with <span class="math inline">\(k=40\)</span>, while its right part starts with <span class="math inline">\(k=61\)</span>. Why is that? Which other ways of defining the rejection region might be useful?</p>
</div>
</div>
</div>
<p>We have just gone through the steps of a binomial test. In fact, this is such a frequent activity in R that it has been wrapped into a single function, and we can compare its output to our results.</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/binom.test_9b255b576b80d5015571b3141cd54b2d">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.test</span>(<span class="at">x =</span> numHeads, <span class="at">n =</span> numFlips, <span class="at">p =</span> <span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Exact binomial test

data:  numHeads and numFlips
number of successes = 59, number of trials = 100, p-value = 0.08863
alternative hypothesis: true probability of success is not equal to 0.5
95 percent confidence interval:
 0.4871442 0.6873800
sample estimates:
probability of success 
                  0.59 </code></pre>
</div>
</div>
</section>
<section id="sec-fivesteps" class="level2 page-columns page-full" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="sec-fivesteps"><span class="header-section-number">6.3</span> The five steps of hypothesis testing</h2>
<p>Let’s summarise the general principles of hypothesis testing:</p>
<ol type="1">
<li><p>Decide on the effect that you are interested in, design a suitable experiment or study, pick a data summary function and <strong>test statistic</strong>.</p></li>
<li><p>Set up a <strong>null hypothesis</strong>, which is a simple, computationally tractable model of reality that lets you compute the <strong>null distribution</strong>, i.e., the possible outcomes of the test statistic and their probabilities under the assumption that the null hypothesis is true.</p></li>
<li><p>Decide on the <strong>rejection region</strong>, i.e., a subset of possible outcomes whose total probability is small<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>.</p></li>
<li><p>Do the experiment and collect the data<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>; compute the test statistic.</p></li>
<li><p>Make a decision: reject the null hypothesis<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> if the test statistic is in the rejection region.</p></li>
</ol>
<div class="no-row-height column-margin column-container"><li id="fn8"><p><sup>8</sup>&nbsp;More on this in <a href="#sec-testing-rejectionregion" class="quarto-xref"><span>Section&nbsp;6.3.1</span></a>.</p></li><li id="fn9"><p><sup>9</sup>&nbsp;Or if someone else has already done it, download their data.</p></li><li id="fn10"><p><sup>10</sup>&nbsp;That is, conclude that it is unlikely to be true.</p></li></div><p>Note how in this idealized workflow, we make all the important decisions in Steps 1–3 before we have even seen the data. As we already alluded to in the Introduction (Figures <a href="00-chap.html#fig-Fisher" class="quarto-xref"><span>1</span></a> and <a href="00-chap.html#fig-iterative" class="quarto-xref"><span>2</span></a>), this is often not realistic. We will also come back to this question in <a href="#sec-pvaluehack" class="quarto-xref"><span>Section&nbsp;6.6</span></a>.</p>
<p>There was also idealization in our null hypothesis that we used in the example above: we postulated that a fair coin should have a probability of exactly 0.5 (not, say, 0.500001) and that there should be absolutely no dependence between tosses. We did not worry about any possible effects of air drag, elasticity of the material on which the coin falls, and so on. This gave us the advantage that the null hypothesis was computationally tractable, namely, with the binomial distribution. Here, these idealizations may not seem very controversial, but in other situations the trade-off between how tractable and how realistic a null hypothesis is can be more substantial. The problem is that if a null hypothesis is too idealized to start with, rejecting it is not all that interesting. The result may be misleading, and certainly we are wasting our time.</p>
<p>The test statistic in our example was the total number of heads. Suppose we observed 50 tails in a row, and then 50 heads in a row. Our test statistic ignores the order of the outcomes, and we would conclude that this is a perfectly fair coin. However, if we used a different test statistic, say, the number of times we see two tails in a row, we might notice that there is something funny about this coin.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-nulltailspairs" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.5 </strong></span>What is the null distribution of this different test statistic?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-tailspairsalwaysbetter" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.6 </strong></span>Would a test based on that statistic be generally preferable?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>No, while it has more power to detect such correlations between coin tosses, it has <em>less</em> power to detect bias in the outcome.</p>
</div>
</div>
</div>
<p>What we have just done is look at two different classes of <strong>alternative hypotheses</strong>. The first class of alternatives was that subsequent coin tosses are still independent of each other, but that the probability of heads differed from 0.5. The second one was that the overall probability of heads may still be 0.5, but that subsequent coin tosses were correlated.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-totalnumberheadssufficient" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.7 </strong></span>Recall the concept of sufficient statistics from <a href="01-chap.html" class="quarto-xref"><span>Chapter&nbsp;1</span></a>. Is the total number of heads a sufficient statistic for the binomial distribution? Why might it be a good test statistic for our first class of alternatives, but not for the second?</p>
</div>
</div>
</div>
<div class="page-columns page-full"><p>So let’s remember that we typically have multiple possible choices of test statistic (in principle it could be any numerical summary of the data). Making the right choice is important for getting a test with good power<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>. What the right choice is will depend on what kind of alternatives we expect. This is not always easy to know in advance.</p><div class="no-row-height column-margin column-container"><li id="fn11"><p><sup>11</sup>&nbsp;See <a href="01-chap.html#sec-generative-SimulatingForPower" class="quarto-xref"><span>Section&nbsp;1.4.1</span></a> and <a href="#sec-testing-typesoferror" class="quarto-xref"><span>6.4</span></a>.</p></li></div></div>
<div class="page-columns page-full"><p>Once we have chosen the test statistic we need to compute its null distribution. You can do this either with pencil and paper or by computer simulations. A pencil and paper solution is parametric and leads to a closed form mathematical expression (like <a href="#eq-testing-dbinom" class="quarto-xref">Equation&nbsp;<span>6.3</span></a>), which has the advantage that it holds for a range of model parameters of the null hypothesis (such as <span class="math inline">\(n\)</span>, <span class="math inline">\(p\)</span>). It can also be quickly computed for any specific set of parameters. But it is not always as easy as in the coin tossing example. Sometimes a pencil and paper solution is impossibly difficult to compute. At other times, it may require simplifying assumptions. An example is a null distribution for the <span class="math inline">\(t\)</span>-statistic (which we will see later in this chapter). We can compute this if we assume that the data are independent and normally distributed: the result is called the <span class="math inline">\(t\)</span>-distribution. Such modelling assumptions may be more or less realistic. Simulating the null distribution offers a potentially more accurate, more realistic and perhaps even more intuitive approach. The drawback of simulating is that it can take a rather long time, and we need extra work to get a systematic understanding of how varying parameters influence the result. Generally, it is more elegant to use the parametric theory when it applies<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>. When you are in doubt, simulate – or do both.</p><div class="no-row-height column-margin column-container"><li id="fn12"><p><sup>12</sup>&nbsp;The assumptions don’t need to be <em>exactly</em> true – it is sufficient that the theory’s predictions are an acceptable approximation of the truth.</p></li></div></div>
<section id="sec-testing-rejectionregion" class="level3 page-columns page-full" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="sec-testing-rejectionregion"><span class="header-section-number">6.3.1</span> The rejection region</h3>
<div class="page-columns page-full"><p>How to choose the right rejection region for your test? First, what should its size be? That is your choice of the <strong>significance level</strong> or false positive rate <span class="math inline">\(\alpha\)</span>, which is the total probability of the test statistic falling into this region even if the null hypothesis is true<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>.</p><div class="no-row-height column-margin column-container"><li id="fn13"><p><sup>13</sup>&nbsp;Some people at some point in time for a particular set of questions colluded on <span class="math inline">\(\alpha=0.05\)</span> as being “small”. But there is nothing special about this number, and in any particular case the best choice for a decision threshold may very much depend on context <span class="citation" data-cites="Wasserstein2016:ASA Altman:PoS:2017">(<a href="16-chap.html#ref-Wasserstein2016:ASA" role="doc-biblioref">Wasserstein and Lazar 2016</a>; <a href="16-chap.html#ref-Altman:PoS:2017" role="doc-biblioref">Altman and Krzywinski 2017</a>)</span>.</p></li></div></div>
<p>Given the size, the next question is about its shape. For any given size, there are usually multiple possible shapes. It makes sense to require that the probability of the test statistic falling into the rejection region is as large possible if the alternative hypothesis is true. In other words, we want our test to have high <strong>power</strong>, or true positive rate.</p>
<p>The criterion that we used in the code for computing the rejection region for <a href="#fig-testing-findrej" class="quarto-xref">Figure&nbsp;<span>6.7</span></a> was to make the region contain as many <code>k</code> as possible. That is because in absence of any information about the alternative distribution, one <code>k</code> is as good as any other, and we maximize their total number.</p>
<p>A consequence of this is that in <a href="#fig-testing-findrej" class="quarto-xref">Figure&nbsp;<span>6.7</span></a> the rejection region is split between the two tails of the distribution. This is because we anticipate that unfair coins could have a bias either towards head or toward tail; we don’t know. If we did know, we would instead concentrate our rejection region all on the appropriate side, e.g., the right tail if we think the bias would be towards head. Such choices are also referred to as <em>two-sided</em> and <em>one-sided</em> tests. More generally, if we have assumptions about the alternative distribution, this can influence our choice of the shape of the rejection region.</p>
</section>
</section>
<section id="sec-testing-typesoferror" class="level2 page-columns page-full" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="sec-testing-typesoferror"><span class="header-section-number">6.4</span> Types of error</h2>
<p>Having set out the mechanics of testing, we can assess how well we are doing. <a href="#tbl-typesoferror" class="quarto-xref">Table&nbsp;<span>6.1</span></a> compares reality (whether or not the null hypothesis is in fact true) with our decision whether or not to reject the null hypothesis after we have seen the data.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/tbl-typesoferror_14f4b65c8e534ac52389a8a1710a8c34">
<div class="cell-output-display page-columns page-full">
<div id="tbl-typesoferror" class="anchored page-columns page-full">
<table class="table table-sm table-striped small">

<colgroup>
<col style="width: 30%">
<col style="width: 34%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Test vs reality</th>
<th style="text-align: left;">Null hypothesis is true</th>
<th style="text-align: left;"><span class="math inline">\(...\)</span> is false</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Reject null hypothesis</strong></td>
<td style="text-align: left;">Type I error (false positive)</td>
<td style="text-align: left;">True positive</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Do not reject</strong></td>
<td style="text-align: left;">True negative</td>
<td style="text-align: left;">Type II error (false negative)</td>
</tr>
</tbody>
</table>
<div class="quarto-table-caption margin-caption">Table&nbsp;6.1: Types of error in a statistical test.</div></div>
</div>
</div>
<p>It is always possible to reduce one of the two error types at the cost of increasing the other one. The real challenge is to find an acceptable trade-off between both of them. This is exemplified in <a href="#fig-testing-FDRvspstatic1" class="quarto-xref">Figure&nbsp;<span>6.2</span></a>. We can always decrease the <strong>false positive rate</strong> (FPR) by shifting the threshold to the right. We can become more “conservative”. But this happens at the price of higher <strong>false negative rate</strong> (FNR). Analogously, we can decrease the FNR by shifting the threshold to the left. But then again, this happens at the price of higher FPR. A bit on terminology: the FPR is the same as the probability <span class="math inline">\(\alpha\)</span> that we mentioned above. <span class="math inline">\(1 - \alpha\)</span> is also called the <strong>specificity</strong> of a test. The FNR is sometimes also called <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(1 - \beta\)</span> the <strong>power</strong>, <strong>sensitivity</strong> or <strong>true positive rate</strong> of a test.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-twosided" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.8 </strong></span>At the end of <a href="#sec-fivesteps" class="quarto-xref"><span>Section&nbsp;6.3</span></a>, we learned about one- and two-sided tests. Why does this distinction exist? Why don’t we always just use the two-sided test, which is sensitive to a larger class of alternatives?</p>
</div>
</div>
</div>
</section>
<section id="sec-testing-ttest" class="level2 page-columns page-full" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="sec-testing-ttest"><span class="header-section-number">6.5</span> The t-test</h2>
<p>Many experimental measurements are reported as rational numbers, and the simplest comparison we can make is between two groups, say, cells treated with a substance compared to cells that are not. The basic test for such situations is the <span class="math inline">\(t\)</span>-test. The test statistic is defined as</p>
<p><span class="anchored-eq" data-anchor-id="eq-testing" id="eq-testing-tstat"><span class="math display">\[
t = c \; \frac{m_1-m_2}{s},
\tag{6.4}\]</span></span></p>
<div class="page-columns page-full"><p>where <span class="anchored-eq" data-anchor-id="eq-testing" class="math inline">\(m_1\)</span> and <span class="math inline">\(m_2\)</span> are the mean of the values in the two groups, <span class="math inline">\(s\)</span> is the pooled standard deviation and <span class="math inline">\(c\)</span> is a constant that depends on the sample sizes, i.e., the numbers of observations <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> in the two groups. In formulas<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>,</p><div class="no-row-height column-margin column-container"><li id="fn14"><p><sup>14</sup>&nbsp;Everyone should try to remember <a href="#eq-testing-tstat" class="quarto-xref">Equation&nbsp;<span>6.4</span></a>, whereas many people get by with looking up <a href="#eq-testing-cttest" class="quarto-xref">Equation&nbsp;<span>6.5</span></a> when they need it.</p></li></div></div>
<p><span class="anchored-eq" data-anchor-id="eq-testing" id="eq-testing-cttest"><span class="math display">\[
\begin{align}
m_g &amp;= \frac{1}{n_g} \sum_{i=1}^{n_g} x_{g, i} \quad\quad\quad g=1,2\\
s^2 &amp;= \frac{1}{n_1+n_2-2}
\left( \sum_{i=1}^{n_1} \left(x_{1,i} - m_1\right)^2 +
\sum_{j=1}^{n_2} \left(x_{2,j} - m_2\right)^2 \right)\\
c   &amp;= \sqrt{\frac{n_1n_2}{n_1+n_2}}
\end{align}
\tag{6.5}\]</span></span></p>
<p>where <span class="math inline">\(x_{g, i}\)</span> is the <span class="math inline">\(i^{\text{th}}\)</span> data point in the <span class="math inline">\(g^{\text{th}}\)</span> group. Let’s try this out with the <code>PlantGrowth</code> data from R’s <strong>datasets</strong> package.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-plantgrowth_771b77f7380727a77f619c5f5a913953">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"ggbeeswarm"</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"PlantGrowth"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(PlantGrowth, <span class="fu">aes</span>(<span class="at">y =</span> weight, <span class="at">x =</span> group, <span class="at">col =</span> group)) <span class="sc">+</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_beeswarm</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>tt <span class="ot">=</span> <span class="fu">with</span>(PlantGrowth,</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>          <span class="fu">t.test</span>(weight[group <span class="sc">==</span><span class="st">"ctrl"</span>],</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>                 weight[group <span class="sc">==</span><span class="st">"trt2"</span>],</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>                 <span class="at">var.equal =</span> <span class="cn">TRUE</span>))</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>tt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Two Sample t-test

data:  weight[group == "ctrl"] and weight[group == "trt2"]
t = -2.134, df = 18, p-value = 0.04685
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.980338117 -0.007661883
sample estimates:
mean of x mean of y 
    5.032     5.526 </code></pre>
</div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-plantgrowth" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-plantgrowth-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;6.8: The <code>PlantGrowth</code> data.</figcaption>
</figure>
</div>
</div></div></div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-othercomparisons" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.9 </strong></span>What do you get from the comparison with <code>trt1</code>? What for <code>trt1</code> versus <code>trt2</code>?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-varequal" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.10 </strong></span>What is the significance of the <code>var.equal = TRUE</code> in the above call to <code>t.test</code>?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We’ll get back to this in <a href="#sec-testing-ttest" class="quarto-xref"><span>Section&nbsp;6.5</span></a>.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-formulainterfacettest" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.11 </strong></span>Rewrite the above call to <code>t.test</code> using the formula interface, i.e., by using the notation <code>weight</code> <span class="math inline">\(\sim\)</span> <code>group</code>.</p>
</div>
</div>
</div>
<p>To compute the p-value, the <code>t.test</code> function uses the asymptotic theory for the <span class="anchored-eq" data-anchor-id="eq-testing" class="math inline">\(t\)</span>-statistic <a href="#eq-testing-tstat" class="quarto-xref">Equation&nbsp;<span>6.4</span></a>; this theory states that under the null hypothesis of equal means in both groups, the statistic follows a known, mathematical distribution, the so-called <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n_1+n_2-2\)</span> degrees of freedom. The theory uses additional technical assumptions, namely that the data are independent and come from a normal distribution with the same standard deviation. We could be worried about these assumptions. Clearly they do not hold: weights are always positive, while the normal distribution extends over the whole real axis. The question is whether this deviation from the theoretical assumption makes a real difference. We can use a permutation test to figure this out (we will discuss the idea behind permutation tests in a bit more detail in <a href="#sec-testing-permutationtests" class="quarto-xref"><span>Section&nbsp;6.5.1</span></a>).</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-ttestperm_b2bc7362a5630332835a91562383067c">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>abs_t_null <span class="ot">=</span> <span class="fu">with</span>(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(PlantGrowth, group <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"ctrl"</span>, <span class="st">"trt2"</span>)),</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">replicate</span>(<span class="dv">10000</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>      <span class="fu">abs</span>(<span class="fu">t.test</span>(weight <span class="sc">~</span> <span class="fu">sample</span>(group))<span class="sc">$</span>statistic)))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(<span class="st">`</span><span class="at">|t|</span><span class="st">`</span> <span class="ot">=</span> abs_t_null), <span class="fu">aes</span>(<span class="at">x =</span> <span class="st">`</span><span class="at">|t|</span><span class="st">`</span>)) <span class="sc">+</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.1</span>, <span class="at">boundary =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">abs</span>(tt<span class="sc">$</span>statistic), <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">abs</span>(tt<span class="sc">$</span>statistic) <span class="sc">&lt;=</span> abs_t_null)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0489</code></pre>
</div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-ttestperm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-ttestperm-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;6.9: The null distribution of the (absolute) <span class="math inline">\(t\)</span>-statistic determined by simulations – namely, by random permutations of the group labels.</figcaption>
</figure>
</div>
</div></div></div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-abst" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.12 </strong></span>Why did we use the absolute value function (<code>abs</code>) in the above code?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<p>Plot the (parametric) <span class="math inline">\(t\)</span>-distribution with the appropriate degrees of freedom.</p>
</div>
</div>
<p>The <span class="math inline">\(t\)</span>-test comes in multiple flavors, all of which can be chosen through parameters of the <code>t.test</code> function. What we did above is called a two-sided two-sample unpaired test with equal variance. <em>Two-sided</em> refers to the fact that we were open to reject the null hypothesis if the weight of the treated plants was either larger or smaller than that of the untreated ones.</p>
<div class="page-columns page-full"><p><em>Two-sample</em><a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> indicates that we compared the means of two groups to each other; another option is to compare the mean of one group against a given, fixed number.</p><div class="no-row-height column-margin column-container"><li id="fn15"><p><sup>15</sup>&nbsp;It can be confusing that the term <em>sample</em> has a different meaning in statistics than in biology. In biology, a sample is a single specimen on which an assay is performed; in statistics, it is a set of measurements, e.g., the <span class="anchored-eq" data-anchor-id="eq-testing" class="math inline">\(n_1\)</span>-tuple <span class="math inline">\(\left(x_{1,1},...,x_{1,n_1}\right)\)</span> in <a href="#eq-testing-cttest" class="quarto-xref">Equation&nbsp;<span>6.5</span></a>, which can comprise several biological samples. In contexts where this double meaning might create confusion, we refer to the data from a single biological sample as an <em>observation</em>.</p></li></div></div>
<p><em>Unpaired</em> means that there was no direct 1:1 mapping between the measurements in the two groups. If, on the other hand, the data had been measured on the same plants before and after treatment, then a paired test would be more appropriate, as it looks at the change of weight within each plant, rather than their absolute weights.</p>
<p><em>Equal variance</em> refers to the way the statistic <a href="#eq-testing-tstat" class="quarto-xref">Equation&nbsp;<span>6.4</span></a> is calculated. That expression is most appropriate if the variances within each group are about the same. If they are very different, an alternative form (Welch’s <span class="math inline">\(t\)</span>-test) and associated asymptotic theory exist.</p>
<p><strong>The independence assumption</strong>. Now let’s try something peculiar: duplicate the data.</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/ttdup_67041f7f5feee610b5158ac3dfa6fe98">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(<span class="fu">rbind</span>(PlantGrowth, PlantGrowth),</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">t.test</span>(weight[group <span class="sc">==</span> <span class="st">"ctrl"</span>],</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>              weight[group <span class="sc">==</span> <span class="st">"trt2"</span>],</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">var.equal =</span> <span class="cn">TRUE</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Two Sample t-test

data:  weight[group == "ctrl"] and weight[group == "trt2"]
t = -3.1007, df = 38, p-value = 0.003629
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.8165284 -0.1714716
sample estimates:
mean of x mean of y 
    5.032     5.526 </code></pre>
</div>
</div>
<p>Note how the estimates of the group means (and thus, of the difference) are unchanged, but the p-value is now much smaller! We can conclude two things from this:</p>
<ul>
<li><p>The power of the <span class="math inline">\(t\)</span>-test depends on the sample size. Even if the underlying biological differences are the same, a dataset with more observations tends to give more significant results<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>.</p></li>
<li><p>The assumption of independence between the measurements is really important. Blatant duplication of the same data is an extreme form of dependence, but to some extent the same thing happens if you mix up different levels of replication. For instance, suppose you had data from 8 plants, but measured the same thing twice on each plant (technical replicates), then pretending that these are now 16 independent measurements is wrong.</p></li>
</ul>
<div class="no-row-height column-margin column-container"><li id="fn16"><p><sup>16</sup>&nbsp;You can also see this from the way the numbers <span class="anchored-eq" data-anchor-id="eq-testing" class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> appear in <a href="#eq-testing-cttest" class="quarto-xref">Equation&nbsp;<span>6.5</span></a>.</p></li></div><section id="sec-testing-permutationtests" class="level3 page-columns page-full" data-number="6.5.1">
<h3 data-number="6.5.1" class="anchored" data-anchor-id="sec-testing-permutationtests"><span class="header-section-number">6.5.1</span> Permutation tests</h3>
<div class="page-columns page-full"><p>What happened above when we contrasted the outcome of the parametric <span class="math inline">\(t\)</span>-test with that of the permutation test applied to the <span class="math inline">\(t\)</span>-statistic? It’s important to realize that these are two different tests, and the similarity of their outcomes is desirable, but coincidental. In the parametric test, the null distribution of the <span class="math inline">\(t\)</span>-statistic follows from the assumed null distribution of the data, a multivariate normal distribution with unit covariance in the <span class="math inline">\((n_1+n_2)\)</span>-dimensional space <span class="math inline">\(\mathbb{R}^{n_1+n_2}\)</span>, and is continuous: the <span class="math inline">\(t\)</span>-distribution. In contrast, the permutation distribution of our test statistic is discrete, as it is obtained from the finite set of <span class="math inline">\((n_1+n_2)!\)</span> permutations<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> of the observation labels, from a single instance of the data (the <span class="math inline">\(n_1+n_2\)</span> observations). All we assume here is that under the null hypothesis, the variables <span class="math inline">\(X_{1,1},...,X_{1,n_1},X_{2,1},...,X_{2,n_2}\)</span> are exchangeable. Logically, this assumption is implied by that of the parametric test, but is weaker. The permutation test employs the <span class="math inline">\(t\)</span>-statistic, but not the <span class="math inline">\(t\)</span>-distribution (nor the normal distribution). The fact that the two tests gave us a very similar result is a consequence of the Central Limit Theorem.</p><div class="no-row-height column-margin column-container"><li id="fn17"><p><sup>17</sup>&nbsp;Or a random subset, in case we want to save computation time.</p></li></div></div>
</section>
</section>
<section id="sec-pvaluehack" class="level2 page-columns page-full" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="sec-pvaluehack"><span class="header-section-number">6.6</span> P-value hacking</h2>
<div class="page-columns page-full"><p>Let’s go back to the coin tossing example. We did not reject the null hypothesis (that the coin is fair) at a level of 5%—even though we “knew” that it is unfair. After all, <code>probHead</code> was chosen as 0.6 in <a href="#sec-cointossing" class="quarto-xref"><span>Section&nbsp;6.2</span></a>. Let’s suppose we now start looking at different test statistics. Perhaps the number of consecutive series of 3 or more heads. Or the number of heads in the first 50 coin flips. And so on. At some point we will find a test that happens to result in a small p-value, even if just by chance (after all, the probability for the p-value to be less than 0.05 under the null hypothesis—fair coin—is one in twenty). We just did what is called <strong>p-value hacking</strong><a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a> <span class="citation" data-cites="Head:PLoSBiol:2015:pvaluehacking">(<a href="16-chap.html#ref-Head:PLoSBiol:2015:pvaluehacking" role="doc-biblioref">Head et al. 2015</a>)</span>. You see what the problem is: in our zeal to prove our point we tortured the data until some statistic did what we wanted. A related tactic is <strong>hypothesis switching</strong> or <strong>HARKing</strong> – hypothesizing after the results are known: we have a dataset, maybe we have invested a lot of time and money into assembling it, so we need results. We come up with lots of different null hypotheses and test statistics, test them, and iterate, until we can report something.</p><div class="no-row-height column-margin column-container"><li id="fn18"><p><sup>18</sup>&nbsp;<a href="http://fivethirtyeight.com/features/science-isnt-broken" class="uri">http://fivethirtyeight.com/features/science-isnt-broken</a></p></li></div></div>
<p>These tactics violate the rules of hypothesis testing, as described in <a href="#sec-fivesteps" class="quarto-xref"><span>Section&nbsp;6.3</span></a>, where we laid out one sequential procedure of choosing the hypothesis and the test, and then collecting the data. But, as we saw in <a href="02-chap.html" class="quarto-xref"><span>Chapter&nbsp;2</span></a>, such tactics can be tempting in reality. With biological data, we tend to have so many different choices for “normalising” the data, transforming the data, trying to adjust for batch effects, removing outliers, …. The topic is complex and open-ended. <span class="citation" data-cites="Wasserstein2016:ASA">Wasserstein and Lazar (<a href="16-chap.html#ref-Wasserstein2016:ASA" role="doc-biblioref">2016</a>)</span> give a readable short summary of the problems with how p-values are used in science, and of some of the misconceptions. They also highlight how p-values can be fruitfully used. The essential message is: be completely transparent about your data, what analyses were tried, and how they were done. Provide the analysis code. Only with such contextual information can a p-value be useful.</p>
<p><strong>Avoid fallacy</strong>. Keep in mind that our statistical test is never attempting to prove our null hypothesis is true - we are simply saying whether or not there is evidence for it to be false. If a high p-value <em>were</em> indicative of the truth of the null hypothesis, we could formulate a completely crazy null hypothesis, do an utterly irrelevant experiment, collect a small amount of inconclusive data, find a p-value that would just be a random number between 0 and 1 (and so with some high probability above our threshold <span class="math inline">\(\alpha\)</span>) and, whoosh, our hypothesis would be demonstrated!</p>
</section>
<section id="multiple-testing" class="level2 page-columns page-full" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="multiple-testing"><span class="header-section-number">6.7</span> Multiple testing</h2>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-xkcd882" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.13 </strong></span>Look up <a href="http://xkcd.com/882">xkcd cartoon 882</a>. Why didn’t the newspaper report the results for the other colors?</p>
</div>
</div>
</div>
<p>The quandary illustrated in the cartoon occurs with high-throughput data in biology. And with force! You will be dealing not only with 20 colors of jellybeans, but, say, with 20,000 genes that were tested for differential expression between two conditions, or with 6 billion positions in the genome where a DNA mutation might have happened. So how do we deal with this? Let’s look again at our table relating statistical test results with reality (<a href="#tbl-typesoferror" class="quarto-xref">Table&nbsp;<span>6.1</span></a>), this time framing everything in terms of many hypotheses.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/tbl-mterrors_56a4ce0c39ea1b5e977603507775b243">
<div class="cell-output-display page-columns page-full">
<div id="tbl-mterrors" class="anchored page-columns page-full">
<table class="table table-sm table-striped small">

<thead>
<tr class="header">
<th style="text-align: left;">Test vs reality</th>
<th style="text-align: left;">Null hypothesis is true</th>
<th style="text-align: left;"><span class="math inline">\(...\)</span> is false</th>
<th style="text-align: left;">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Rejected</strong></td>
<td style="text-align: left;"><span class="math inline">\(V\)</span></td>
<td style="text-align: left;"><span class="math inline">\(S\)</span></td>
<td style="text-align: left;"><span class="math inline">\(R\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Not rejected</strong></td>
<td style="text-align: left;"><span class="math inline">\(U\)</span></td>
<td style="text-align: left;"><span class="math inline">\(T\)</span></td>
<td style="text-align: left;"><span class="math inline">\(m-R\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Total</strong></td>
<td style="text-align: left;"><span class="math inline">\(m_0\)</span></td>
<td style="text-align: left;"><span class="math inline">\(m-m_0\)</span></td>
<td style="text-align: left;"><span class="math inline">\(m\)</span></td>
</tr>
</tbody>
</table>
<div class="quarto-table-caption margin-caption">Table&nbsp;6.2: Types of error in multiple testing. The letters designate the number of times each type of error occurs.</div></div>
</div>
</div>
<ul>
<li><p><span class="math inline">\(m\)</span>: total number of tests (and null hypotheses)</p></li>
<li><p><span class="math inline">\(m_0\)</span>: number of true null hypotheses</p></li>
<li><p><span class="math inline">\(m-m_0\)</span>: number of false null hypotheses</p></li>
<li><p><span class="math inline">\(V\)</span>: number of false positives (a measure of type I error)</p></li>
<li><p><span class="math inline">\(T\)</span>: number of false negatives (a measure of type II error)</p></li>
<li><p><span class="math inline">\(S\)</span>, <span class="math inline">\(U\)</span>: number of true positives and true negatives</p></li>
<li><p><span class="math inline">\(R\)</span>: number of rejections</p></li>
</ul>
<p>In the rest of this chapter, we look at different ways of taking care of the type I and II errors.</p>
</section>
<section id="sec-testing-FWER" class="level2 page-columns page-full" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="sec-testing-FWER"><span class="header-section-number">6.8</span> The family wise error rate</h2>
<div class="page-columns page-full"><p>The <strong>family wise error rate</strong> (FWER) is the probability that <span class="math inline">\(V&gt;0\)</span>, i.e., that we make one or more false positive errors. We can compute it as the complement of making no false positive errors at all<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a>.</p><div class="no-row-height column-margin column-container"><li id="fn19"><p><sup>19</sup>&nbsp;Assuming independence.</p></li></div></div>
<p><span class="anchored-eq" data-anchor-id="eq-testing" id="eq-testing-bonferroni"><span class="math display">\[
\begin{align}
P(V&gt;0) &amp;= 1 - P(\text{no rejection of any of $m_0$ nulls}) \\
       &amp;= 1 - (1 - \alpha)^{m_0} \to 1 \quad\text{as } m_0\to\infty.
\end{align}
\tag{6.6}\]</span></span></p>
<p>For any fixed <span class="math inline">\(\alpha\)</span>, this probability is appreciable as soon as <span class="math inline">\(m_0\)</span> is in the order of <span class="math inline">\(1/\alpha\)</span>, and it tends towards 1 as <span class="math inline">\(m_0\)</span> becomes larger. This relationship can have serious consequences for experiments like DNA matching, where a large database of potential matches is searched. For example, if there is a one in a million chance that the DNA profiles of two people match by random error, and your DNA is tested against a database of 800000 profiles, then the probability of a random hit with the database (i.e., without you being in it) is:</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/typeerror3_595864c1b1990664ebfa308a81d1a0c6">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="dv">1</span><span class="sc">/</span><span class="fl">1e6</span>)<span class="sc">^</span><span class="fl">8e5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5506712</code></pre>
</div>
</div>
<p>That’s pretty high. And once the database contains a few million profiles more, a false hit is virtually unavoidable.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-fwertendstoone" class="theorem proposition">
<p><span class="anchored-eq" data-anchor-id="eq-testing" class="theorem-title"><strong>Question 6.14 </strong></span>Prove that the probability <a href="#eq-testing-bonferroni" class="quarto-xref">Equation&nbsp;<span>6.6</span></a> does indeed become very close to 1 when <span class="math inline">\(m_0\)</span> is large.</p>
</div>
</div>
</div>
<section id="bonferroni-method" class="level3 page-columns page-full" data-number="6.8.1">
<h3 data-number="6.8.1" class="anchored" data-anchor-id="bonferroni-method"><span class="header-section-number">6.8.1</span> Bonferroni method</h3>
<p>How are we to choose the per-hypothesis <span class="math inline">\(\alpha\)</span> if we want FWER control? The above computations suggest that the product of <span class="math inline">\(\alpha\)</span> with <span class="math inline">\(m_0\)</span> may be a reasonable ballpark estimate. Usually we don’t know <span class="math inline">\(m_0\)</span>, but we know <span class="math inline">\(m\)</span>, which is an upper limit for <span class="math inline">\(m_0\)</span>, since <span class="math inline">\(m_0\le m\)</span>. The Bonferroni method is simply that if we want FWER control at level <span class="math inline">\(\alpha_{\text{FWER}}\)</span>, we should choose the per hypothesis threshold <span class="math inline">\(\alpha = \alpha_{\text{FWER}}/m\)</span>. Let’s check this out on an example.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-bonferroni_a032fb27925cbd60a3e4400093ca1048">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> <span class="dv">10000</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="fl">7e-6</span>, <span class="at">length.out =</span> <span class="dv">100</span>),</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">p     =</span> <span class="dv">1</span> <span class="sc">-</span> (<span class="dv">1</span> <span class="sc">-</span> alpha)<span class="sc">^</span>m),</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> alpha, <span class="at">y =</span> p)) <span class="sc">+</span>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(alpha)) <span class="sc">+</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Prob( no false rejection )"</span>) <span class="sc">+</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.05</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-bonferroni" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-bonferroni-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;6.10: Bonferroni method. The plot shows the graph of <a href="#eq-testing-bonferroni" class="quarto-xref"><span>6.6</span></a> for <span class="math inline">\(m=10000\)</span> as a function of <span class="math inline">\(\alpha\)</span>.</figcaption>
</figure>
</div>
</div></div></div>
<p>In <a href="#fig-testing-bonferroni" class="quarto-xref">Figure&nbsp;<span>6.10</span></a>, the black line intersects the red line (which corresponds to a value of 0.05) at <span class="math inline">\(\alpha=5.13\times 10^{-6}\)</span>, which is just a little bit more than the value of <span class="math inline">\(0.05/m\)</span> implied by the Bonferroni method.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-bonferroni" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.15 </strong></span>Why are the two values not exactly the same?</p>
</div>
</div>
</div>
<p>A potential drawback of this method, however, is that if <span class="math inline">\(m_0\)</span> is large, the rejection threshold is very small. This means that the individual tests need to be very powerful if we want to have any chance of detecting something. Often FWER control is too stringent, and would lead to an ineffective use of the time and money that was spent to generate and assemble the data. We will now see that there are more nuanced methods of controlling our type I error.</p>
</section>
</section>
<section id="the-false-discovery-rate" class="level2 page-columns page-full" data-number="6.9">
<h2 data-number="6.9" class="anchored" data-anchor-id="the-false-discovery-rate"><span class="header-section-number">6.9</span> The false discovery rate</h2>
<p>Let’s look at some data. We load up the RNA-Seq dataset <code>airway</code>, which contains gene expression measurements (gene-level counts) of four primary human airway smooth muscle cell lines with and without treatment with dexamethasone, a synthetic glucocorticoid. We’ll use the <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> method that we’ll discuss in more detail in <a href="08-chap.html" class="quarto-xref"><span>Chapter&nbsp;8</span></a> For now it suffices to say that it performs a test for differential expression for each gene. Conceptually, the tested null hypothesis is similar to that of the <span class="math inline">\(t\)</span>-test, although the details are slightly more involved since we are dealing with count data.</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/mtdeseq2airway_2cdce5eacb491901c5e17ab813754dc4">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"DESeq2"</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"airway"</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"airway"</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>aw   <span class="ot">=</span> <span class="fu">DESeqDataSet</span>(<span class="at">se =</span> airway, <span class="at">design =</span> <span class="sc">~</span> cell <span class="sc">+</span> dex)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>aw   <span class="ot">=</span> <span class="fu">DESeq</span>(aw)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>awde <span class="ot">=</span> <span class="fu">as.data.frame</span>(<span class="fu">results</span>(aw)) <span class="sc">|&gt;</span> dplyr<span class="sc">::</span><span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(pvalue))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<p>Have a look at the content of <code>awde</code>.</p>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<p>(Optional) Consult the <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> vignette and/or <a href="08-chap.html" class="quarto-xref"><span>Chapter&nbsp;8</span></a> for more information on what the above code chunk does.</p>
</div>
</div>
<section id="the-p-value-histogram" class="level3 page-columns page-full" data-number="6.9.1">
<h3 data-number="6.9.1" class="anchored" data-anchor-id="the-p-value-histogram"><span class="header-section-number">6.9.1</span> The p-value histogram</h3>
<p>The <strong>p-value histogram</strong> is an important sanity check for any analysis that involves multiple tests. It is a mixture composed of two components:</p>
<p><strong>null:</strong> the p-values resulting from the tests for which the null hypothesis is true.</p>
<p><strong>alt:</strong> the p-values resulting from the tests for which the null hypothesis is not true. The relative size of these two components depends on the fraction of true nulls and true alternatives (i.e., on <span class="math inline">\(m_0\)</span> and <span class="math inline">\(m\)</span>), and it can often be visually estimated from the histogram. If our analysis has high statistical power, then the second component (“alt”) consists of mostly small p-values, i.e., appears as a peak near 0 in the histogram; if the power is not high for some of the alternatives, we expect that this peak extends towards the right, i.e., has a “shoulder”. For the “null” component, we expect (by definition of the p-value for continuous data and test statistics) a uniform distribution in <span class="math inline">\([0,1]\)</span>. Let’s plot the histogram of p-values for the airway data.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-awpvhist_fe819d86c62f820642d50ff4fd95c4e5">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(awde, <span class="fu">aes</span>(<span class="at">x =</span> pvalue)) <span class="sc">+</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.025</span>, <span class="at">boundary =</span> <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-awpvhist" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-awpvhist-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;6.11: p-value histogram of for the <code>airway</code> data.</figcaption>
</figure>
</div>
</div></div></div>
<p>In <a href="#fig-testing-awpvhist" class="quarto-xref">Figure&nbsp;<span>6.11</span></a> we see the expected mixture. We also see that the null component is not exactly flat (uniform): this is because the data are counts. While these appear quasi-continuous when high, for the tests with low counts the discreteness of the data and the resulting p-values shows up in the spikes towards the right of the histogram.</p>
<p>Now suppose we reject all tests with a p-value less than <span class="math inline">\(\alpha\)</span>. We can visually determine an estimate of the false discovery proportion with a plot such as in <a href="#fig-testing-awpvvisfdr" class="quarto-xref">Figure&nbsp;<span>6.12</span></a>, generated by the following code.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-awpvvisfdr_9ee979567a6d9aca7a101990c939a2e0">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">=</span> binw <span class="ot">=</span> <span class="fl">0.025</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>pi0 <span class="ot">=</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">mean</span>(awde<span class="sc">$</span>pvalue <span class="sc">&gt;</span> <span class="fl">0.5</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(awde,</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> pvalue)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> binw, <span class="at">boundary =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> pi0 <span class="sc">*</span> binw <span class="sc">*</span> <span class="fu">nrow</span>(awde), <span class="at">col =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> alpha, <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-awpvvisfdr" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-awpvvisfdr-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;6.12: Visual estimation of the FDR with the p-value histogram.</figcaption>
</figure>
</div>
</div></div></div>
<p>We see that there are 4772 p-values in the first bin <span class="math inline">\([0,\alpha]\)</span>, among which we expect around 945 to be nulls (as indicated by the blue line). Thus we can estimate the fraction of false rejections as</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/fdrvis_8ac33eb5c7d656b6c03133c470869251">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>pi0 <span class="sc">*</span> alpha <span class="sc">/</span> <span class="fu">mean</span>(awde<span class="sc">$</span>pvalue <span class="sc">&lt;=</span> alpha)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1980092</code></pre>
</div>
</div>
<p>The <strong>false discovery rate</strong> (FDR) is defined as</p>
<p><span class="anchored-eq" data-anchor-id="eq-testing" id="eq-testing-deffdr"><span class="math display">\[
\text{FDR} = \text{E}\!\left [\frac{V}{\max(R, 1)}\right ],
\tag{6.7}\]</span></span></p>
<div class="page-columns page-full"><p>where <span class="math inline">\(R\)</span> and <span class="math inline">\(V\)</span> are as in <a href="#tbl-mterrors" class="quarto-xref">Table&nbsp;<span>6.2</span></a>. The expression in the denominator makes sure that the FDR is well-defined even if <span class="math inline">\(R=0\)</span> (in that case, <span class="math inline">\(V=0\)</span> by implication). Note that the FDR becomes identical to the FWER if all null hypotheses are true, i.e., if <span class="math inline">\(V=R\)</span>. <span class="math inline">\(\text{E[ ]}\)</span> stands for the <strong>expected value</strong>. That means that the FDR is not a quantity associated with a specific outcome of <span class="math inline">\(V\)</span> and <span class="math inline">\(R\)</span> for one particular experiment. Rather, given our choice of tests and associated rejection rules for them, it is the average<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> proportion of type I errors out of the rejections made, where the average is taken (at least conceptually) over many replicate instances of the experiment.</p><div class="no-row-height column-margin column-container"><li id="fn20"><p><sup>20</sup>&nbsp;Since the FDR is an expectation value, it does not provide worst case control: in any single experiment, the so-called false discovery proportion (FDP), that is the realized value <span class="math inline">\(v/r\)</span> (without the <span class="math inline">\(\text{E[ ]}\)</span>), could be much higher or lower.</p></li></div></div>
</section>
<section id="the-benjamini-hochberg-algorithm-for-controlling-the-fdr" class="level3 page-columns page-full" data-number="6.9.2">
<h3 data-number="6.9.2" class="anchored" data-anchor-id="the-benjamini-hochberg-algorithm-for-controlling-the-fdr"><span class="header-section-number">6.9.2</span> The Benjamini-Hochberg algorithm for controlling the FDR</h3>
<p>There is a more elegant alternative to the “visual FDR” method of the last section. The procedure, introduced by <span class="citation" data-cites="BH:1995">Benjamini and Hochberg (<a href="16-chap.html#ref-BH:1995" role="doc-biblioref">1995</a>)</span> has these steps:</p>
<ul>
<li><p>First, order the p-values in increasing order, <span class="math inline">\(p_{(1)} ... p_{(m)}\)</span></p></li>
<li><p>Then for some choice of <span class="math inline">\(\varphi\)</span> (our target FDR), find the largest value of <span class="math inline">\(k\)</span> that satisfies: <span class="math inline">\(p_{(k)} \leq \varphi \, k / m\)</span></p></li>
<li><p>Finally reject the hypotheses <span class="math inline">\(1, ..., k\)</span></p></li>
</ul>
<p>We can see how this procedure works when applied to our RNA-Seq p-values through a simple graphical illustration:</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-BH_594f5318377ea1bacc96d6def22b038f">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>phi  <span class="ot">=</span> <span class="fl">0.10</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>awde <span class="ot">=</span> <span class="fu">mutate</span>(awde, <span class="at">rank =</span> <span class="fu">rank</span>(pvalue))</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>m    <span class="ot">=</span> <span class="fu">nrow</span>(awde)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dplyr<span class="sc">::</span><span class="fu">filter</span>(awde, rank <span class="sc">&lt;=</span> <span class="dv">7000</span>), <span class="fu">aes</span>(<span class="at">x =</span> rank, <span class="at">y =</span> pvalue)) <span class="sc">+</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">slope =</span> phi <span class="sc">/</span> m, <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-BH" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-BH-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;6.13: Visualization of the Benjamini-Hochberg procedure. Shown is a zoom-in to the 7000 lowest p-values.</figcaption>
</figure>
</div>
</div></div></div>
<p>The method finds the rightmost point where the black (our p-values) and red lines (slope <span class="math inline">\(\varphi / m\)</span>) intersect. Then it rejects all tests to the left.</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/kmax_66a8b2a461447e0e7ad18f95a8214471">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>kmax <span class="ot">=</span> <span class="fu">with</span>(<span class="fu">arrange</span>(awde, rank),</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>         <span class="fu">last</span>(<span class="fu">which</span>(pvalue <span class="sc">&lt;=</span> phi <span class="sc">*</span> rank <span class="sc">/</span> m)))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>kmax</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4099</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-compare" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.16 </strong></span>Compare the value of <code>kmax</code> with the number of 4772 from above (<a href="#fig-testing-awpvvisfdr" class="quarto-xref">Figure&nbsp;<span>6.12</span></a>). Why are they different?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-BH" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.17 </strong></span>Look at the code associated with the option <code>method="BH"</code> of the <code>p.adjust</code> function that comes with R. How does it compare to what we did above?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-SchwederSpjotvoll" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.18 </strong></span><strong>Schweder and Spj<span>ø</span>tvoll plot</strong>: check out Figures 1–3 in <span class="citation" data-cites="SchwederSpjotvoll1982">Schweder and Spjøtvoll (<a href="16-chap.html#ref-SchwederSpjotvoll1982" role="doc-biblioref">1982</a>)</span>. Make a similar plot for the data in <code>awde</code>. How does it relate to Figures <a href="#fig-testing-BH" class="quarto-xref"><span>6.13</span></a> and <a href="#fig-testing-awpvvisfdr" class="quarto-xref"><span>6.12</span></a>?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-25-contents" aria-controls="callout-25" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-25" class="callout-25-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Thirteen years before <span class="citation" data-cites="BH:1995">Benjamini and Hochberg (<a href="16-chap.html#ref-BH:1995" role="doc-biblioref">1995</a>)</span>, <span class="citation" data-cites="SchwederSpjotvoll1982">Schweder and Spjøtvoll (<a href="16-chap.html#ref-SchwederSpjotvoll1982" role="doc-biblioref">1982</a>)</span> suggested a diagnostic plot of the observed <span class="math inline">\(p\)</span>-values that permits estimation of the fraction of true null hypotheses. For a series of hypothesis tests <span class="math inline">\(H_1, ..., H_m\)</span> with <span class="math inline">\(p\)</span>-values <span class="math inline">\(p_i\)</span>, they suggested plotting</p>
<p><span class="anchored-eq" data-anchor-id="eq-zuhlkdsaeiov" id="eq-zuhlkdsaeiov"><span class="math display">\[
\left( 1-p_i, N(p_i) \right) \mbox{ for } i \in 1, ..., m,
\tag{6.8}\]</span></span></p>
<p>where <span class="math inline">\(N(p)\)</span> is the number of <span class="math inline">\(p\)</span>-values greater than <span class="math inline">\(p\)</span>. An application of this diagnostic plot to <code>awde$pvalue</code> is shown in <a href="#fig-testing-SchwederSpjotvoll" class="quarto-xref">Figure&nbsp;<span>6.14</span></a>. When all null hypotheses are true, each of the <span class="math inline">\(p\)</span>-values is uniformly distributed in <span class="math inline">\([0,1]\)</span>, Consequently, the empirical cumulative distribution of the sample <span class="math inline">\((p_1, ..., p_m)\)</span> is expected to be close to the line <span class="math inline">\(F(t)=t\)</span>. By symmetry, the same applies to <span class="math inline">\((1 - p_1, ..., 1 - p_m)\)</span>. When (without loss of generality) the first <span class="math inline">\(m_0\)</span> null hypotheses are true and the other <span class="math inline">\(m-m_0\)</span> are false, the empirical cumulative distribution of <span class="math inline">\((1-p_1, ..., 1-p_{m_0})\)</span> is again expected to be close to the line <span class="math inline">\(F_0(t)=t\)</span>. The empirical cumulative distribution of <span class="math inline">\((1-p_{m_0+1}, ..., 1-p_{m})\)</span>, on the other hand, is expected to be close to a function <span class="math inline">\(F_1(t)\)</span> which stays below <span class="math inline">\(F_0\)</span> but shows a steep increase towards 1 as <span class="math inline">\(t\)</span> approaches <span class="math inline">\(1\)</span>. In practice, we do not know which of the null hypotheses are true, so we only observe a mixture whose empirical cumulative distribution is expected to be close to</p>
<p><span class="anchored-eq" data-anchor-id="eq-yrvgmlafuhiw" id="eq-yrvgmlafuhiw"><span class="math display">\[
F(t) = \frac{m_0}{m} F_0(t) + \frac{m-m_0}{m} F_1(t).
\tag{6.9}\]</span></span></p>
<p>Such a situation is shown in <a href="#fig-testing-SchwederSpjotvoll" class="quarto-xref">Figure&nbsp;<span>6.14</span></a>. If <span class="math inline">\(F_1(t)/F_0(t)\)</span> is small for small <span class="math inline">\(t\)</span> (i.e., the tests have reasonable power), then the mixture fraction <span class="math inline">\(\frac{m_0}{m}\)</span> can be estimated by fitting a line to the left-hand portion of the plot, and then noting its height on the right. Such a fit is shown by the red line. Here, we focus on those tests for which the count data are not all very small numbers (<code>baseMean&gt;=1</code>), since for these the p-value null distribution is sufficiently close to uniform (i.e., does not show the discreteness mentioned above), but you could try the making the same plot on all of the genes.</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-SchwederSpjotvoll_c9893f9d42a1edaf635b954a76e6ed9b">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>awdef <span class="ot">=</span> awde <span class="sc">|&gt;</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(baseMean <span class="sc">&gt;=</span><span class="dv">1</span>) <span class="sc">|&gt;</span> </span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(pvalue) <span class="sc">|&gt;</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">oneminusp =</span> <span class="dv">1</span> <span class="sc">-</span> pvalue,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">N =</span> <span class="fu">n</span>() <span class="sc">-</span> <span class="fu">row_number</span>())</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>jj <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(awdef) <span class="sc">*</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">0.5</span>))</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>slope <span class="ot">=</span> <span class="fu">with</span>(awdef, <span class="fu">diff</span>(N[jj]) <span class="sc">/</span> <span class="fu">diff</span>(oneminusp[jj]))</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(awdef) <span class="sc">+</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> oneminusp, <span class="at">y =</span> N), <span class="at">size =</span> <span class="fl">0.15</span>) <span class="sc">+</span> </span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(<span class="dv">1</span><span class="sc">-</span>p[i])) <span class="sc">+</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="fu">expression</span>(<span class="fu">N</span>(p[i]))) <span class="sc">+</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> slope, <span class="at">col =</span> <span class="st">"red3"</span>) <span class="sc">+</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> slope, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">1</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> slope, <span class="at">label =</span> <span class="fu">paste</span>(<span class="fu">round</span>(slope)), </span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>            <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.1</span>, <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.25</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-testing-SchwederSpjotvoll" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-SchwederSpjotvoll-1.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;6.14: Schweder and Spjtvoll plot, as described in the answer to <a href="#prp-testing-SchwederSpjotvoll" class="quarto-xref">Question&nbsp;<span>6.18</span></a>.</figcaption>
</figure>
</div>
</div>
</div>
<p>There are 22853 rows in <code>awdef</code>, thus, according to this simple estimate, there are 22853-17302=5551 alternative hypotheses.</p>
</div>
</div>
</div>
</section>
</section>
<section id="sec-testing-localfdr" class="level2 page-columns page-full" data-number="6.10">
<h2 data-number="6.10" class="anchored" data-anchor-id="sec-testing-localfdr"><span class="header-section-number">6.10</span> The local FDR</h2>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-sunexplode_b60759b26788397799b21b785883ee71">
<div class="cell-output-display page-columns page-full">
<div id="fig-testing-sunexplode" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="imgs/xkcd1132.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption margin-caption">Figure&nbsp;6.15: From <a href="http://xkcd.com/1132">http://xkcd.com/1132</a> – While the frequentist only has the currently available data, the Bayesian can draw on her understanding of the world or on previous experience. As a Bayesian, she would know enough about physics to understand that our sun’s mass is too small to become a nova. Even if she does not know physics, she might be an <strong>empirical Bayesian</strong> and draw her prior from a myriad previous days where the sun did not go nova.</figcaption>
</figure>
</div>
</div>
</div>
<p>While the xkcd cartoon in the chapter’s opening figure ends with a rather sinister interpretation of the multiple testing problem as a way to accumulate errors, <a href="#fig-testing-sunexplode" class="quarto-xref">Figure&nbsp;<span>6.15</span></a> highlights the multiple testing opportunity: when we do many tests, we can use the multiplicity to increase our understanding beyond what’s possible with a single test.</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-lfdr_88a3400bca3afabaaae4941eb5ef2510">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-lfdr" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-lfdr-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;6.16: Local false discovery rate and the two-group model, with some choice of <span class="math inline">\(f_{\text{alt}}(p)\)</span>, and <span class="math inline">\(\pi_0=0.6\)</span>; densities (top) and distribution functions (bottom).</figcaption>
</figure>
</div>
</div></div></div>
<p>Let’s get back to the histogram in <a href="#fig-testing-awpvvisfdr" class="quarto-xref">Figure&nbsp;<span>6.12</span></a>. Conceptually, we can think of it in terms of the so-called two-groups model <span class="citation" data-cites="Efron2010">(<a href="16-chap.html#ref-Efron2010" role="doc-biblioref">Efron 2010</a>)</span>:</p>
<p><span class="anchored-eq" data-anchor-id="eq-testing" id="eq-testing-twogroups"><span class="math display">\[
f(p)= \pi_0  + (1-\pi_0) f_{\text{alt}}(p),
\tag{6.10}\]</span></span></p>
<p>Here, <span class="math inline">\(f(p)\)</span> is the density of the distribution (what the histogram would look like with an infinite amount of data and infinitely small bins), <span class="math inline">\(\pi_0\)</span> is a number between 0 and 1 that represents the size of the uniform component, and <span class="math inline">\(f_{\text{alt}}\)</span> is the alternative component. This is a mixture model, as we already saw in <a href="04-chap.html" class="quarto-xref"><span>Chapter&nbsp;4</span></a>. The mixture densities and the marginal density <span class="math inline">\(f(p)\)</span> are visualized in the upper panel of <a href="#fig-testing-lfdr" class="quarto-xref">Figure&nbsp;<span>6.16</span></a>: the blue areas together correspond to the graph of <span class="math inline">\(f_{\text{alt}}(p)\)</span>, the grey areas to that of <span class="math inline">\(f_{\text{null}}(p) = \pi_0\)</span>. If we now consider one particular cutoff <span class="math inline">\(p\)</span> (say, <span class="math inline">\(p=0.1\)</span> as in <a href="#fig-testing-lfdr" class="quarto-xref">Figure&nbsp;<span>6.16</span></a>), then we can compute the probability that a hypothesis that we reject at this cutoff is a false positive, as follows. We decompose the value of <span class="math inline">\(f\)</span> at the cutoff (red line) into the contribution from the nulls (light red, <span class="math inline">\(\pi_0\)</span>) and from the alternatives (darker red, <span class="math inline">\((1-\pi_0) f_{\text{alt}}(p)\)</span>). The <strong>local false discovery rate</strong> is then</p>
<p><span class="anchored-eq" data-anchor-id="eq-fdr" id="eq-fdr-local"><span class="math display">\[
\text{fdr}(p) = \frac{\pi_0}{f(p)}.
\tag{6.11}\]</span></span></p>
<p>By definition this quantity is between 0 and 1. Note how the <span class="math inline">\(\text{fdr}\)</span> in <a href="#fig-testing-lfdr" class="quarto-xref">Figure&nbsp;<span>6.16</span></a> is a monotonically increasing function of <span class="math inline">\(p\)</span>, and this goes with our intuition that the fdr should be lowest for the smallest <span class="math inline">\(p\)</span> and then gradually get larger, until it reaches 1 at the very right end. We can make a similar decomposition not only for the red line, but also for the area under the curve. This is</p>
<p><span class="anchored-eq" data-anchor-id="eq-fdr" id="eq-fdr-area"><span class="math display">\[
F(p)  = \int_0^p f(t)\,dt,
\tag{6.12}\]</span></span></p>
<div class="page-columns page-full"><p>and the ratio of the dark grey area (that is, <span class="anchored-eq" data-anchor-id="eq-testing" class="math inline">\(\pi_0\)</span> times <span class="math inline">\(p\)</span>) to the overall area <span class="math inline">\(F(p)\)</span> is the <strong>tail area false discovery rate</strong> (Fdr<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a>),</p><div class="no-row-height column-margin column-container"><li id="fn21"><p><sup>21</sup>&nbsp;The convention is to use the lower case abbreviation fdr for the local, and the abbreviation Fdr for the tail-area false discovery rate in the context of the two-groups model <a href="#eq-testing-twogroups" class="quarto-xref">Equation&nbsp;<span>6.10</span></a>. The abbreviation FDR is used for the original definition <a href="#eq-testing-deffdr" class="quarto-xref">Equation&nbsp;<span>6.7</span></a>, which is a bit more general, namely, it does not depend on the modelling assumptions of <a href="#eq-testing-twogroups" class="quarto-xref">Equation&nbsp;<span>6.10</span></a>.</p></li></div></div>
<p><span class="anchored-eq" data-anchor-id="eq-fdr" id="eq-fdr-tail-area"><span class="math display">\[
\text{Fdr}(p) = \frac{\pi_0\,p}{F(p)}.
\tag{6.13}\]</span></span></p>
<p>We’ll use the data version of <span class="math inline">\(F\)</span> for diagnostics in <a href="#fig-testing-awde-stratified-ecdf" class="quarto-xref">Figure&nbsp;<span>6.20</span></a>.</p>
<p>The packages <strong><a href="https://bioconductor.org/packages/qvalue/">qvalue</a></strong> and <strong><a href="https://cran.r-project.org/web/packages/fdrtool/">fdrtool</a></strong> offer facilities to fit these models to data.</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/fdrtool_4c58bf966dbd3d0365635a403196e6d6">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"fdrtool"</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>ft <span class="ot">=</span> <span class="fu">fdrtool</span>(awde<span class="sc">$</span>pvalue, <span class="at">statistic =</span> <span class="st">"pvalue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In <strong><a href="https://cran.r-project.org/web/packages/fdrtool/">fdrtool</a></strong>, what we called <span class="math inline">\(\pi_0\)</span> above is called <code>eta0</code>:</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/qvalue31_83ca6835382ae2c013e602f6eb1a824a">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>ft<span class="sc">$</span>param[,<span class="st">"eta0"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     eta0 
0.8822922 </code></pre>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-fdrtoolplot" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.19 </strong></span>What do the plots that are produced by the above call to <code>fdrtool</code> show?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<p>Explore the other elements of the <em>list</em> <code>ft</code>.</p>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-emoiricalbayes" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.20 </strong></span>What does the <em>empirical</em> in empirical Bayes methods stand for?</p>
</div>
</div>
</div>
<section id="local-versus-total" class="level3" data-number="6.10.1">
<h3 data-number="6.10.1" class="anchored" data-anchor-id="local-versus-total"><span class="header-section-number">6.10.1</span> Local versus total</h3>
<p>The FDR (or the Fdr) is a set property. It is a single number that applies to a whole set of rejections made in the course of a multiple testing analysis. In contrast, the fdr is a local property. It applies to an individual hypothesis. Recall <a href="#fig-testing-lfdr" class="quarto-xref">Figure&nbsp;<span>6.16</span></a>, where the fdr was computed for each point along the <span class="math inline">\(x\)</span>-axis of the density plot, whereas the Fdr depends on the areas to the left of the red line.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-economics" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.21 </strong></span>Check out the concepts of <em>total cost</em> and <em>marginal cost</em> in economics. Can you see an analogy with Fdr and fdr?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-30-contents" aria-controls="callout-30" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-30" class="callout-30-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For a production process that produces a set of <span class="math inline">\(m\)</span> products, the total cost is the sum of the all costs involved. The average cost of a product is a hypothetical quantity, computed as the total cost divided by <span class="math inline">\(m\)</span>. The marginal cost is the cost of making one additional product, and is often very different from the average cost. For instance, learning to play a single Beethoven sonata on the piano may take an uninitiated person a substantial amount of time, but then playing it once more requires comparatively little additional effort: the marginal costs are much less than the fixed (and thus the total) costs. An example for marginal costs that are higher than the average costs is running: putting on your shoes and going out for a 10km run may be quite tolerable (perhaps even fun) to most people, whereas each additional 10km could add disproportional discomfort.</p>
</div>
</div>
</div>
</section>
<section id="terminology" class="level3" data-number="6.10.2">
<h3 data-number="6.10.2" class="anchored" data-anchor-id="terminology"><span class="header-section-number">6.10.2</span> Terminology</h3>
<p>Historically, the terms <em>multiple testing correction</em> and <em>adjusted p-value</em> have been used for process and output. In the context of false discovery rates, these terms are not helpful, if not confusing. We advocate avoiding them. They imply that we start out with a set of p-values <span class="math inline">\((p_1,...,p_m)\)</span>, apply some canonical procedure, and obtain a set of “corrected” or “adjusted” p-values <span class="math inline">\((p_1^{\text{adj}},...,p_m^{\text{adj}})\)</span>. However, the output of the Benjamini-Hochberg method is not p-values, and neither are the FDR, Fdr or the fdr. Remember that FDR and Fdr are set properties, and associating them with an individual test makes as much sense as confusing average and marginal costs. Fdr and fdr also depend on a substantial amount of modelling assumptions. In the next session, you will also see that the method of Benjamini-Hochberg is not the only game in town, and that there are important and useful extensions, which further displace any putative direct correspondence between the set of hypotheses and p-values that are input into a multiple testing procedure, and its outputs.</p>
</section>
</section>
<section id="independent-hypothesis-weighting" class="level2 page-columns page-full" data-number="6.11">
<h2 data-number="6.11" class="anchored" data-anchor-id="independent-hypothesis-weighting"><span class="header-section-number">6.11</span> Independent hypothesis weighting</h2>
<p>The Benjamini-Hochberg method and the two-groups model, as we have seen them so far, implicitly assume <em>exchangeability</em> of the hypotheses: all we use are the p-values. Beyond these, we do not take into account any additional information. This is not always optimal, and here we’ll study ways of how to improve on this.</p>
<p>Let’s look at an example. Intuitively, the signal-to-noise ratio for genes with larger numbers of reads mapped to them should be better than for genes with few reads, and that should affect the power of our tests. We look at the mean of normalized counts across observations. In the <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong> package this quantity is called the <code>baseMean</code>.</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/awde_basemean_counts_405c71e0a01d64e13109c58aceab1c94">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>awde<span class="sc">$</span>baseMean[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 708.6022</code></pre>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>cts <span class="ot">=</span> <span class="fu">counts</span>(aw, <span class="at">normalized =</span> <span class="cn">TRUE</span>)[<span class="dv">1</span>, ]</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>cts</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>SRR1039508 SRR1039509 SRR1039512 SRR1039513 SRR1039516 SRR1039517 SRR1039520 
  663.3142   499.9070   740.1528   608.9063   966.3137   748.3722   836.2487 
SRR1039521 
  605.6024 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(cts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 708.6022</code></pre>
</div>
</div>
<p>Next we produce the histogram of this quantity across genes, and plot it against the p-values (Figures <a href="#fig-testing-basemean-hist" class="quarto-xref"><span>6.17</span></a> and <a href="#fig-testing-basemean-scp" class="quarto-xref"><span>6.18</span></a>).</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-basemean-hist_078f851e1490b3b741242ff96b39bad2">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(awde, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">asinh</span>(baseMean))) <span class="sc">+</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">60</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-basemean-hist" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-basemean-hist-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;6.17: Histogram of <code>baseMean</code>. We see that it covers a large dynamic range, from close to 0 to around 330000.</figcaption>
</figure>
</div>
</div></div></div>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-basemean-scp_38f53fb2b621396cf44e9962d05a3ff1">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(awde, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">rank</span>(baseMean), <span class="at">y =</span> <span class="sc">-</span><span class="fu">log10</span>(pvalue))) <span class="sc">+</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hex</span>(<span class="at">bins =</span> <span class="dv">60</span>) <span class="sc">+</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-basemean-scp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-basemean-scp-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;6.18: Scatterplot of the rank of <code>baseMean</code> versus the negative logarithm of the p-value. For small values of <code>baseMean</code>, no small p-values occur. Only for genes whose read counts across all observations have a certain size, the test for differential expression has power to come out with a small p-value.</figcaption>
</figure>
</div>
</div></div></div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-trsf" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.22 </strong></span>Why did we use the <span class="math inline">\(\text{asinh}\)</span> transformation for the histogram? How does it look like with no transformation, the logarithm, the shifted logarithm, i.e., <span class="math inline">\(\log(x+\text{const.})\)</span>?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-log10" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.23 </strong></span>In the scatterplot, why did we use <span class="math inline">\(-\log_{10}\)</span> for the p-values? Why the rank transformation for the <code>baseMean</code>?</p>
</div>
</div>
</div>
<p>For convenience, we discretize <code>baseMean</code> into a factor variable <code>group</code>, which corresponds to six equal-sized groups.</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/awde_stratify_313f1a002ccd3db5f5a04478a04a55df">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>awde <span class="ot">=</span> <span class="fu">mutate</span>(awde, <span class="at">stratum =</span> <span class="fu">cut</span>(baseMean, <span class="at">include.lowest =</span> <span class="cn">TRUE</span>,</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">breaks =</span> <span class="fu">signif</span>(<span class="fu">quantile</span>(baseMean,<span class="at">probs=</span><span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">length.out=</span><span class="dv">7</span>)),<span class="dv">2</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In Figures <a href="#fig-testing-awde-stratified-hist" class="quarto-xref"><span>6.19</span></a> and <a href="#fig-testing-awde-stratified-ecdf" class="quarto-xref"><span>6.20</span></a> we see the histograms of p-values and the ECDFs stratified by <code>stratum</code>.</p>
<!-- TODO: fig-caps overlap here -->
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-awde-stratified-hist_a734f9c07fd377aae01ef042c47e5865">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(awde, <span class="fu">aes</span>(<span class="at">x =</span> pvalue)) <span class="sc">+</span> <span class="fu">facet_wrap</span>( <span class="sc">~</span> stratum, <span class="at">nrow =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.025</span>, <span class="at">boundary =</span> <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-awde-stratified-hist" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-awde-stratified-hist-1.png" class="img-fluid figure-img" width="240"></p>
<figcaption class="figure-caption">Figure&nbsp;6.19: p-value histograms of the airway data, stratified into equally sized groups defined by increasing value of <code>baseMean</code>.</figcaption>
</figure>
</div>
</div></div></div>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-awde-stratified-ecdf_61c0160da829375d4f3f426f87de41aa">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(awde, <span class="fu">aes</span>(<span class="at">x =</span> pvalue, <span class="at">col =</span> stratum)) <span class="sc">+</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_ecdf</span>(<span class="at">geom =</span> <span class="st">"step"</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-awde-stratified-ecdf" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-awde-stratified-ecdf-1.png" class="img-fluid figure-img" width="320"></p>
<figcaption class="figure-caption">Figure&nbsp;6.20: Same data as in <a href="#fig-testing-awde-stratified-hist" class="quarto-xref">Figure&nbsp;<span>6.19</span></a>, shown with ECDFs.</figcaption>
</figure>
</div>
</div></div></div>
<p>If we were to fit the two-group model to these strata separately, we would get quite different estimates for <span class="math inline">\(\pi_0\)</span> and <span class="math inline">\(f_{\text{alt}}\)</span>. For the most lowly expressed genes, the power of the <strong><a href="https://bioconductor.org/packages/DESeq2/">DESeq2</a></strong>-test is low, and the p-values essentially all come from the null component. As we go higher in average expression, the height of the small-p-values peak in the histograms increases, reflecting the increasing power of the test.</p>
<!-- TODO: footnote here overlaps with figure caption -->
<div class="page-columns page-full"><p>Can we use that to improve our handling of the multiple testing? It turns out that this is possible. One approach is <strong>independent hypothesis weighting</strong> (IHW) <span class="citation" data-cites="Ignatiadis:2016 Ignatiadis:JRSSB:2021">(<a href="16-chap.html#ref-Ignatiadis:2016" role="doc-biblioref">Ignatiadis et al. 2016</a>; <a href="16-chap.html#ref-Ignatiadis:JRSSB:2021" role="doc-biblioref">Ignatiadis and Huber 2021</a>)</span><a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a>.</p><div class="no-row-height column-margin column-container"><li id="fn22"><p><sup>22</sup>&nbsp;There are a number of other approaches, see e.g., a benchmark study by <span class="citation" data-cites="Korthauer:GB:2019">Korthauer et al. (<a href="16-chap.html#ref-Korthauer:GB:2019" role="doc-biblioref">2019</a>)</span> or the citations in the paper by <span class="citation" data-cites="Ignatiadis:JRSSB:2021">Ignatiadis and Huber (<a href="16-chap.html#ref-Ignatiadis:JRSSB:2021" role="doc-biblioref">2021</a>)</span>.</p></li></div></div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"IHW"</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>ihw_res <span class="ot">=</span> <span class="fu">ihw</span>(awde<span class="sc">$</span>pvalue, awde<span class="sc">$</span>baseMean, <span class="at">alpha =</span> <span class="fl">0.1</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rejections</span>(ihw_res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4892</code></pre>
</div>
</div>
<p>Let’s compare this to what we get from the ordinary (unweighted) Benjamini-Hochberg method:</p>
<div class="cell" data-layout-align="center" data-hash="06-chap_cache/html/ihwcompare_ca250fcfb603ecf4a1e53471a6d6776f">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>padj_BH <span class="ot">=</span> <span class="fu">p.adjust</span>(awde<span class="sc">$</span>pvalue, <span class="at">method =</span> <span class="st">"BH"</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(padj_BH <span class="sc">&lt;</span> <span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4099</code></pre>
</div>
</div>
<p>With hypothesis weighting, we get more rejections. For these data, the difference is notable though not spectacular; this is because their signal-to-noise ratio is already quite high. In other situations, where there is less power to begin with (e.g., where there are fewer replicates, the data are more noisy, or the effect of the treatment is less drastic), the difference from using IHW can be more pronounced.</p>
<p>We can have a look at the weights determined by the <code>ihw</code> function (<a href="#fig-testing-ihwplot" class="quarto-xref">Figure&nbsp;<span>6.21</span></a>).</p>
<div class="cell page-columns page-full" data-layout-align="center" data-hash="06-chap_cache/html/fig-testing-ihwplot_692e3f1997d89a169c04d19f90fa8bd3">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ihw_res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-testing-ihwplot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="06-chap_files/figure-html/fig-testing-ihwplot-1.png" class="img-fluid figure-img" width="280"></p>
<figcaption class="figure-caption">Figure&nbsp;6.21: Hypothesis weights determined by the <code>ihw</code> function. Here the function’s default settings chose 22 strata, while in our manual exploration above (Figures <a href="#fig-testing-awde-stratified-hist" class="quarto-xref"><span>6.19</span></a>, <a href="#fig-testing-awde-stratified-ecdf" class="quarto-xref"><span>6.20</span></a>) we had used 6; in practice, this is a minor detail.</figcaption>
</figure>
</div>
</div></div></div>
<p>Intuitively, what happens here is that IHW chooses to put more weight on the hypothesis strata with higher <code>baseMean</code>, and low weight on those with very low counts. The Benjamini-Hochberg method has a certain type-I error budget, and rather than spreading it equally among all hypotheses, here we take it away from those strata that have little change of small fdr anyway, and “invest” it in strata where many hypotheses can be rejected at small fdr.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="prp-testing-kfolds" class="theorem proposition">
<p><span class="theorem-title"><strong>Question 6.24 </strong></span>Why does <a href="#fig-testing-ihwplot" class="quarto-xref">Figure&nbsp;<span>6.21</span></a> show 5 curves, rather than only one?</p>
</div>
</div>
</div>
<p>Such possibilities for stratification by an additional summary statistic besides the p-value—in our case, the <code>baseMean</code>—exist in many multiple testing situations. Informally, we need such a so-called <em>covariate</em> to be</p>
<ul>
<li><p>statistically independent from our p-values under the null, but</p></li>
<li><p>informative of the prior probability <span class="math inline">\(\pi_0\)</span> and/or the power of the test (the shape of the alternative density, <span class="math inline">\(f_{\text{alt}}\)</span>) in the two-groups model.</p></li>
</ul>
<p>These requirements can be assessed through diagnostic plots as in Figures <a href="#fig-testing-basemean-hist" class="quarto-xref"><span>6.17</span></a>—<a href="#fig-testing-awde-stratified-ecdf" class="quarto-xref"><span>6.20</span></a>.</p>
</section>
<section id="summary-of-this-chapter" class="level2" data-number="6.12">
<h2 data-number="6.12" class="anchored" data-anchor-id="summary-of-this-chapter"><span class="header-section-number">6.12</span> Summary of this chapter</h2>
<p>We have explored the concepts behind <em>single hypothesis testing</em> and then moved on to <em>multiple testing</em>. We have seen how some of the limitations of interpreting a single p-value from a single test can be overcome once we are able to consider a whole distribution of outcomes from many tests. We have also seen that there are often additional summary statistics of our data, besides the p-values. We called them informative covariates, and we saw how we can use them to weigh the p-values and overall get more (or better) discoveries.</p>
<p>The usage of hypothesis testing in the <em>multiple testing</em> scenario is quite different from that in the <em>single test</em> case: for the latter, the hypothesis test might literally be the final result, the culmination of a long and expensive data acquisition campaign (ideally, with a prespecified hypothesis and data analysis plan). In the multiple testing case, its outcome will often just be an intermediate step: a subset of most worthwhile hypotheses selected by screening a large initial set. This subset is then followed up by more careful analyses.</p>
<p>We have seen the concept of the <em>false discovery rate</em> (FDR). It is important to keep in mind that this is an average property, for the subset of hypotheses that were selected. Like other averages, it does not say anything about the individual hypotheses. Then there is the concept of the <em>local false discovery rate</em> (fdr), which indeed does apply to an individual hypothesis. The local false discovery rate is however quite unrelated to the p-value, as the two-group model showed us. Much of the confusion and frustration about p-values seems to come from the fact that people would like to use them for purposes that the fdr is made for. It is perhaps a historical aberration that so much of applied sciences focuses on p-values and not local false discovery rate. On the other hand, there are also practical reasons, since a p-value is readily computed, whereas a fdr is difficult to estimate or control from data without making strong modelling assumptions.</p>
<p>We saw the importance of diagnostic plots, in particular, to always look at the p-value histograms when encountering a multiple testing analysis.</p>
</section>
<section id="further-reading" class="level2" data-number="6.13">
<h2 data-number="6.13" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">6.13</span> Further reading</h2>
<ul>
<li><p>A comprehensive text book treatment of multiple testing is given by <span class="citation" data-cites="Efron2010">Efron (<a href="16-chap.html#ref-Efron2010" role="doc-biblioref">2010</a>)</span>.</p></li>
<li><p>Outcome switching in clinical trials: <a href="http://compare-trials.org" class="uri">http://compare-trials.org</a></p></li>
<li><p>For hypothesis weighting, the <strong><a href="https://bioconductor.org/packages/IHW/">IHW</a></strong> vignette, the IHW paper <span class="citation" data-cites="Ignatiadis:2016">(<a href="16-chap.html#ref-Ignatiadis:2016" role="doc-biblioref">Ignatiadis et al. 2016</a>)</span> and the references therein.</p></li>
</ul>
</section>
<section id="exercises" class="level2" data-number="6.14">
<h2 data-number="6.14" class="anchored" data-anchor-id="exercises"><span class="header-section-number">6.14</span> Exercises</h2>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-testing-yourmt" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.1 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p>Identify an application from your scientific field of expertise that relies on multiple testing. Find an exemplary dataset and plot the histogram of p-values. Are the hypotheses all exchangeable, or is there one or more informative covariates? Plot the stratified histograms.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-testing-nullvsalt" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.2 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p>Why do mathematical statisticians focus so much on the null hypothesis of a test, compared to the alternative hypothesis?</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-testing-proovenull" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.3 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p>How can we ever prove that the null hypothesis is true? Or that the alternative is true?</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-testing-lessextremecorr" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.4 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p>Make a less extreme example of correlated test statistics than the data duplication at the end of <a href="#sec-testing-ttest" class="quarto-xref"><span>Section&nbsp;6.5</span></a>. Simulate data with true null hypotheses only, and let the data morph from having completely independent replicates (columns) to highly correlated as a function of some continuous-valued control parameter. Check type-I error control (e.g., with the p-value histogram) as a function of this control parameter.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-testing-pvaluehacking" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.5 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p>Find an example in the published literature that looks as if p-value hacking, outcome switching, HARKing played a role.</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-testing-worstcase" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.6 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p>The FDR is an expectation value, i.e., it is used if we want to control the average behavior of a procedure. Are there methods for worst case control?</p>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-testing-complexity" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.7 </strong></span>&nbsp;</p>
</div>
</div>
</div>
<p>What is the memory and time complexity of the Benjamini-Hochberg algorithm? How about the IHW method? Can you fit polynomial functions as a function of the number of tests <span class="math inline">\(m\)</span>? Hint: Simulate data with increasing numbers of hypothesis tests, measure time and memory consumption with functions such as <code>pryr::object_size</code> or <code>microbenchmark</code> from the eponymous package, and plot these against <span class="math inline">\(m\)</span> in a double-logarithmic plot.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-Altman:PoS:2017" class="csl-entry" role="listitem">
Altman, Naomi, and Martin Krzywinski. 2017. <span>“Points of Significance: Interpreting p Values.”</span> <em>Nature <span>M</span>ethods</em> 14 (3): 213–14. <a href="https://doi.org/10.1038/nmeth.4210">https://doi.org/10.1038/nmeth.4210</a>.
</div>
<div id="ref-BH:1995" class="csl-entry" role="listitem">
Benjamini, Yoav, and Yosef Hochberg. 1995. <span>“Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing.”</span> <em>Journal of the Royal Statistical Society B</em> 57: 289–300.
</div>
<div id="ref-Efron2010" class="csl-entry" role="listitem">
Efron, Bradley. 2010. <em>Large-Scale Inference: Empirical <span>B</span>ayes Methods for Estimation, Testing, and Prediction</em>. Cambridge University Press.
</div>
<div id="ref-Head:PLoSBiol:2015:pvaluehacking" class="csl-entry" role="listitem">
Head, Megan L, Luke Holman, Rob Lanfear, Andrew T Kahn, and Michael D Jennions. 2015. <span>“The Extent and Consequences of p-Hacking in Science.”</span> <em>PLoS Biology</em> 13 (3): e1002106.
</div>
<div id="ref-Ignatiadis:JRSSB:2021" class="csl-entry" role="listitem">
Ignatiadis, Nikolaos, and Wolfgang Huber. 2021. <span>“Covariate Powered Cross-Weighted Multiple Testing.”</span> <em>Journal of the Royal Statistical Society: Series B</em> 83: 720–51. <a href="https://doi.org/10.1111/rssb.12411">https://doi.org/10.1111/rssb.12411</a>.
</div>
<div id="ref-Ignatiadis:2016" class="csl-entry" role="listitem">
Ignatiadis, Nikolaos, Bernd Klaus, Judith Zaugg, and Wolfgang Huber. 2016. <span>“Data-Driven Hypothesis Weighting Increases Detection Power in Genome-Scale Multiple Testing.”</span> <em>Nature Methods</em> 13: 577–80.
</div>
<div id="ref-Korthauer:GB:2019" class="csl-entry" role="listitem">
Korthauer, K., P. K. Kimes, C. Duvallet, A. Reyes, A. Subramanian, M. Teng, C. Shukla, E. J. Alm, and S. C. Hicks. 2019. <span>“<span class="nocase"><span>A</span> practical guide to methods controlling false discoveries in computational biology</span>.”</span> <em>Genome Biology</em> 20 (1): 118.
</div>
<div id="ref-SchwederSpjotvoll1982" class="csl-entry" role="listitem">
Schweder, T., and E. Spjøtvoll. 1982. <span>“Plots of <span class="nocase">P-values</span> to Evaluate Many Tests Simultaneously.”</span> <em>Biometrika</em> 69: 493–502. <a href="https://doi.org/10.1093/biomet/69.3.493">https://doi.org/10.1093/biomet/69.3.493</a>.
</div>
<div id="ref-Storey:AnnStat:2003" class="csl-entry" role="listitem">
Storey, John D. 2003. <span>“The Positive False Discovery Rate: A Bayesian Interpretation and the q-Value.”</span> <em>The Annals of Statistics</em> 31 (6). <a href="https://doi.org/10.1214/aos/1074290335">https://doi.org/10.1214/aos/1074290335</a>.
</div>
<div id="ref-Wasserstein2016:ASA" class="csl-entry" role="listitem">
Wasserstein, Ronald L, and Nicole A Lazar. 2016. <span>“The <span>ASA</span>’s Statement on p-Values: Context, Process, and Purpose.”</span> <em>The American Statistician</em>.
</div>
</div>
</section>
<aside id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>






















</ol>
</aside>

<p>Page built on 2023-08-03 21:37:40.81968 using R version 4.3.0 (2023-04-21)</p></main> <!-- /main --></p><p class="build-date">
Support for maintaining the online version of this book is provided by <a href="http://www.denbi.de">de.NBI</a>
  <img src="imgs/denbi.png" style="vertical-align: text-top;height: 16px"><br>
For website support please contact msmith@embl.de
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS_eq = new window.AnchorJS();
  anchorJS_eq.options = {
    placement: 'left',
    class: 'eq-link',
    icon: icon
  };
  anchorJS_eq.add('.anchored-eq');
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>
